<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>onnxruntime构建项目</title>
    <link href="/2024/onnxruntime%E6%9E%84%E5%BB%BA%E9%A1%B9%E7%9B%AE/"/>
    <url>/2024/onnxruntime%E6%9E%84%E5%BB%BA%E9%A1%B9%E7%9B%AE/</url>
    
    <content type="html"><![CDATA[<h2 id="bug1：The-given-version-11-is-not-supported-only-version-1-to-7-is-supported-in-this-build"><a href="#bug1：The-given-version-11-is-not-supported-only-version-1-to-7-is-supported-in-this-build" class="headerlink" title="bug1：The given version [11] is not supported, only version 1 to 7 is supported in this build."></a>bug1：The given version [11] is not supported, only version 1 to 7 is supported in this build.</h2><p>应该是加载了C:\Windows\System32\onnxruntime.dll里的这个文件，因为我之前使用的是1.6版本，C盘下的onnxruntime.dll没有替换，导致了错误。可以把最新的onnxruntime.dll替换掉，或者直接将该文件放置到编译后的.exe同级目录下。</p><h2 id="windows下构建onnxruntime的c-推理环境"><a href="#windows下构建onnxruntime的c-推理环境" class="headerlink" title="windows下构建onnxruntime的c++推理环境"></a>windows下构建onnxruntime的c++推理环境</h2><p>1。下载编译好的onnxruntime库，<a href="https://github.com/microsoft/onnxruntime/releases/tag/v1.15.0">链接</a><br>2.打开VS的属性页，设定配置（我一般直接Release），平台（我直接X64），找到c&#x2F;c++ -&gt; 常规 -&gt; 附加包含目录。将onnxruntime-win-x64-gpu-1.15.0\include路径添加进去<br>3.打开VS的属性页，找到链接器-&gt;输入-&gt;附加依赖项。将onnxruntime-win-x64-gpu-1.15.0\lib\onnxruntime.lib路径添加进去<br>4.在cpp文件中，添加库：#include&lt;onnxruntime_cxx_api.h&gt;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>如何利用onnxruntime构建c++项目</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>免费视频素材音乐音效</title>
    <link href="/2024/%E5%85%8D%E8%B4%B9%E8%A7%86%E9%A2%91%E7%B4%A0%E6%9D%90%E9%9F%B3%E4%B9%90%E9%9F%B3%E6%95%88/"/>
    <url>/2024/%E5%85%8D%E8%B4%B9%E8%A7%86%E9%A2%91%E7%B4%A0%E6%9D%90%E9%9F%B3%E4%B9%90%E9%9F%B3%E6%95%88/</url>
    
    <content type="html"><![CDATA[<p>尝试剪辑一些视频，但是想找一些视频素材或者音乐音效，一时难以找全，这里记录一下，方便获取</p><h2 id="视频相关"><a href="#视频相关" class="headerlink" title="视频相关"></a>视频相关</h2><ul><li>暂时未找到</li></ul><h2 id="音乐音效相关"><a href="#音乐音效相关" class="headerlink" title="音乐音效相关"></a>音乐音效相关</h2><ul><li><p><a href="https://freepd.com/upbeat.php">FreePD</a>：一些音乐会给出相应的情绪头像，挺有趣的。</p><img src="/2024/%E5%85%8D%E8%B4%B9%E8%A7%86%E9%A2%91%E7%B4%A0%E6%9D%90%E9%9F%B3%E4%B9%90%E9%9F%B3%E6%95%88/FreePD.png" class="" title="alt text"></li><li><p><a href="https://www.tosound.com/search/word-%E6%90%9E%E7%AC%91">淘声网</a>:感觉像是音效网站</p><img src="/2024/%E5%85%8D%E8%B4%B9%E8%A7%86%E9%A2%91%E7%B4%A0%E6%9D%90%E9%9F%B3%E4%B9%90%E9%9F%B3%E6%95%88/%E6%B7%98%E5%A3%B0%E7%BD%91.png" class="" title="alt text"></li></ul>]]></content>
    
    
    <categories>
      
      <category>视频剪辑</category>
      
    </categories>
    
    
    <tags>
      
      <tag>一些有趣的网站，提供视频检索+下载，免费音乐音效</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浏览器脚本-下载视频去广告</title>
    <link href="/2024/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%84%9A%E6%9C%AC-%E4%B8%8B%E8%BD%BD%E8%A7%86%E9%A2%91%E5%8E%BB%E5%B9%BF%E5%91%8A/"/>
    <url>/2024/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%84%9A%E6%9C%AC-%E4%B8%8B%E8%BD%BD%E8%A7%86%E9%A2%91%E5%8E%BB%E5%B9%BF%E5%91%8A/</url>
    
    <content type="html"><![CDATA[<p>因为想下载一些网站的视频，找到利用脚本进行下载的。感觉挺有用，分享出来。<br>1.找到一个<a href="https://greasyfork.org/zh-CN">脚本网址</a>,进入主页，我这里安装的谷歌浏览器的 Violentmonkey。</p><img src="/2024/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%84%9A%E6%9C%AC-%E4%B8%8B%E8%BD%BD%E8%A7%86%E9%A2%91%E5%8E%BB%E5%B9%BF%E5%91%8A/Greasy.png" class="" title="alt text"><ol start="2"><li>找到自己想要的脚本，我这里找到的是：<img src="/2024/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%84%9A%E6%9C%AC-%E4%B8%8B%E8%BD%BD%E8%A7%86%E9%A2%91%E5%8E%BB%E5%B9%BF%E5%91%8A/m3u8.png" class="" title="alt text">3.然后打开一个播放的视频，左上角就会出现一个链接，和download，点击就可以下载了。<img src="/2024/%E6%B5%8F%E8%A7%88%E5%99%A8%E8%84%9A%E6%9C%AC-%E4%B8%8B%E8%BD%BD%E8%A7%86%E9%A2%91%E5%8E%BB%E5%B9%BF%E5%91%8A/download.png" class="" title="alt text"></li></ol><p>当然还有很多实用的脚本，比如去掉视频网站里面的广告，或者加速网盘下载，以及一些其他脚本，还在探索中。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>如何利用Greasy Fork脚本实现一些功能，比如，免费下载视频，去掉网站广告等等</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>macbook Air 小问题解决</title>
    <link href="/2024/macbookair%E5%B0%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/"/>
    <url>/2024/macbookair%E5%B0%8F%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/</url>
    
    <content type="html"><![CDATA[<h3 id="clashX打不开了"><a href="#clashX打不开了" class="headerlink" title="clashX打不开了"></a>clashX打不开了</h3><ul><li>解决方案：在命令行输入下面代码，然后到 设置-&gt;通用-&gt;登陆项  将clashx设置为自启动<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">sudo launchctl enable system/com.west2online.ClashX.ProxyConfigHelper<br></code></pre></td></tr></table></figure></li></ul><h3 id="在macbook-air-m2下，已经配置好ssh，依旧clone超时结局方案"><a href="#在macbook-air-m2下，已经配置好ssh，依旧clone超时结局方案" class="headerlink" title="在macbook air m2下，已经配置好ssh，依旧clone超时结局方案"></a>在macbook air m2下，已经配置好ssh，依旧clone超时结局方案</h3><p>在命令行下，运行下面这行代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c++">git config --global <span class="hljs-string">&quot;url.ssh://git@ssh.github.com:443/.insteadOf&quot;</span> git@github.com:<br></code></pre></td></tr></table></figure><h3 id="为mac配置镜像源，比如下载brew等太慢等情况"><a href="#为mac配置镜像源，比如下载brew等太慢等情况" class="headerlink" title="为mac配置镜像源，比如下载brew等太慢等情况"></a>为mac配置镜像源，比如下载brew等太慢等情况</h3><ul><li><p><a href="https://zhuanlan.zhihu.com/p/90508170">参考网址</a></p></li><li><p>如果有更换镜像源的想法，强烈推荐使用<a href="https://brew.idayer.com/guide/change-source/">镜像助手</a>获取执行脚本。</p></li><li><p>下面是我的配置</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-keyword">export</span> HOMEBREW_BREW_GIT_REMOTE=<span class="hljs-string">&quot;https://mirrors.ustc.edu.cn/brew.git&quot;</span><br><span class="hljs-keyword">export</span> HOMEBREW_CORE_GIT_REMOTE=<span class="hljs-string">&quot;https://mirrors.ustc.edu.cn/homebrew-core.git&quot;</span><br><span class="hljs-keyword">export</span> HOMEBREW_API_DOMAIN=<span class="hljs-string">&quot;https://mirrors.ustc.edu.cn/homebrew-bottles/api&quot;</span><br><span class="hljs-keyword">export</span> HOMEBREW_BOTTLE_DOMAIN=<span class="hljs-string">&quot;https://mirrors.ustc.edu.cn/homebrew-bottles/bottles&quot;</span><br><br><span class="hljs-comment">//安装brew</span><br>/bin/bash -c <span class="hljs-string">&quot;$(curl -fsSL https://gitee.com/ineo6/homebrew-install/raw/master/install.sh)&quot;</span><br></code></pre></td></tr></table></figure></li><li><p>安装完成，想要恢复默认值怎么办，可以执行下面的代码</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs c++">git -C <span class="hljs-string">&quot;$(brew --repo)&quot;</span> remote set-url origin https:<span class="hljs-comment">//github.com/Homebrew/brew.git</span><br><br>git -C <span class="hljs-string">&quot;$(brew --repo homebrew/core)&quot;</span> remote set-url origin https:<span class="hljs-comment">//github.com/Homebrew/homebrew-core.git</span><br><br>git -C <span class="hljs-string">&quot;$(brew --repo homebrew/cask)&quot;</span> remote set-url origin https:<span class="hljs-comment">//github.com/Homebrew/homebrew-cask.git</span><br><br>brew update<br></code></pre></td></tr></table></figure><h3 id="hexo-Failed-to-connect-to-github-com-port-443-Timed-out-错误解决"><a href="#hexo-Failed-to-connect-to-github-com-port-443-Timed-out-错误解决" class="headerlink" title="hexo Failed to connect to github.com port 443: Timed out 错误解决"></a>hexo Failed to connect to github.com port 443: Timed out 错误解决</h3><p>将hexo _config.yml里的git地址由<a href="https://github.com/xxx%E4%BF%AE%E6%94%B9%E4%B8%BAssh">https://github.com/xxx修改为ssh</a> <a href="mailto:&#103;&#105;&#116;&#x40;&#103;&#x69;&#x74;&#104;&#117;&#98;&#x2e;&#99;&#x6f;&#x6d;">&#103;&#105;&#116;&#x40;&#103;&#x69;&#x74;&#104;&#117;&#98;&#x2e;&#99;&#x6f;&#x6d;</a>:xxx&#x2F;xxx也可以。</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mac</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>视频软件介绍</title>
    <link href="/2024/%E5%90%84%E7%A7%8D%E8%A7%86%E9%A2%91%E7%89%B9%E6%95%88%E6%80%BB%E7%BB%93/"/>
    <url>/2024/%E5%90%84%E7%A7%8D%E8%A7%86%E9%A2%91%E7%89%B9%E6%95%88%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="一些视频软件"><a href="#一些视频软件" class="headerlink" title="一些视频软件"></a>一些视频软件</h1><ul><li>1.1 整体最佳、功能最强的视频编辑软件：Adobe Premiere Pro CC</li><li>1.2 物美价廉的中文视频编辑软件：<a href="#1.2">蜜蜂剪辑（Beecut）</a></li><li>1.3 最适合Apple Mac的视频编辑软件：Apple Final Cut Pro X</li><li>1.4 适合初学者的视频编辑软件：<a href="#1.4">Corel VideoStudio Ultimate</a></li><li>1.5 价格实惠的视频剪辑软件：Adobe Premiere Elements 2020</li><li>1.6 适合制作电影效果的视频编辑软件：CyberLink PowerDirector</li><li>1.7 编辑速度快的视频编辑软件：Ulead Video Studio</li><li>1.8 一款适合Mac的视频剪辑软件：<a href="#1.8">DaVinci Resolve</a></li><li>1.9 最受欢迎的家庭视频剪辑软件：Magix Movie Edit Pro Premium</li><li>1.10 免费的苹果系统视频编辑软件：Apple iMovie</li><li>1.11 最佳快速视频编辑软件：<a href="#1.11">Movavi Video Editor</a></li><li>1.12 最佳预算视频编辑软件：Wondershare Filmora</li><li>1.13 最佳细节调整视频编辑软件：Vegas Pro</li><li>1.14 最佳移动客户端视频编辑软件：Adobe Premiere Rush</li><li>1.15 最佳小型企业适用视频编辑软件：Vimeo</li><li>1.16 录屏+视频编辑软件二合一：Camtasia</li><li>1.17 最佳免费视频剪辑软件：<a href="#1.17">Lightworks</a></li><li>1.18 免费好用的视频剪辑软件：<a href="#1.18">OpenShot</a></li><li>1.19 最佳简洁界面视频编辑软件：<a href="#1.19">Shotcut</a></li><li>1.20 最佳性价比专业级视频编辑软件：Blender</li><li>1.21 最佳Windows自带视频编辑软件：Windows Video Editor</li><li>1.22 最佳在线视频编辑软件：<a href="#1.22">WeVideo</a></li><li>1.23 最佳专业性移动视频编辑软件：KineMaster</li><li>1.24 最适合社交媒体使用者的视频编辑软件：Magisto</li><li>1.25 最佳画面色彩视频编辑软件：<a href="#1.25">Pinnacle Studio Ultimate</a></li><li>1.26 最佳业余爱好者适用视频编辑软件： HitFilm Pro 和 HitFilm Express</li><li>1.27 最佳Windows系统适用视频编辑软件：VideoPad</li><li>1.28 模板种类繁多的视频变价软件：<a href="#1.28">万兴喵影</a></li></ul><h2 id="蜜蜂剪辑"><a href="#蜜蜂剪辑" class="headerlink" title="蜜蜂剪辑"></a><center><h3 id="1.2">蜜蜂剪辑</h3></center></h2><p>蜜蜂是一个视频编辑软件，它有很多不同的特效可以使用。以下是蜜蜂剪辑中一些常见的特效：</p><ol><li><p>缩放特效：可以将视频放大或缩小到指定的比例。</p></li><li><p>旋转特效：可以将视频旋转指定的角度。</p></li><li><p>倒放特效：可以将视频倒放，使其从后往前播放。</p></li><li><p>模糊特效：可以将视频或画面进行模糊处理，从而产生柔和的效果。</p></li><li><p>色彩特效：可以调整视频的颜色和饱和度，以获得不同的色彩效果。</p></li><li><p>动画特效：可以使用不同的动画效果，例如淡入淡出、飞入飞出等等，为视频添加更多的动感。</p></li><li><p>拼接特效：可以将多个视频拼接在一起，创造出更有趣的效果。</p></li><li><p>变速特效：可以改变视频的播放速度，使其快速播放或慢动作。</p></li></ol><p>以上是蜜蜂剪辑中的一些常见特效，但实际上蜜蜂还有很多其他的特效可供使用，具体的特效还要根据具体的版本和软件使用者的需求而定。</p><p><font color=red size=4>优缺点</font></p><p>蜜蜂剪辑有两个版本，一个是免费版，另一个是专业版。免费版可以免费下载和使用，但其功能有一定限制，例如不能导出高清视频、会有水印等。而专业版则需要付费购买才能使用所有的功能。</p><h2 id="Corel-VideoStudio-Ultimate"><a href="#Corel-VideoStudio-Ultimate" class="headerlink" title="Corel VideoStudio Ultimate"></a><center><h3 id="1.4">Corel VideoStudio Ultimate</h3></center></h2><p>Corel VideoStudio Ultimate是一款功能丰富的视频编辑软件，可以帮助用户创建专业水平的视频。以下是该软件的一些主要特点：</p><ol><li><p>用户友好的界面：Corel VideoStudio Ultimate的界面非常直观，易于使用。用户可以轻松地将视频素材拖放到时间轴上，并使用各种工具进行编辑。</p></li><li><p>视频编辑功能：该软件具有丰富的视频编辑功能，包括剪辑、分割、裁剪、旋转、调整亮度、对比度、色调和饱和度等。此外，它还提供了多种视频过渡效果和滤镜，可以轻松地将视频素材制作成专业水平的视频。</p></li><li><p>音频编辑功能：Corel VideoStudio Ultimate还具有强大的音频编辑功能。用户可以添加音乐、音效和语音记录，并使用音频混合器调整音频音量和平衡。</p></li><li><p>视频效果：该软件提供了大量的视频效果，包括红眼消除、噪音降低、图像稳定、运动跟踪等。这些效果可以改善视频的质量和外观。</p></li><li><p>多媒体支持：Corel VideoStudio Ultimate支持各种视频、音频和图像格式，包括AVI、MP4、MKV、FLV、MP3、WAV、JPEG、PNG等。用户可以导入多种类型的媒体文件进行编辑。</p></li><li><p>输出设置：该软件提供了各种输出设置选项，包括视频格式、分辨率、帧速率、音频编码等。用户可以根据自己的需求选择适当的输出设置。</p></li></ol><p>总的来说，Corel VideoStudio Ultimate是一款强大的视频编辑软件，提供了丰富的编辑工具和效果，可以帮助用户制作高质量的视频。<br>但是，Corel VideoStudio Ultimate是一款商业软件，需要付费购买。该软件提供了30天的免费试用，可以在试用期内测试软件并决定是否购买正式版本。</p><h2 id="DaVinci-Resolve"><a href="#DaVinci-Resolve" class="headerlink" title="DaVinci Resolve"></a><center><h3 id="1.8">DaVinci Resolve</h3></center></h2><p>DaVinci Resolve是一款功能强大的视频编辑软件，它提供了许多不同的特效和调色工具，以下是其中一些常见的特效：</p><ol><li><p>颜色校正：DaVinci Resolve是一个著名的颜色校正工具，它提供了许多调色工具和颜色校正技术，可以精确地调整视频的颜色和色调。</p></li><li><p>视觉特效：DaVinci Resolve提供了许多视觉特效，例如模糊、美颜、像素化、翻转、缩放、旋转等等，可以为视频添加更多的视觉效果。</p></li><li><p>文字特效：DaVinci Resolve提供了多种文字特效，包括滚动文字、弹出文字、背景文字、标签等等，可以让用户更容易地在视频中添加文字。</p></li><li><p>混音特效：DaVinci Resolve可以对音频进行混音，可以在视频中添加背景音乐、音效、声音处理等。</p></li><li><p>剪辑特效：DaVinci Resolve提供了多种剪辑特效，例如缓慢运动、速度变化、转场效果等等，可以让视频剪辑更加流畅和自然。</p></li><li><p>3D特效：DaVinci Resolve提供了一些3D特效，可以为视频添加立体效果，例如立体字、立体图像等。</p></li><li><p>转场特效：DaVinci Resolve提供了多种转场特效，包括淡入淡出、交叉淡入淡出、切换效果等等，可以为视频添加更加生动的转场效果。</p></li></ol><p>以上是DaVinci Resolve中一些常见的特效，但实际上它提供了许多其他的特效和工具，可以根据用户的需求进行选择和使用。</p><p><font color=red size=4>优缺点：</font></h2></p><p>免费版是可以<font color=red>没有水印</font>的，列表所列的80%的免费版良心一点。可能是人家家大业大，不在乎添加水印进行推广。但是缺点也很明显，他对于你的机器设备要求较高，毕竟阿凡达的特效都是用人家做的。</p><h2 id="Movavi-Video-Editor"><a href="#Movavi-Video-Editor" class="headerlink" title="Movavi Video Editor"></a><center><h3 id="1.11">Movavi Video Editor</h3></center></h2><p>Movavi Video Editor是一款视频编辑软件，它提供了许多内置的特效，包括：</p><ol><li><p>转场特效：可以选择不同的转场特效来平滑地将视频片段连接在一起，例如淡入淡出、擦除、闪烁等。</p></li><li><p>滤镜特效：可以将不同的滤镜应用于视频，以改变视频的外观和风格，例如黑白、褪色、电影、漫画等。</p></li><li><p>文字和标题特效：可以添加各种文字和标题，选择不同的字体、颜色、大小、样式等。</p></li><li><p>动画特效：可以在视频中添加各种动画效果，例如缩放、旋转、移动、闪烁等。</p></li><li><p>音效特效：可以添加各种音效和音乐，例如淡入淡出、回声、变速等。</p></li><li><p>视频加速和减速特效：可以加速或减慢视频的速度，创建慢动作和快速剪辑。</p></li><li><p>马赛克特效：可以添加马赛克来隐藏视频中的敏感信息或面部特征。</p></li></ol><p>以上是Movavi Video Editor提供的一些常见的特效，您可以根据需要选择和应用它们。</p><p><font color=red size=4>优缺点</font></p><p>这款编辑软件只有免费试用时间，没有免费版，其次试用期间导出有水印。</p><h2 id="Lightworks"><a href="#Lightworks" class="headerlink" title="Lightworks"></a><center><h3 id="1.17">Lightworks</h3></center></h2><p>Lightworks是一款功能强大的视频编辑软件，主要用于制作电影、电视节目和广告等专业级视频项目。以下是该软件的一些主要特点：</p><ol><li><p>用户友好的界面：Lightworks的界面简洁直观，用户可以轻松地将视频素材拖放到时间轴上，并使用各种工具进行编辑。</p></li><li><p>视频编辑功能：该软件具有丰富的视频编辑功能，包括剪辑、分割、裁剪、旋转、调整亮度、对比度、色调和饱和度等。此外，它还提供了多种视频过渡效果和滤镜，可以轻松地将视频素材制作成专业水平的视频。</p></li><li><p>音频编辑功能：Lightworks还具有强大的音频编辑功能。用户可以添加音乐、音效和语音记录，并使用音频混合器调整音频音量和平衡。</p></li><li><p>视频效果：该软件提供了大量的视频效果，包括图像稳定、色彩校正、绿屏合成等。这些效果可以改善视频的质量和外观。</p></li><li><p>多媒体支持：Lightworks支持各种视频、音频和图像格式，包括AVI、MP4、MKV、FLV、MP3、WAV、JPEG、PNG等。用户可以导入多种类型的媒体文件进行编辑。</p></li><li><p>输出设置：该软件提供了各种输出设置选项，包括视频格式、分辨率、帧速率、音频编码等。用户可以根据自己的需求选择适当的输出设置。</p></li><li><p>支持多平台：Lightworks可在Windows、macOS和Linux等多个平台上运行，方便用户进行跨平台编辑。</p></li></ol><p>总的来说，Lightworks是一款功能强大的视频编辑软件，提供了丰富的编辑工具和效果，可以帮助用户制作高质量的视频。</p><p>同时，该软件还提供了免费版和付费版，用户可以根据自己的需求选择不同版本。免费版相对于付费版来说功能上有一些限制，但仍然提供了一些基本的视频编辑工具和特效，以下是免费版的主要功能：</p><p><font color=red size=4>优缺点</font></p><p>需要注意的是，免费版的视频输出是有限制的，用户只能导出<strong>720p</strong>的视频，并且每个项目只能导出一个输出文件格式。此外，免费版的一些高级功能和<strong>特效</strong>是需要付费购买的。如果用户需要更多的功能和更高质量的输出，可以考虑升级到付费版。</p><h2 id="OpenShot"><a href="#OpenShot" class="headerlink" title="OpenShot"></a><center><h3 id=1.18>OpenShot</h3></center></h2><p>OpenShot是一款免费、开源的视频编辑软件，提供了许多内置的特效，包括：</p><ol><li><p>转场特效：可以选择不同的转场特效来平滑地将视频片段连接在一起，例如淡入淡出、擦除、闪烁等。</p></li><li><p>滤镜特效：可以将不同的滤镜应用于视频，以改变视频的外观和风格，例如黑白、褪色、电影、漫画等。</p></li><li><p>文字和标题特效：可以添加各种文字和标题，选择不同的字体、颜色、大小、样式等。</p></li><li><p>动画特效：可以在视频中添加各种动画效果，例如缩放、旋转、移动、闪烁等。</p></li><li><p>音效特效：可以添加各种音效和音乐，例如淡入淡出、回声、变速等。</p></li><li><p>视频加速和减速特效：可以加速或减慢视频的速度，创建慢动作和快速剪辑。</p></li><li><p>马赛克特效：可以添加马赛克来隐藏视频中的敏感信息或面部特征。</p></li><li><p>颜色特效：可以调整视频的色彩和亮度，增强视频的视觉效果。</p></li><li><p>图片特效：可以在视频中添加图片，创建幻灯片效果。</p></li></ol><p>以上是OpenShot提供的一些常见的特效，您可以根据需要选择和应用它们。此外，OpenShot还支持使用键帧和掩码等高级技术来创建自定义特效，使视频编辑更加灵活和创造性。</p><p><font color=red size=4>优缺点</font></p><p>毕竟都开源了，还要啥要求呢。</p><h2 id="Shotcut"><a href="#Shotcut" class="headerlink" title="Shotcut"></a><center><h3 id=1.19>Shotcut</h3></center></h2><p>Shotcut是一款免费、开源的视频编辑软件，它提供了许多特效来帮助用户创建和编辑视频。下面列举了一些常见的特效：</p><ol><li><p>转场特效：可以选择不同的转场特效，例如淡入淡出、闪烁、飞入等。</p></li><li><p>滤镜特效：可以选择不同的滤镜，例如模糊、褪色、黑白等。</p></li><li><p>音效特效：可以添加各种音效和音乐，例如淡入淡出、回声、音量等。</p></li><li><p>文字和标题特效：可以添加各种文字和标题，选择不同的字体、颜色、大小、样式等。</p></li><li><p>图像特效：可以使用不同的调色板和色彩渐变来调整视频的色彩。</p></li><li><p>马赛克特效：可以添加马赛克来隐藏视频中的敏感信息或面部特征。</p></li><li><p>速度特效：可以加速或减慢视频的速度，创建慢动作和快速剪辑。</p></li><li><p>旋转和缩放特效：可以在视频中添加旋转和缩放效果，以创建动画效果。</p></li><li><p>色键特效：可以使用色键来移除视频背景并替换为自定义背景。</p></li><li><p>图像覆盖特效：可以将视频叠加到另一个视频上，创建画中画效果。</p></li></ol><p>以上是Shotcut提供的一些常见的特效，您可以根据需要选择和应用它们。此外，Shotcut还支持使用键帧和掩码等高级技术来创建自定义特效，使视频编辑更加灵活和创造性。</p><p><font color=red size=4>优缺点</font></p><p>毕竟都开源了，还要啥要求呢。</p><h2 id="WeVideo"><a href="#WeVideo" class="headerlink" title="WeVideo"></a><center><h3 id=1.22>WeVideo</h3></center></h2><p>WeVideo是一款基于云的在线视频编辑软件，它提供了许多特效来帮助用户创建和编辑视频。下面列举了一些常见的特效：</p><ol><li><p>转场特效：可以选择不同的转场特效，例如淡入淡出、闪烁、飞入等。</p></li><li><p>滤镜特效：可以选择不同的滤镜，例如模糊、褪色、黑白等。</p></li><li><p>音效特效：可以添加各种音效和音乐，例如淡入淡出、回声、音量等。</p></li><li><p>文字和标题特效：可以添加各种文字和标题，选择不同的字体、颜色、大小、样式等。</p></li><li><p>图像特效：可以使用不同的调色板和色彩渐变来调整视频的色彩。</p></li><li><p>马赛克特效：可以添加马赛克来隐藏视频中的敏感信息或面部特征。</p></li><li><p>速度特效：可以加速或减慢视频的速度，创建慢动作和快速剪辑。</p></li><li><p>旋转和缩放特效：可以在视频中添加旋转和缩放效果，以创建动画效果。</p></li><li><p>图像覆盖特效：可以将视频叠加到另一个视频上，创建画中画效果。</p></li></ol><p>以上是WeVideo提供的一些常见的特效，您可以根据需要选择和应用它们。此外，WeVideo还支持使用键帧和掩码等高级技术来创建自定义特效，使视频编辑更加灵活和创造性。</p><p><font color=red size=4>优缺点</font></p><p>提供免费版和付费版，其中免费版只能导出720p以下的图像，同时还有水印。</p><h2 id="Pinnacle-Studio-Ultimate"><a href="#Pinnacle-Studio-Ultimate" class="headerlink" title="Pinnacle Studio Ultimate"></a><center><h3 id=1.25>Pinnacle Studio Ultimate</h3></center></h2><p>Pinnacle Studio Ultimate是一款功能强大的桌面视频编辑软件，提供了许多特效和过渡效果，包括但不限于以下几种：</p><ol><li><p>图像效果：包括色彩校正、镜头校正、色彩渐变、图像反转、缩放和旋转等。</p></li><li><p>视频效果：包括时间延迟、速度变化、缩放和旋转、背景模糊、镜像效果、画中画效果等。</p></li><li><p>文字效果：包括动态文本、标题模板、字幕、滚动文本等。</p></li><li><p>音效：包括音效增强、混音、剪辑、音频过渡等。</p></li><li><p>过渡效果：包括淡入淡出、三角形过渡、分割屏幕、滑动、旋转等。</p></li><li><p>其他效果：包括慢动作、倒放、绿屏、蓝屏、立体3D效果等。</p></li></ol><p>以上仅是Pinnacle Studio Ultimate提供的一部分特效，它具有丰富的特效和过渡效果，可以让用户创建更加丰富和独特的视频。</p><p><font color=red size=4>优缺点</font><br>有视频稳定功能，减少拍摄期间晃动等影响。但是没有免费版本。价格较高（120美元左右）。并且对设备要求较高。</p><h2 id="万兴喵影"><a href="#万兴喵影" class="headerlink" title="万兴喵影"></a><center><h3 id=1.28>万兴喵影</h3></center></h2><p>万兴喵影是一款易于使用的视频编辑软件，它提供了许多特效和过渡效果，包括：</p><ol><li><p>色彩调整：可以调整视频的色彩、亮度、对比度和饱和度等参数，使视频更加鲜艳和生动。</p></li><li><p>视频特效：包括动态画面、慢动作、快动作、镜像、旋转等，可以使视频更加生动有趣。</p></li><li><p>文字效果：包括字幕、标题、滚动字幕等，可以为视频添加文字注释和说明。</p></li><li><p>转场效果：包括淡入淡出、百叶窗、滑动、闪烁等，可以让视频之间的转换更加自然和流畅。</p></li><li><p>音效：包括混音、剪辑、音频过渡等，可以为视频添加背景音乐、音效和声音效果。</p></li><li><p>绿屏&#x2F;蓝屏效果：可以通过使用绿屏或蓝屏效果将视频中的背景替换为自定义图像或视频。</p></li><li><p>3D效果：可以为视频添加3D效果，增加视觉效果。</p></li><li><p>剪辑和裁剪：可以将视频剪辑成不同的片段或裁剪成不同的尺寸。</p></li><li><p>图像处理：可以添加图像、贴图和水印等特效，让视频更具视觉冲击力。</p></li><li><p>视频修复：可以对视频进行去噪、模糊、抖动等修复处理。</p></li></ol><p>以上仅是万兴喵影提供的一部分特效，用户可以根据自己的需求选择和编辑，以创建更加丰富和独特的视频。</p><p><font color=red size=4>优缺点</font></p><p>相对上手比较容易，模板种类挺多。</p><p>使用模板导出时没有水印。但是如果你使用其他功能就会有水印。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>视频软件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《论中国》</title>
    <link href="/2023/%E8%AE%BA%E4%B8%AD%E5%9B%BD/"/>
    <url>/2023/%E8%AE%BA%E4%B8%AD%E5%9B%BD/</url>
    
    <content type="html"><![CDATA[<p>利用闲暇时间，听完了这本书。本书是美国前国务卿、“政坛常青树”亨利·基辛格德一部中国问题专著。从一个外国人的角度更加清晰的认识了从清朝到近代的中国发展。感受颇多，从清朝的一次次狂妄自大，结果被列强轰开了国门，促使了中国近代以来悲惨的开始。随着之后国民党的失败，中国共产党执政，才使得中国的发展走向了正规。</p><p>本书是我感受到了：清政府的自大；毛主席的大开大合，高屋建瓴，富有哲学气质；周恩来总理的温文尔雅；邓小平主席的实干精神，做事直击重点；江泽明主席的睿智。</p>]]></content>
    
    
    <categories>
      
      <category>读一本好书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>论中国</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>shadertoy特效简单总结</title>
    <link href="/2023/shadertoy%E7%89%B9%E6%95%88%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93/"/>
    <url>/2023/shadertoy%E7%89%B9%E6%95%88%E7%AE%80%E5%8D%95%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="光线追踪"><a href="#光线追踪" class="headerlink" title="光线追踪"></a>光线追踪</h1><blockquote>    利用光线追踪算法实现逼真的渲染效果，包括反射、折射、阴影等等。这些效果需要更高的计算资源，但是可以产生非常逼真的结果。</blockquote><h2 id="相关例子"><a href="#相关例子" class="headerlink" title="相关例子"></a>相关例子</h2><h3 id="1、场景漫游：https-www-shadertoy-com-view-Xls3D2"><a href="#1、场景漫游：https-www-shadertoy-com-view-Xls3D2" class="headerlink" title="1、场景漫游：https://www.shadertoy.com/view/Xls3D2"></a>1、场景漫游：<a href="https://www.shadertoy.com/view/Xls3D2">https://www.shadertoy.com/view/Xls3D2</a></h3><h3 id="2、光学迷宫：-https-www-shadertoy-com-view-4tBGWR"><a href="#2、光学迷宫：-https-www-shadertoy-com-view-4tBGWR" class="headerlink" title="2、光学迷宫：  https://www.shadertoy.com/view/4tBGWR"></a>2、光学迷宫：  <a href="https://www.shadertoy.com/view/4tBGWR">https://www.shadertoy.com/view/4tBGWR</a></h3><h3 id="3、模拟地球：-https-www-shadertoy-com-view-4lBGD7"><a href="#3、模拟地球：-https-www-shadertoy-com-view-4lBGD7" class="headerlink" title="3、模拟地球： https://www.shadertoy.com/view/4lBGD7"></a>3、模拟地球： <a href="https://www.shadertoy.com/view/4lBGD7">https://www.shadertoy.com/view/4lBGD7</a></h3><h3 id="4、星空：-https-www-shadertoy-com-view-XlfGRj"><a href="#4、星空：-https-www-shadertoy-com-view-XlfGRj" class="headerlink" title="4、星空： https://www.shadertoy.com/view/XlfGRj"></a>4、星空： <a href="https://www.shadertoy.com/view/XlfGRj">https://www.shadertoy.com/view/XlfGRj</a></h3><h3 id="5、光影追踪："><a href="#5、光影追踪：" class="headerlink" title="5、光影追踪："></a>5、光影追踪：</h3><blockquote>    是三维计算机图形学中的特殊渲染算法，追踪光线从来源开始照射到物体上，再由物体反射的光线“路径”，由于完整运算所有路径十分消耗运算资源，因此现有光线追踪技术仅运算“目所能及”的光线路径。</blockquote><p><a href="https://www.shadertoy.com/view/4dl3zr">https://www.shadertoy.com/view/4dl3zr</a></p><h1 id="粒子系统"><a href="#粒子系统" class="headerlink" title="粒子系统"></a>粒子系统</h1><blockquote>    粒子系统是一种常见的实时渲染技术，它可以创建和模拟一组小的图形元素，例如雪花、烟雾、火焰或者星星等。这些小的图形元素被称为粒子，它们可以根据一定的规则运动、变化、互相作用，以此形成出各种形态的图案和动画。</blockquote><h2 id="相关例子-1"><a href="#相关例子-1" class="headerlink" title="相关例子"></a>相关例子</h2><p><a href="https://www.shadertoy.com/view/slSBzc">https://www.shadertoy.com/view/slSBzc</a><br><a href="https://www.shadertoy.com/view/NdjBWK">https://www.shadertoy.com/view/NdjBWK</a><br><a href="https://www.shadertoy.com/view/clB3Dt">https://www.shadertoy.com/view/clB3Dt</a></p><h1 id="光效"><a href="#光效" class="headerlink" title="光效"></a>光效</h1><blockquote>    通过模拟光的传播和反射，可以实现各种光效，包括镜面反射、折射、漫反射、环境光等等。</blockquote><h2 id="相关例子-2"><a href="#相关例子-2" class="headerlink" title="相关例子"></a>相关例子</h2><p><a href="https://www.shadertoy.com/view/4tK3Wd">https://www.shadertoy.com/view/4tK3Wd</a><br><a href="https://www.shadertoy.com/view/tsXSzn">https://www.shadertoy.com/view/tsXSzn</a><br><a href="https://www.shadertoy.com/view/Mll3WB">https://www.shadertoy.com/view/Mll3WB</a></p><h1 id="音频可视化"><a href="#音频可视化" class="headerlink" title="音频可视化"></a>音频可视化</h1><blockquote>    利用音频数据实现各种可视化效果，例如频谱分析、波形动画等等。</blockquote><h2 id="相关例子-3"><a href="#相关例子-3" class="headerlink" title="相关例子"></a>相关例子</h2><p><a href="https://www.shadertoy.com/view/ldfGWf">https://www.shadertoy.com/view/ldfGWf</a><br><a href="https://www.shadertoy.com/view/XdBGzm">https://www.shadertoy.com/view/XdBGzm</a><br><a href="https://www.shadertoy.com/view/MsBXRK">https://www.shadertoy.com/view/MsBXRK</a><br><a href="https://www.shadertoy.com/view/XdG3Wc">https://www.shadertoy.com/view/XdG3Wc</a><br><a href="https://www.shadertoy.com/view/lscXzN">https://www.shadertoy.com/view/lscXzN</a><br><a href="https://www.shadertoy.com/view/Wd23Rw">https://www.shadertoy.com/view/Wd23Rw</a></p><h1 id="图形变换"><a href="#图形变换" class="headerlink" title="图形变换"></a>图形变换</h1><blockquote>    图形变换是一种将二维或三维图形进行变形、转换、调整位置的操作。在着色器程序中，可以通过一系列的数学计算和变换操作来实现图形变换。例如，平移操作可以通过将坐标系的原点移动到不同的位置来实现；旋转操作可以通过对坐标系进行旋转变换来实现。<pre><code class="hljs">在ShaderToy中，图形变换通常与其他图形效果一起使用，例如颜色变换、光照效果、纹理映射等，从而创造出独特的视觉效果</code></pre></blockquote><h2 id="相关例子-4"><a href="#相关例子-4" class="headerlink" title="相关例子"></a>相关例子</h2><p><a href="https://www.shadertoy.com/view/4s3fDH">https://www.shadertoy.com/view/4s3fDH</a><br><a href="https://www.shadertoy.com/view/XtyfDG">https://www.shadertoy.com/view/XtyfDG</a></p><h1 id="3D效果"><a href="#3D效果" class="headerlink" title="3D效果"></a>3D效果</h1><blockquote> 通过着色器实现各种3D效果，例如球体、立方体、多边形、水面等等。</blockquote><h2 id="相关例子-5"><a href="#相关例子-5" class="headerlink" title="相关例子"></a>相关例子</h2><p><a href="https://www.shadertoy.com/view/3lsSzf">https://www.shadertoy.com/view/3lsSzf</a><br><a href="https://www.shadertoy.com/view/WsSBzh">https://www.shadertoy.com/view/WsSBzh</a><br><a href="https://www.shadertoy.com/view/ld3Gz2">https://www.shadertoy.com/view/ld3Gz2</a><br><a href="https://www.shadertoy.com/view/4sS3zG">https://www.shadertoy.com/view/4sS3zG</a></p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>shadertoy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深入GPU硬件架构及运行机制</title>
    <link href="/2023/%E6%B7%B1%E5%85%A5GPU%E7%A1%AC%E4%BB%B6%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/"/>
    <url>/2023/%E6%B7%B1%E5%85%A5GPU%E7%A1%AC%E4%BB%B6%E6%9E%B6%E6%9E%84%E5%8F%8A%E8%BF%90%E8%A1%8C%E6%9C%BA%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/timlly/p/11471507.html">这篇博客写的非常详细,做个标记，之后再读读</a></p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《我的精神家园》</title>
    <link href="/2023/%E6%88%91%E7%9A%84%E7%B2%BE%E7%A5%9E%E5%AE%B6%E5%9B%AD/"/>
    <url>/2023/%E6%88%91%E7%9A%84%E7%B2%BE%E7%A5%9E%E5%AE%B6%E5%9B%AD/</url>
    
    <content type="html"><![CDATA[<p>这本书是从去长沙和从长沙回银川的高铁上看完的。整本书说了很多那个时代的一些东西，也诙谐幽默的讲述的社会存在的一些问题。正如作者王小波本人说，他有着海外四年的经历，相比较一直在国内的人来说，一些海外华人可能比国内一些人更爱这个国家。当然看到的东西也就更加本质。因为相比较国内一些人，他们缺少很多的人际关系，不存在有人误导这种情况。因而对待问题，看待问题的眼光更加犀利。</p><p>我就简单摘抄一些我感觉好的段落，在这里分享给大家：</p><ul><li><p>井底之蛙也有一片天空              —— 引自第2页</p></li><li><p>就算是高雅的艺术，也有功力、水平之分，不可以一概而论。              —— 引自第8页</p></li><li><p>所有狂野粗俗的笑都被我咽到肚子里，结果把内脏都震成了碎片。              —— 引自第9页</p></li><li><p>太古板的人没法欣赏文艺作品，他能干的事只是扰乱别人。              —— 引自第25页</p></li><li><p>莫泊桑曾说，提笔为文，就想到了读者。有些读者说：请让我笑吧。有些读者说：请让我哭吧。有些读者说：请让我感动吧。….。在中国，有些读者会说，请让我受教育吧。              —— 引自第47页（我对国产片的看法）</p></li><li><p>海明威在《钟为谁鸣》里说过这个意思：所有的人是一个整体，别人的不幸就是你的不幸。所以，不要以为丧钟是为谁而鸣——它就是为你而鸣。  —— 引自第56页（从Internet说起）</p></li><li><p>直到现在，中国还是世界上少数几个没有政治漫画的国家。于是，幽默在这个国家就成了高深莫测的学问。                —— 引自第62页（外国电影里的幽默）</p></li><li><p>青年人的动人之处，就在于勇气，和他们的远大前程。                        —— 引自第106页（卖唱的人们）</p></li><li><p>我对国学的看法是：这种东西实在厉害。最可怕之处就在那个“国”字。顶着这个字，谁还敢有不同意见？这种套子套上脖子，想把它再扯下来是枉然的；否则也不至于套了好几千年。它的诱人之处也在这个“国”字，抢到这个制高点，就可以压制一切不同意见；所以它对一切想在思想领域里巧取豪夺的不良分子都有莫大的诱惑力。你说它是史学也好，哲学也罢，我都不反对——倘若此文对正经史学家哲学家有了得罪之处，我深表歉意——但你不该否认它有成为棍子的潜力。想当年，像姚文元之类的思想流氓拿阶级斗争当棍子，打死打伤了无数人。现在有人又在造一根漂亮棍子。它实在太漂亮了，简直是完美无缺。我怀疑除了落进思想流氓手中变成一种凶器之外，它还能有什么用场。鉴于有这种危险，我建议大家都不要做上帝梦，也别做圣人梦，以免头上鲜血淋漓。              —— 引自第111页</p></li><li><p><strong>中国有五千年的文明史，这部历史有一半写在故纸上，还有一半埋在地下，只是缺少了一部立在地上的历史，可以供人在其中漫步。</strong>我小的时候，北京不但有城墙，还有很多古老的院子一我在教育部院里住过很久，那地方是原来的郑王府，在很长时间里保持了王府的旧貌，屋檐下住满了燕子。傍晚时分，燕子在那里表演着令人惊讶的飞行术：它以闪电般的速度俯冲下来，猛地一抬头，收起翅膀，不差毫厘地进椽子中间一个小洞里。一二百年前，郑王府里的一位宫女也能看到这种景象，并且对燕子的飞行技巧感到诧异一能见到古人所见，感到古人所感，这种感觉就是历史感。很遗憾的是，现在北京城里盖满了高楼，燕子找不着自己住过的屋檐，所以也很少能看到了。现在的年轻人读到“似曾相识燕归来”，大概也读不懂了。所幸的是，北京还有故宮，还有顾和园。但是没有了城墙，没有了燕子，总是一种缺憾。                  —— 引自第116页（北京风情）</p></li><li><p>但中国忽视个人尊严，却不是我的新发现。从大智者到通俗作家，有不少人注意到一个有中国特色的现象。罗素说，中国文化里只重家族内的私德，不重社会的公德公益，这一点造成了很要命的景象。费孝通说，中国社会里有所谓的“差序格局”，与己关系近的就关心，关系远的就不关心或者少关心；结果有些事从来就没人关心。……人有无尊严，有一个简单的判据，是看他被当作一个人还是一个东西来看待。这件事有点两重性，其一是别人把你当做人还是东西，是你尊严之所在。其二是你把自己看成人还是东西，也是你的尊严所在。挤公交和上公共厕所时，人只被当身体看待。这里既有其一的成分，也有其二的成分；而且归根结蒂，和我们的文化传统有关。说来也奇怪，中华礼仪之邦，一切尊严，都从整体和人与人的关系上定义，就是没有个人的位置。           —— 引自第125页（个人尊严）</p></li><li><p>中国这地方有一种特别之处，那就是人只在家里（现在还要加上在单位里）负责任，出了门就没有了责任感（罗素和费孝通对此都有过论述，谁有兴趣可以去查阅）。大家所到之处，既无权利，也无义务；所有的公利公德，全靠政府去管，但政府不可能处处管到，所以到处乱糟糟。一个人在单位是老张或老李，回了家是爸爸或妈妈，在这两处都要顾及体面和自己的价值，这是很好的；但在家门外和单位门外就什么都不是，被称做“那男的”或是“那女的”，一点尊严也没有，这就很糟糕。我总觉得，大多数人在受到重视之后，行为就会好。               —— 引自第137页（居住环境与尊严）</p></li><li><p>但我确实感受到了，假如别人都不尊重我，我也没法尊重别人。假如所有的人都一直斜眼看我，粗声粗气地说我，那我的确什么事都干得出来。  —— 引自第139页（饮食卫生与尊严）</p></li><li><p>看到几个“外地来京人员”拿自来水和脏东西兑假酱油，为之发指。觉得不但国家该去法办这些人，我也该去碎他们一口。但想想人家住在什么地方，受到什么样的对待，又有点理不直气不壮。—— 引自第140页（饮食卫生与尊严）</p></li><li><p>当我跨过沉沦的一切，向着永恒开战的时候，你是我的军旗。                 —— 引自第182页（附录一  诗人之爱）</p></li><li><p>人需要思想，如同需要空气和水一样。…。没有这个，人就要沉沦得和畜生一样了。   —— 引自第187页（附录一  诗人之爱）</p></li><li><p>说真的，我喜欢你的热情，你可以温暖我。我很讨厌我自己不温不凉的思虑过度，也许我是个坏人，不过我只要你吻我一下就会变好呢。  —— 引自第198页（附录一  诗人之爱）</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>读一本好书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>《我的精神家园》</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《人民的名义》</title>
    <link href="/2023/%E4%BA%BA%E6%B0%91%E7%9A%84%E5%90%8D%E4%B9%89/"/>
    <url>/2023/%E4%BA%BA%E6%B0%91%E7%9A%84%E5%90%8D%E4%B9%89/</url>
    
    <content type="html"><![CDATA[<p>这是一部拍摄于2017年的一部反腐倡廉电视剧。早期对于这类电视剧并不是特别感冒，所以一直到2020年左右才看了这部剧。按照网上讨论的那样，这部剧删减很严重，根据我观看之后的感触，就是删减后已经这么大胆了，那没删减版本该是多么大胆。应该也就是这份大胆，这部剧也没有第二部，甚至都没有重播的机会。这可真是一个值得讨论的问题？</p><p>这几天晚上不想玩手机了，想着听书也是一种不错的想法。但是好书有很多，一时不知道该选择那一本了。但是打开听书软件，第一眼就看到这本书《人民的名义》。想着电视剧删减了很多，书本里他总该没删减吧，索性听一听。从书本里才真正了解了电视剧里一些人，以及他们的内心活动。网上很多人拿李达康来与山西前任市长耿彦波做比较，其实我觉得两者根本没有可比较的地方。一个极其爱惜自己的政治羽毛，脏活累活都是手下干，自己一点污迹不沾身；一个则是实心实意的为城市发展做贡献（大家可以看看<a href="https://www.youtube.com/watch?v=jQIzQyTKbRk">《中国市长》</a>这部记录片）。想起剧中李威饰演的光明区区长孙连城怒怼李达康的一段话（剧中删减，书本中没有这段）</p><blockquote>    因为沙书记暗访光明区信访办，看到了信访办低矮的窗口，李达康面红耳赤，连夜组织京洲市懒政干部学习班，并视频向省委直播。当着众多干部的面，拿光明区副区长孙连城做典型，冷嘲热讽。“我们这个孙连城区长，在区长的位置上毫不作为，混吃等死，最大的爱好是看星星……”孙连城毕竟也是50多岁的人了，哪里受得了这种屈辱。当场拍桌子站起来，怒斥李达康。孙连城：“李达康！我忍你很久了，你不要欺人太甚！”李达康先是一愣，没想到老实巴交的孙连城居然会反击，但很快就镇定下来，呵呵一笑，问：“哎呦，你还有委屈了？那你说说吧。”孙连城：“你说我不作为，不就是因为我没给新大风厂解决工业用地问题么？陈岩石给你告状去了。新大风厂要20亩工业用地，光明区能卖的地都让丁义诊给卖的一干二净，你为了讨好陈岩石，嘴上说的轻松，可我上哪给他们搞20亩工业用地？你让我怎么作为？就算光明区有地，那他们有钱么？一分钱都没有，你说说这地怎么批？就他们那些个下岗职工，乌合之众，哪家银行愿意给他们贷款？还有那个信访办的窗口，改不得花钱么？区财政刚刚给大风厂垫了1000万，哪还有钱了？我自费花60元买4个小椅子先顶一顶怎么了？怎么就不作为了？老百姓坐小椅子委屈了？再说了，那信访办也不是一天两天了，丁义诊在的时候，你怎么没发现？他一跑，你就看见了？早你干吗去了？”李达康被问的哑口无言，孙连城丝毫没有停下来的意思，继续说：“你李达康说我不作为，那么你呢？你任用丁义诊主持光明峰项目，他吃拿卡要，胡作非为，勾结开发商，随意把工业用地改成商业用地？你身为一把手，当真一点都不知道？丁义诊出事之前，群众举报就没断过，你为了政绩，充耳不闻。丁义诊出逃了，你却毫发无伤，你这叫有作为？”李达康嘴唇颤抖地说：“在丁义诊这件事上，我用人不察，我失职，我道歉。”孙连城：“得了吧，达康书记，你承担什么责任了？降职了？还是处分了？连罚酒三杯都没有，要是道歉有用的话，还要纪委干啥？”“说完丁义诊，再说说你前妻欧阳菁，你前妻身为银行行长，放贷吃回扣，你一丁点都不知道？她出事当天，你俩火线离婚，怎么就那么巧呢？你前妻走哪都拎着好几万的名牌包，你这么些年一点都没觉察？就算你不知道她受贿，那你孩子在美国念书的学费和生活费是哪来的？你知不知道？你是真不知道，还是装不知道？你连自己老婆孩子都管不了，你还有脸说我不作为？”李达康气得浑身颤抖，一拍桌子，大喊：“你要是觉得我李达康有问题就去纪委举报我！今天是讨论的是懒政，就事论事，你扯欧阳菁干什么？”孙连城微微一笑：“好，咱们就事论事，你说我懒政，我孙连城在光明区一干就是二十年，我懒政？光明区为什么**全市第一？为什么大风厂一块地就价值十几亿？这就是我懒政的结果么？我兢兢业业二十年，连个区委书记都不让我当，谁不知道咋回事啊？你达康书记是赵立春的大秘，祁同伟是梁群峰老书记的女婿，你们都是有政治资源的人，跟坐着火箭似的嗖嗖往上升，我孙连城在光明区一干二十年，连个区委书记都升不上去，不就是因为我没有政治资源么？我连那个大贪官丁义诊都不如，讽刺啊。对了，丁义诊出事之前带着一群干部，天天往山水庄园跑，都快把那当干部食堂了，你李达康能不知道？怎么没见你有一丁点作为呢？你是不是懒政？”李达康指着孙连城大喊：“闭嘴，再胡闹我开除你党籍！”孙连城毫不示弱：“我违纪了么？你凭什么说开除就开除？你以为党是你家的啊？你在这吓唬谁俩呢？李达康，我等着你开除我党籍！”</blockquote>从这里其实我们已经可以看到李达康是一个什么样的人了。<p>这部剧其实也揭示了反腐的力度与强度，<strong>反腐无禁区无上限</strong>。整部书听下来，明白了很多，也懂了很多。还是一部值得看的书。当然电视剧里人物塑造更加立体，推荐看完电视剧（希望你还能找到资源）再看书。</p>]]></content>
    
    
    <categories>
      
      <category>读一本好书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>人民的名义</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>gaussian噪声</title>
    <link href="/2023/gaussian%E5%99%AA%E5%A3%B0/"/>
    <url>/2023/gaussian%E5%99%AA%E5%A3%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a>高斯噪声</h2><p>高斯噪声（Gaussian noise）是一种具有正态分布（也称作高斯分布）概率密度函数的噪声。换句话说，高斯噪声的值遵循高斯分布或者它在各个频率分量上的能量具有高斯分布。它被极其普遍地应用为用以产生加成性高斯白噪声（AWGN）的迭代白噪声。<br>其公式如下：<br>$p_G(z)&#x3D;\frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{(z-\mu)^2}{2 \sigma^2}}$ </p><p>式中：z表示灰度级图像；$\mu$表示平均灰度值；$\sigma$表示标准差。</p><p>python Code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">my_gaussian</span>(<span class="hljs-params">img, sigma</span>):<br>    <span class="hljs-comment"># fig = plt.figure(figsize=(1,1), dpi=300)</span><br>    <span class="hljs-comment"># 生成高斯噪声</span><br>    H, W = img.shape<br>    noise = np.random.randn(H,W)<br>    gaussian_noises = np.sqrt(<span class="hljs-number">2</span>*math.pi*sigma**<span class="hljs-number">2</span>)*np.exp((-(noise-np.mean(noise))**<span class="hljs-number">2</span>)/(<span class="hljs-number">2</span>*sigma**<span class="hljs-number">2</span>))<br>    <span class="hljs-comment"># 为图像添加高斯噪声</span><br>    img = img /<span class="hljs-number">255</span><br>    gaussian_out = img + gaussian_noises<br>    gaussian_out = np.clip(gaussian_out,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>)<br>    gaussian_out = np.uint8(gaussian_out*<span class="hljs-number">255</span>)<br>    <span class="hljs-keyword">return</span>  gaussian_out, gaussian_noises<br>    <span class="hljs-comment"># sub = fig.add_subplot(111)</span><br>    <span class="hljs-comment"># sub.imshow(gaussian_n, cmap=&#x27;gray&#x27;)</span><br>    <span class="hljs-comment"># plt.show()</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">gaussian_noise</span>(<span class="hljs-params">img, mean, sigma</span>):<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    此函数用将产生的高斯噪声加到图片上</span><br><span class="hljs-string">    传入:</span><br><span class="hljs-string">        img   :  原图</span><br><span class="hljs-string">        mean  :  均值</span><br><span class="hljs-string">        sigma :  标准差</span><br><span class="hljs-string">    返回:</span><br><span class="hljs-string">        gaussian_out : 噪声处理后的图片</span><br><span class="hljs-string">        noise        : 对应的噪声</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-comment"># 将图片灰度标准化</span><br>    img = img / <span class="hljs-number">255</span><br>    <span class="hljs-comment"># 产生高斯 noise</span><br>    noise = np.random.normal(mean, sigma, img.shape)<br>    <span class="hljs-comment"># 将噪声和图片叠加</span><br>    gaussian_out = img + noise<br>    <span class="hljs-comment"># 将超过 1 的置 1，低于 0 的置 0</span><br>    gaussian_out = np.clip(gaussian_out, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)<br>    <span class="hljs-comment"># 将图片灰度范围的恢复为 0-255</span><br>    gaussian_out = np.uint8(gaussian_out*<span class="hljs-number">255</span>)<br>    <span class="hljs-comment"># 将噪声范围搞为 0-255</span><br>    <span class="hljs-comment"># noise = np.uint8(noise*255)</span><br>    <span class="hljs-keyword">return</span> gaussian_out, noise <span class="hljs-comment"># 这里也会返回噪声，注意返回值</span><br><br><br><span class="hljs-keyword">if</span> __name__==<span class="hljs-string">&quot;__main__&quot;</span>:<br><br>    <span class="hljs-comment"># 读取图片</span><br>    src = cv2.imread(<span class="hljs-string">&#x27;img.png&#x27;</span>, <span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># 创建绘图 figure</span><br>    fig_out = plt.figure(figsize=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>), dpi=<span class="hljs-number">370</span>) <span class="hljs-comment"># figsize宽高比</span><br>    fig_noise = plt.figure(figsize=(<span class="hljs-number">4</span>, <span class="hljs-number">2</span>), dpi=<span class="hljs-number">370</span>)<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-number">8</span>):<br><br>        <span class="hljs-comment"># 将图片和不同的噪声叠加</span><br>        <span class="hljs-comment"># gaussian_out, noise = gaussian_noise(src, 0, 0.03*i)</span><br>        gaussian_out, noise = my_gaussian(src, <span class="hljs-number">0.03</span>*i)  <span class="hljs-comment"># RuntimeWarning需要优化</span><br>        <span class="hljs-comment"># 创建 AxesSubplot 对象</span><br>        ax_out = fig_out.add_subplot(i+<span class="hljs-number">241</span>)<br>        ax_noise = fig_noise.add_subplot(i+<span class="hljs-number">241</span>)<br>        <span class="hljs-comment"># 将丑兮兮的坐标抽去掉</span><br>        ax_out.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>        ax_noise.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>        <span class="hljs-comment"># 设置标题</span><br>        ax_out.set_title(<span class="hljs-string">&#x27;$\sigma$ = &#x27;</span>+<span class="hljs-built_in">str</span>(<span class="hljs-number">0.03</span>*i), loc=<span class="hljs-string">&#x27;left&#x27;</span>, fontsize=<span class="hljs-number">3</span>, fontstyle=<span class="hljs-string">&#x27;italic&#x27;</span>)<br>        ax_noise.set_title(<span class="hljs-string">&#x27;$\sigma$ = &#x27;</span>+<span class="hljs-built_in">str</span>(<span class="hljs-number">0.03</span>*i), loc=<span class="hljs-string">&#x27;left&#x27;</span>, fontsize=<span class="hljs-number">3</span>, fontstyle=<span class="hljs-string">&#x27;italic&#x27;</span>)<br>        <span class="hljs-comment"># 图片展示</span><br>        ax_out.imshow(gaussian_out, cmap=<span class="hljs-string">&#x27;gray&#x27;</span>)<br>        ax_noise.imshow((noise+<span class="hljs-number">1</span>)/<span class="hljs-number">2</span>, cmap=<span class="hljs-string">&#x27;gray&#x27;</span>)<br><br><br>    <span class="hljs-comment"># 保存图片</span><br>    fig_out.savefig(<span class="hljs-string">&#x27;1_Peppers_noise.png&#x27;</span>)<br>    fig_noise.savefig(<span class="hljs-string">&#x27;1_Guassion_noise.png&#x27;</span>)<br>    <span class="hljs-comment"># 图片显示</span><br>    plt.show()<br></code></pre></td></tr></table></figure><p>result:</p><img src="/2023/gaussian%E5%99%AA%E5%A3%B0/1_Guassion_noise.png" class=""><img src="/2023/gaussian%E5%99%AA%E5%A3%B0/1_Peppers_noise.png" class="">]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>gaussian噪声</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Perlin噪声</title>
    <link href="/2023/Perlin%E5%99%AA%E5%A3%B0/"/>
    <url>/2023/Perlin%E5%99%AA%E5%A3%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="perlin基本信息"><a href="#perlin基本信息" class="headerlink" title="perlin基本信息"></a>perlin基本信息</h2><p>Perlin噪声（Perlin noise，又称为柏林噪声）指由Ken Perlin发明的<strong>自然噪声生成算法</strong>，具有在函数上的连续性，并可在多次调用时给出一致的数值。 在电子游戏领域中可以透过使用Perlin噪声生成具连续性的地形；或是在艺术领域中使用Perlin噪声生成图样。</p><p>由于一些历史原因，Simplex噪声和分形噪声（texture synthesis）都曾在学术论文中被单独称作Perlin噪声。</p><h2 id="经典Perlin噪声"><a href="#经典Perlin噪声" class="headerlink" title="经典Perlin噪声"></a>经典Perlin噪声</h2><p>perlin噪声是基于晶格的方法。它属于梯度噪声，其原理就是将坐标系划分成一块一块的晶格，之后在晶格的顶点出生成一个随机梯度，通过与晶格顶点到晶格内点的向量进行点乘加权计算后得到噪声。<br><img src="/2023/Perlin%E5%99%AA%E5%A3%B0/1.jpg"></p><h3 id="实现perlin噪声的过程需要插值"><a href="#实现perlin噪声的过程需要插值" class="headerlink" title="实现perlin噪声的过程需要插值"></a>实现perlin噪声的过程需要插值</h3><ul><li>对于一维：插值使用的是一个在0处为1，在1处为0，在0.5处为0.5的连续单调递减函数。例如对，设$c_{0}$,$c_{1}$为左右两个整数点的数值，t为该点距离左边点的距离，使用$(1-t)$作为插值函数，则该点的值为$c_{1}(1-t)+c_{0}t$。<p><img src="/2023/Perlin噪声/2.jpg" height=50% width="50%"></p><!-- ![](/2023/Perlin噪声/2.jpg) -->但是$(1-t)$是线性插值，人工痕迹比较严重，并且在整数点上不连续。Perlin建议使用$3t^{2}-2t^{3}$作为插值函数。后来建议使用$6t^{5}-15t^{4}+10t^{3}$作为插值函数。事实上，只有在区间[0,1]内的连续函数$f$，有$f(0)=1,f(1)=0$且$f^{`}(0)=f^{`}(1)=0$的函数皆可作为插值函数。</li><li>对于二维：对于点$(x,y)$，令$i&#x3D;\lfloor x \rfloor,j&#x3D;\lfloor y \rfloor$，它所在的晶格的四个顶点分别为$(i,j)、(i+1,j)、(i+1,j+1)、(i,j+1)$。令$u&#x3D;x-i,v&#x3D;y-j$，这四个顶点对点$(x,y)$的贡献可以使用它们的梯度$(g_{00},g_{10},g_{11},g_{01})$和$(x,y)$点与这四个顶点的方向$((u,v),(u-1,v),(u-1,v-1),(u,v-1))$进行点积获得。但是在二维的情况下，插值更为复杂。首先需要对 $(i,j)$ 和$(i+1,j)$ 两点在$x$方向插值，得到点$(x,j)$的值；之后对$(i,j+1)$ 和 $(i+1,j+1)$两点在$x$方向插值，得到点$(x,j+1)$的值；最后对$(x,j)$和$(x,j+1)$ 在$y$方向插值，得到$(x, y)$的值。<p><img src="/2023/Perlin噪声/3.jpg" height=50% width="50%"></p></li></ul><h2 id="code"><a href="#code" class="headerlink" title="code"></a>code</h2><p><a href="https://github.com/DreamOneYou/Perline">完整代码</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">interpolant</span>(<span class="hljs-params">t</span>):<br>    <span class="hljs-keyword">return</span> t*t*t*(t*(t*<span class="hljs-number">6</span> - <span class="hljs-number">15</span>) + <span class="hljs-number">10</span>)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_perlin_noise_2d</span>(<span class="hljs-params"></span><br><span class="hljs-params">        shape, res, tileable=(<span class="hljs-params"><span class="hljs-literal">False</span>, <span class="hljs-literal">False</span></span>), interpolant=interpolant</span><br><span class="hljs-params"></span>):<br>    delta = (res[<span class="hljs-number">0</span>] / shape[<span class="hljs-number">0</span>], res[<span class="hljs-number">1</span>] / shape[<span class="hljs-number">1</span>])<br>    d = (shape[<span class="hljs-number">0</span>] // res[<span class="hljs-number">0</span>], shape[<span class="hljs-number">1</span>] // res[<span class="hljs-number">1</span>])<br>    grid = np.mgrid[<span class="hljs-number">0</span>:res[<span class="hljs-number">0</span>]:delta[<span class="hljs-number">0</span>], <span class="hljs-number">0</span>:res[<span class="hljs-number">1</span>]:delta[<span class="hljs-number">1</span>]]\<br>             .transpose(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>) % <span class="hljs-number">1</span><br>    <span class="hljs-comment"># Gradients</span><br>    angles = <span class="hljs-number">2</span>*np.pi*np.random.rand(res[<span class="hljs-number">0</span>]+<span class="hljs-number">1</span>, res[<span class="hljs-number">1</span>]+<span class="hljs-number">1</span>)<br>    gradients = np.dstack((np.cos(angles), np.sin(angles)))<br>    <span class="hljs-keyword">if</span> tileable[<span class="hljs-number">0</span>]:<br>        gradients[-<span class="hljs-number">1</span>,:] = gradients[<span class="hljs-number">0</span>,:]<br>    <span class="hljs-keyword">if</span> tileable[<span class="hljs-number">1</span>]:<br>        gradients[:,-<span class="hljs-number">1</span>] = gradients[:,<span class="hljs-number">0</span>]<br>    gradients = gradients.repeat(d[<span class="hljs-number">0</span>], <span class="hljs-number">0</span>).repeat(d[<span class="hljs-number">1</span>], <span class="hljs-number">1</span>)<br>    g00 = gradients[    :-d[<span class="hljs-number">0</span>],    :-d[<span class="hljs-number">1</span>]]<br>    g10 = gradients[d[<span class="hljs-number">0</span>]:     ,    :-d[<span class="hljs-number">1</span>]]<br>    g01 = gradients[    :-d[<span class="hljs-number">0</span>],d[<span class="hljs-number">1</span>]:     ]<br>    g11 = gradients[d[<span class="hljs-number">0</span>]:     ,d[<span class="hljs-number">1</span>]:     ]<br>    <span class="hljs-comment"># Ramps</span><br>    n00 = np.<span class="hljs-built_in">sum</span>(np.dstack((grid[:,:,<span class="hljs-number">0</span>]  , grid[:,:,<span class="hljs-number">1</span>]  )) * g00, <span class="hljs-number">2</span>)<br>    n10 = np.<span class="hljs-built_in">sum</span>(np.dstack((grid[:,:,<span class="hljs-number">0</span>]-<span class="hljs-number">1</span>, grid[:,:,<span class="hljs-number">1</span>]  )) * g10, <span class="hljs-number">2</span>)<br>    n01 = np.<span class="hljs-built_in">sum</span>(np.dstack((grid[:,:,<span class="hljs-number">0</span>]  , grid[:,:,<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>)) * g01, <span class="hljs-number">2</span>)<br>    n11 = np.<span class="hljs-built_in">sum</span>(np.dstack((grid[:,:,<span class="hljs-number">0</span>]-<span class="hljs-number">1</span>, grid[:,:,<span class="hljs-number">1</span>]-<span class="hljs-number">1</span>)) * g11, <span class="hljs-number">2</span>)<br>    <span class="hljs-comment"># Interpolation</span><br>    t = interpolant(grid)<br>    c0 = n00*(<span class="hljs-number">1</span>-t[:,:,<span class="hljs-number">0</span>]) + t[:,:,<span class="hljs-number">0</span>]*n10<br>    c1 = n01*(<span class="hljs-number">1</span>-t[:,:,<span class="hljs-number">0</span>]) + t[:,:,<span class="hljs-number">0</span>]*n11<br>    <span class="hljs-keyword">return</span> np.sqrt(<span class="hljs-number">2</span>)*((<span class="hljs-number">1</span>-t[:,:,<span class="hljs-number">1</span>])*c0 + t[:,:,<span class="hljs-number">1</span>]*c1)<br></code></pre></td></tr></table></figure><h2 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h2><ul><li>Perlin 2D噪声 <img src="/2023/Perlin%E5%99%AA%E5%A3%B0/generate_fractal_noise_2d.png"></li><li>给人物图像添加perlin噪声<table><tr><td><img src="/2023/Perlin噪声/people.jpg" border=0 width=400px height=400px></td><td><img src="/2023/Perlin噪声/img_perin.png" border=0 width=400px height=400px></td></tr></table><!-- ![](/2023/Perlin噪声/people.jpg)![](/2023/Perlin噪声/img_perin.png) --></li><li>3D perline噪声<br><img src="/2023/Perlin%E5%99%AA%E5%A3%B0/Fractal_perlin_3D.gif"></li></ul>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>噪声</tag>
      
      <tag>perlin</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>毛泽东选集</title>
    <link href="/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/"/>
    <url>/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<br><img src="/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/1.jpg" class="" title="image1">&emsp;<img src="/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/2.jpg" class="" title="image2">&nbsp;<img src="/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/3.jpg" class="" title="image3">&nbsp;<img src="/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/4.jpg" class="" title="image4"> &nbsp;<img src="/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/5.jpg" class="" title="image5"> &nbsp;<img src="/2023/%E6%AF%9B%E6%B3%BD%E4%B8%9C%E9%80%89%E9%9B%86/6.jpg" class="" title="image6">]]></content>
    
    
    <categories>
      
      <category>读一本好书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>毛泽东选集</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《青铜时代》</title>
    <link href="/2023/%E9%9D%92%E9%93%9C%E6%97%B6%E4%BB%A3/"/>
    <url>/2023/%E9%9D%92%E9%93%9C%E6%97%B6%E4%BB%A3/</url>
    
    <content type="html"><![CDATA[<h2>这世界上之所有会有无主的东西，就是因为有人失去了记忆  --万寿寺-第一章</h2>]]></content>
    
    
    <categories>
      
      <category>读一本好书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>青铜时代</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客园迁移hexo博客</title>
    <link href="/2023/image/"/>
    <url>/2023/image/</url>
    
    <content type="html"><![CDATA[<p>相关代码来自<a href="https://xie.infoq.cn/article/2b77c142f8753e30218230879">这里</a>。</p><h2 id="迁移步骤"><a href="#迁移步骤" class="headerlink" title="迁移步骤"></a>迁移步骤</h2><p>1、登录这个<a href="https://i1.cnblogs.com/BlogBackup.aspx">地址下载</a>xml博客备份文件。因为当前博客园后台备份是.db文件格式。没法用上面那个代码。ps：那个链接只能在规定时间备份。如果这个链接不能用了，那你需要联系博客园客服（我发邮件问的），问他有什么方式可以下载xml博客备份文件不。<br>2、首先使用：<code>main.py</code>,，当然你需要将你的xml文件名称改一下。代码中写的是 <code>backup.xml</code>。<br>3、然后使用:<code>image.py</code>，下载你博客里的图片。这里可能会出现下载失败的问题，那很有可能是你的开了VPN了。ps：我不会告诉你我就是开了vpn，导致下载不下来。<br>4、 用正则表达式替换图片的网址链接，我使用的visual studio code。<br>正则表达式：</p><pre><code class="hljs">1）https://img2020.cnblogs.com/blog/(.*?)/(.*?)/2）https://images2020.cnblogs.com/blog/(.*?)/(.*?)/3）https://img.*.cnblogs.com/blog/(.*?)/(.*?)/</code></pre><p>选择合适的一个替换为：<code>/2023/image/ </code><br>至于为什么替换为 <code>/2023/image/ </code>。因为我看了一下编译之后的<code>public</code>文件夹，发现图片都在<code>public/2023/image</code>这个目录里。</p><p>5、由于我不想把<code>image</code>目录下的图片放到<strong>Fluid</strong>主题下的img里面，因此我在博客里面，即<code>source/_posts/image</code>创建了image文件夹，将所有迁移过来的图片放在了这个下面，但是要想页面顺利链接上图片，你还需要执行这个<a href="https://opencc.icu/2023/hexo%E5%9B%BE%E7%89%87%E7%AE%A1%E7%90%86/">操作</a>。<br>6、由于迁移过来之后，tags和categories类型都变为一个，所以很不幸，你只能一个文件一个文件的修改为你认为对的标签和分类。如果有自动化实现，希望评论区各位大佬基于意见。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>博客迁移</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图片素材</title>
    <link href="/2023/%E5%9B%BE%E7%89%87%E7%B4%A0%E6%9D%90/"/>
    <url>/2023/%E5%9B%BE%E7%89%87%E7%B4%A0%E6%9D%90/</url>
    
    <content type="html"><![CDATA[<p>最新发现一些图片网址，简单整理了一。都是可以免费下载的奥，赶紧记录下来吧。以后桌面不怕没好看的图片了。</p><h3 id="pixabay"><a href="#pixabay" class="headerlink" title="pixabay"></a><a href="https://pixabay.com/">pixabay</a></h3><p>供高清图片、高清文艺类图片、高清视频。<strong>我比较喜欢用这个</strong></p><h2 id="pexels、unsplash"><a href="#pexels、unsplash" class="headerlink" title="pexels、unsplash"></a><a href="https://www.pexels.com/zh-cn/">pexels</a>、<a href="https://unsplash.com/">unsplash</a></h2><p>人物图、风景图、城市风光、乡村图片</p><h3 id="stocksnap、streetwill"><a href="#stocksnap、streetwill" class="headerlink" title="stocksnap、streetwill"></a><a href="https://stocksnap.io/">stocksnap</a>、<a href="http://streetwill.co/">streetwill</a></h3><p>高清摄影类图片</p><h3 id="gratisography"><a href="#gratisography" class="headerlink" title="gratisography"></a><a href="https://gratisography.com/">gratisography</a></h3><p>创意图片，有的是经过ps处理后的成品。</p><h3 id="textures"><a href="#textures" class="headerlink" title="textures"></a><a href="https://www.textures.com/">textures</a></h3><p>高清材质类图片、物体（动物、生物、植物、建筑等等）表面图片、纹理图像、三维立体图像（几何、实物等类型）。</p>]]></content>
    
    
    <categories>
      
      <category>图册</category>
      
    </categories>
    
    
    <tags>
      
      <tag>免费图片素材</tag>
      
      <tag>高清</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>argmax经过sigmoid和不经过sigmoid区别</title>
    <link href="/2023/argmax%E7%BB%8F%E8%BF%87sigmoid%E5%92%8C%E4%B8%8D%E7%BB%8F%E8%BF%87sigmoid%E5%8C%BA%E5%88%AB/"/>
    <url>/2023/argmax%E7%BB%8F%E8%BF%87sigmoid%E5%92%8C%E4%B8%8D%E7%BB%8F%E8%BF%87sigmoid%E5%8C%BA%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h2 id="起因"><a href="#起因" class="headerlink" title="起因"></a>起因</h2><p>今天和同组讨论了一下网络输出时，在torch.argmax之前经过torch.sigmoid和不经过sigmoid的区别。<br>主要起因是实验结果图像不同</p><!-- * **不经过sigmoid**  --><div align=center><img src="/2023/argmax%E7%BB%8F%E8%BF%87sigmoid%E5%92%8C%E4%B8%8D%E7%BB%8F%E8%BF%87sigmoid%E5%8C%BA%E5%88%AB/%E4%B8%8D%E7%BB%8F%E8%BF%87sigmoid.png" class="" title="不经过sigmoid"><p><font>图1 不经过sigmoid</font></p><img src="/2023/argmax%E7%BB%8F%E8%BF%87sigmoid%E5%92%8C%E4%B8%8D%E7%BB%8F%E8%BF%87sigmoid%E5%8C%BA%E5%88%AB/%E7%BB%8F%E8%BF%87sigmoid.png" class="" title="不经过sigmoid"><p><font>图2 经过sigmoid</font></p></div><p>我们发现经过sigmoid预测的图像更加严格（实验结果证明，经过sigmoid效果好），会将一些<code>不经过sigmoid</code>预测的前景分为背景。</p><h2 id="简单实现"><a href="#简单实现" class="headerlink" title="简单实现"></a>简单实现</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding:utf-8</span><br><span class="hljs-keyword">import</span> torch<br>a = torch.tensor([<br>    [[<span class="hljs-number">8.0</span>,<span class="hljs-number">5.0</span>,-<span class="hljs-number">20000.0</span>],[<span class="hljs-number">4.0</span>,<span class="hljs-number">1.0</span>,<span class="hljs-number">2.0</span>],[<span class="hljs-number">1.0</span>,<span class="hljs-number">6.0</span>,<span class="hljs-number">7.0</span>]],<br>    [[-<span class="hljs-number">6.0</span>,<span class="hljs-number">11.0</span>,-<span class="hljs-number">20000.0</span>],[<span class="hljs-number">5.0</span>,<span class="hljs-number">7.0</span>,<span class="hljs-number">9.0</span>],[<span class="hljs-number">8.0</span>,<span class="hljs-number">9.0</span>,<span class="hljs-number">10.0</span>]],<br>    [[-<span class="hljs-number">6.0</span>,<span class="hljs-number">10.0</span>,-<span class="hljs-number">20001.0</span>],[<span class="hljs-number">5.0</span>,<span class="hljs-number">7.0</span>,<span class="hljs-number">9.0</span>],[<span class="hljs-number">8.0</span>,<span class="hljs-number">9.0</span>,<span class="hljs-number">10.0</span>]]<br>])<br>b = torch.argmax(a,dim=<span class="hljs-number">0</span>)<br>d = torch.sigmoid(a)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;as:\n&quot;</span>,d)<br>ds = torch.argmax(d,dim=<span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;没经过sig:\n&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(b))<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;经过sig:\n&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(ds))<br></code></pre></td></tr></table></figure><ul><li>结果<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs lua">as:<br> tensor(<span class="hljs-string">[[[0.9997, 0.9933, 0.0000],</span><br><span class="hljs-string">         [0.9820, 0.7311, 0.8808],</span><br><span class="hljs-string">         [0.7311, 0.9975, 0.9991]]</span>,<br><br>        <span class="hljs-string">[[0.0025, 1.0000, 0.0000],</span><br><span class="hljs-string">         [0.9933, 0.9991, 0.9999],</span><br><span class="hljs-string">         [0.9997, 0.9999, 1.0000]]</span>,<br><br>        <span class="hljs-string">[[0.0025, 1.0000, 0.0000],</span><br><span class="hljs-string">         [0.9933, 0.9991, 0.9999],</span><br><span class="hljs-string">         [0.9997, 0.9999, 1.0000]]</span>])<br></code></pre></td></tr></table></figure><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs lua">没经过sig:<br>tensor(<span class="hljs-string">[[0, 1, 1],</span><br><span class="hljs-string">        [2, 2, 2],</span><br><span class="hljs-string">        [2, 2, 2]]</span>)<br>经过sig:<br>tensor(<span class="hljs-string">[[0, 1, 2],</span><br><span class="hljs-string">        [2, 2, 2],</span><br><span class="hljs-string">        [2, 2, 2]]</span>)<br></code></pre></td></tr></table></figure></li><li>我们可以发现其中-20000.0，-20000.0，-20001.0分别出现在第1,2,3通道上。但是由于经过sigmoid,我们看到<strong>as</strong>结果都为0，所以导致我们最终argmax最大索引到2通道。但是如果我们不经过sigmoid，发现argmax最大索引是1。这也就证实了上面两张预测图为什么会不一样。</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>深度学习</tag>
      
      <tag>argmax</tag>
      
      <tag>sigmoid</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo图片管理</title>
    <link href="/2023/hexo%E5%9B%BE%E7%89%87%E7%AE%A1%E7%90%86/"/>
    <url>/2023/hexo%E5%9B%BE%E7%89%87%E7%AE%A1%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h3 id="选择使用hexo-asset-img进行Hexo博客图片管理。因为这个可以在你创建文章的目录下自动新建一个存储当前文章所用到的图片文件夹，感觉比较方便，也便于后续备份。"><a href="#选择使用hexo-asset-img进行Hexo博客图片管理。因为这个可以在你创建文章的目录下自动新建一个存储当前文章所用到的图片文件夹，感觉比较方便，也便于后续备份。" class="headerlink" title="选择使用hexo-asset-img进行Hexo博客图片管理。因为这个可以在你创建文章的目录下自动新建一个存储当前文章所用到的图片文件夹，感觉比较方便，也便于后续备份。"></a>选择使用hexo-asset-img进行Hexo博客图片管理。因为这个可以在你创建文章的目录下自动新建一个存储当前文章所用到的图片文件夹，感觉比较方便，也便于后续备份。</h3><hr><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><pre><code class="hljs">npm install hexo-asset-img --save</code></pre><h2 id="config-yml配置"><a href="#config-yml配置" class="headerlink" title="_config.yml配置"></a>_config.yml配置</h2><p>如果你之前已经安装了hexo，那么默认_config.yml文件中有<code>post_asset_folder</code>这个选项，将其值设置为<strong>true</strong></p><h2 id="创建一个-md文章试试"><a href="#创建一个-md文章试试" class="headerlink" title="创建一个.md文章试试"></a>创建一个.md文章试试</h2><pre><code class="hljs">hexo new &quot;hexo图片管理&quot;</code></pre><p>那么目录结构应该是这样的<br>    <img src="/2023/hexo%E5%9B%BE%E7%89%87%E7%AE%A1%E7%90%86/mulujigou.png" class="" title="目录"></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>hexo-asset-img图片管理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用Git LFS上传大文件步骤</title>
    <link href="/2023/%E4%BD%BF%E7%94%A8Git-LFS%E4%B8%8A%E4%BC%A0%E5%A4%A7%E6%96%87%E4%BB%B6%E6%AD%A5%E9%AA%A4/"/>
    <url>/2023/%E4%BD%BF%E7%94%A8Git-LFS%E4%B8%8A%E4%BC%A0%E5%A4%A7%E6%96%87%E4%BB%B6%E6%AD%A5%E9%AA%A4/</url>
    
    <content type="html"><![CDATA[<p>1.首先我们要先下载git lfs。<a href="https://git-lfs.github.com/">链接地址</a><br>2.我们需要安装git lfs，但是必须安装到git&#x2F;bin下面。就是你安装git的时候，那个路径。可以看我的git安装路径：</p><img src="/2023/%E4%BD%BF%E7%94%A8Git-LFS%E4%B8%8A%E4%BC%A0%E5%A4%A7%E6%96%87%E4%BB%B6%E6%AD%A5%E9%AA%A4/1.png" class="" title="image"><p>3.我们可以使用以下步骤进行大文件上传，因为github上传有大文件有100M的限制。但是在上传的过程中，可能会出现443：timeout，或者refused等错误，可以看我<a href="https://www.cnblogs.com/peixu/p/17231781.html">博客园里的一篇文章</a>，里面写了解决方案。<br>首先进入到你的项目下，可以直接cmd。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs python">git init <span class="hljs-comment">#创建本地仓库环境</span><br><br>git lfs install <span class="hljs-comment"># 安装大文件上传应用&lt;br /&gt;#如果你之前已经向远端git过文件，并且已经安装使用过lfs。那么上述两个语句可以不用写</span><br><br>git lfs track * <span class="hljs-comment">#追踪要上传的大文件，*表示路劲下的所有文件。我们如果只上传nii文件，可以使用*.nii</span><br><br>git add .gitattributes <span class="hljs-comment">#添加上传的属性文件（要先上传属性文件，不然可能会失败）ps：我没写这句话，但是也上传成功了</span><br><br>git commit -m <span class="hljs-string">&quot;first commit&quot;</span><br><br>git remote add origin git@github.com:DreamOneYou/Liver_Tumor.git<br><br>git push origin master <span class="hljs-comment">#将本地仓库origin分支更新到远程仓库master分支下。这一步字第一次上传是很可能会报错：error：failed to push some refs to &amp;ldquo;...&amp;rdquo;。我们不用管，直接按照下面步骤继续就行</span><br><br>git add * <span class="hljs-comment">#添加要上传的大文件，*表示路劲下的所有文件</span><br>git commit -m <span class="hljs-string">&quot;first commit&quot;</span><span class="hljs-comment"># 添加大文件上传说明</span><br>git push origin master <span class="hljs-comment">#上传大文件</span><br></code></pre></td></tr></table></figure><p>　4、我们在上传大文件的过程中，可能会遇到已经执行<code>git lfs track *.zip</code> 等文件，之后使用<code>it add * </code>向本地库添加文件。但是发现使用<code>git lfs status</code>时发现，没有跟踪到任何文件。对于这种情况。我采用了最原始的方法，就是单个大文件上传。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">git lfs track *.<span class="hljs-built_in">zip</span><br>git add models/LITS_UNet_MAT_HDC/<span class="hljs-number">2022</span>1003_121927_MAT_HDC_Centerline/model.<span class="hljs-built_in">zip</span><br>git commit -m <span class="hljs-string">&quot;upload best model&quot;</span><br>git push origin master <span class="hljs-comment">#有时候会遇到这一步执行成功了，但是远端没有更新。我们只需要在执行一次这个语句就行</span><br></code></pre></td></tr></table></figure><p>5、当需要clone远端文件和大文件时，可以按照以下步骤：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">git clone git@github.com:DreamOneYous/Hepatic_vessel.git<br>git lfs pull <span class="hljs-comment"># 拉取所有lfs上传的大文件</span><br> <br>git lfs pull --include=&lt;file_path&gt; <span class="hljs-comment"># 可以指定拉取某个大文件</span><br></code></pre></td></tr></table></figure><p>6、如果克隆远端仓库的同时，还要克隆远端仓库中的子模块（其他仓库文件），可以采用下面语句：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">git clone --recursive URL <span class="hljs-comment"># 第一种：让 Git 在克隆仓库时同时下载所有子模块的代码</span><br><br>git submodule update <span class="hljs-comment">#第二种：进入每个子模块的目录中，分别执行 git submodule update 命令来下载子模块中的代码</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>lfs</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>如何使用Waline评论</title>
    <link href="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/"/>
    <url>/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[<h2 id="为什么选择Waline评论"><a href="#为什么选择Waline评论" class="headerlink" title="为什么选择Waline评论"></a>为什么选择Waline评论</h2><p>刚开始选择valine，但是网上有人说valine评论不安全，比如：评论者和自己的IP和邮箱等信息容易被泄露（ps：这是我从valine换到waline的重点原因）。还有一个原因就是很容易被发送垃圾信息，因为他没有一个注册功能，只要是个人，就可以随便发评论。</p><ul><li>选择国际版的<strong>缺点</strong>：就是只能用外网评论，很尴尬啊，我面向的是国内啊。等我的域名备案了，在转向国内吧。</li></ul><h2 id="开始配置（基于Valine进行迁移）"><a href="#开始配置（基于Valine进行迁移）" class="headerlink" title="开始配置（基于Valine进行迁移）"></a>开始配置（基于Valine进行迁移）</h2><h3 id="LeanCloud配置（数据库）"><a href="#LeanCloud配置（数据库）" class="headerlink" title="LeanCloud配置（数据库）"></a>LeanCloud配置（数据库）</h3><ul><li>这个我选择的是<a href="https://console.leancloud.app/">国际版</a>，这样后面的那个<code>LEAN_SERVER</code>就可以不用配置了。ps：主要我买的域名还没有备案，只能先选择国际版了。</li><li>进入到链接里面，就可以开始注册账户。注册完了之后进如控制台,点击创建应用，选择开发版就行，毕竟就这个版本不要money。之后进入设置（setting）找到 <code>APP ID,APP Key 和 Master Key</code> ,因为后面需要用到。<img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/1.png" class="" title="LeanCloud"><img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/2.png" class="" title="LeanCloud1"></li></ul><h3 id="Vercel配置（服务端）"><a href="#Vercel配置（服务端）" class="headerlink" title="Vercel配置（服务端）"></a>Vercel配置（服务端）</h3><ul><li>点击<a href="https://vercel.com/new/clone">部署</a>,你可以选择使用GitHub快捷登录。</li><li>创建项目并点击Create继续,此时 Vercel 会基于 Waline 模板帮助你新建并初始化仓库，仓库名为你之前输入的项目名。<img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/3.png" class="" title="Vercel3"></li><li>一两分钟后，满屏的烟花会庆祝你部署成功。此时点击 <code>Go to Dashboard</code> 可以跳转到应用的控制台。<img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/4.png" class="" title="Vercel4"></li><li>点击顶部的 <code>Settings - Environment Variables </code>进入环境变量配置页，并配置三个环境变量 <code>LEAN_ID, LEAN_KEY 和 LEAN_MASTER_KEY </code>。它们的值分别对应上一步在 LeanCloud 中获得的 <code>APP ID, APP KEY, Master Key</code>。<img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/5.png" class="" title="Vercel5"></li><li>环境变量配置完成之后点击顶部的<code>Deployments</code>点击顶部最新的一次部署右侧的 <code>Redeploy </code>按钮进行重新部署。该步骤是为了让刚才设置的环境变量生效。<img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/6.png" class="" title="Vercel6"></li><li>此时会跳转到 <code>Overview </code>界面开始部署，等待片刻后 <code>STATUS </code>会变成<code> Ready</code>。此时请点击<code>Visit</code>，即可跳转到部署好的网站地址，此地址即为你的服务端地址。<img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/7.png" class="" title="Vercel7"></li></ul><h3 id="hexo主题（我用的是Fluid主题）中配置"><a href="#hexo主题（我用的是Fluid主题）中配置" class="headerlink" title="hexo主题（我用的是Fluid主题）中配置"></a>hexo主题（我用的是Fluid主题）中配置</h3><ul><li>进入到主题中的<code>_config.yml</code>修改 <code>serverURL</code>,这里的serverURL值必须写你Vercel生成的<code>DOMAINS</code>的<code>.app</code>那个链接。<img src="/2023/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Waline%E8%AF%84%E8%AE%BA/8.png" class="" title="hexo8"></li><li>在Fluid主题中，需要修改<code>themes\fluid\layout\_partials\plugins\waline.ejs</code>文件。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs python">&lt;head&gt;<br>    &lt;!-- ... --&gt;<br>    &lt;link<br>      rel=<span class="hljs-string">&quot;stylesheet&quot;</span><br>      href=<span class="hljs-string">&quot;https://unpkg.com/@waline/client@v2/dist/waline.css&quot;</span><br>    /&gt;<br>    &lt;!-- ... --&gt;<br>  &lt;/head&gt;<br>  &lt;body&gt;<br>    &lt;!-- ... --&gt;<br>    &lt;div <span class="hljs-built_in">id</span>=<span class="hljs-string">&quot;waline&quot;</span>&gt;&lt;/div&gt;<br>    &lt;script <span class="hljs-built_in">type</span>=<span class="hljs-string">&quot;module&quot;</span>&gt;<br>      <span class="hljs-keyword">import</span> &#123; init &#125; <span class="hljs-keyword">from</span> <span class="hljs-string">&#x27;https://unpkg.com/@waline/client@v2/dist/waline.mjs&#x27;</span>;<br>  <br>      init(&#123;<br>        el: <span class="hljs-string">&#x27;#waline&#x27;</span>,<br>        serverURL: <span class="hljs-string">&#x27;https://dream-one-you-github-io.vercel.app&#x27;</span>,<br>      &#125;);<br>    &lt;/script&gt;<br>  &lt;/body&gt;<br></code></pre></td></tr></table></figure></li></ul><h3 id="评论管理"><a href="#评论管理" class="headerlink" title="评论管理"></a>评论管理</h3><ul><li>部署完成后，在<code>&lt;serverURL&gt;/ui/register</code>进行注册。第一个注册的人被设定为管理员。</li><li>管理员可管理评论。</li><li>用户可通过评论框<code>注册账号</code>，登录后可跳转至自己的评论页。</li></ul><h3 id="Ref"><a href="#Ref" class="headerlink" title="Ref"></a>Ref</h3><ul><li><a href="https://waline.js.org/guide/get-started/">Waline</a></li><li><a href="https://blog.csdn.net/hubojing/article/details/122659549">博客更换为Waline评论系统</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>waline</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo搭建github博客</title>
    <link href="/2023/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2/"/>
    <url>/2023/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<p>1、你必须建一个存储库，这个存储库要和你的github名称一致（不然就会404），如下图：</p><img src="/2023/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2/1.png" class="" title="alt text"><p>2、如果是window配置，需要安装git和<a href="https://nodejs.org/en/download">node.js</a></p><p>备注：如果出现 <strong>The punycode module is deprecated</strong> 这类错误，大概率就是node版本过高，降低一下版本。如何降低版本呢？</p><ul><li>可以按照下面命令执行，首先卸载系统里的node版本，然后安装nvm， 然后安装低版本。我这里安装图片中的版本（20）解决了。</li><li>卸载命令<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c++">brew uninstall --ignore-dependencies node <br>brew uninstall --force node <br></code></pre></td></tr></table></figure></li><li>安装低版本<img src="/2023/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2/nvm%E5%AE%89%E8%A3%85.png" class="" title="alt text"></li><li>上图中的地址可以点击这个链接<a href="https://nodejs.org/en/download">node.js</a></li></ul><p>3、下载hexo</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs python">npm config <span class="hljs-built_in">set</span> registry https://registry.npm.taobao.org  <span class="hljs-comment">#换源，下载hexo快一点</span><br>npm install hexo-cli -g  <span class="hljs-comment">#进行下载</span><br></code></pre></td></tr></table></figure><p>4、在本地进行hexo部署:hexo init<br>ps:如果你之前已经在一个博客文件夹里，那么就不用 hexo init。直接跳过这个步骤。</p><p>5、执行 <code>npm install</code>，如果不行，可以执行这句：<code>npm install --save</code></p><p>6、执行这段代码：<code>npm install hexo-deployer-git --save</code></p><p>7、分别输入  <code>git config --global user.name &quot;你的昵称&quot;</code>  和  <code>git config --global user.email &quot;你的邮箱&quot;</code> 并替换为你的昵称（我的就是DreamOneYou）和邮箱</p><p>8、获取ssh，可以在Git GUI Here进行查看。然后到你的github设置下，找到ssh key设置。</p><img src="/2023/hexo%E6%90%AD%E5%BB%BAgithub%E5%8D%9A%E5%AE%A2/gitgui.png" class=""><p>9、找到你安装博客的文件夹找到_config.yml配置文件并打开（可以用Notepad++也可以用记事本打开）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs python">deploy:<br>  <span class="hljs-built_in">type</span>: git<br>  repository: 你复制的ssh<br>  branch: master<br></code></pre></td></tr></table></figure><p>10、之后依次执行进行上传：<br>（1）<code>hexo clean</code>：此命令用于清理生成的静态文件和缓存文件。 在运行 hexo clean 后， public 目录中的所有文件将被删除; </p><p>（2）<code>hexo g</code> ：此命令用于生成静态文件。 在编写完文章后，您需要运行 hexo generate 或简写为 hexo g 来将Markdown 文件转换为HTML 文件。 这些HTML 文件将被存储在 public 目录中;</p><p>（3）<code>hexo d</code>： hexo deploy 命令用于部署网站，一般可以简写为 hexo d;</p><p>（4）<code>hexo s</code>：hexo server 命令用于启动本地服务器，如果你想本地看一下效果，可以执行该行代码，一般可以简写为 hexo s</p><p>（5）<code>hexo new</code>：hexo new 命令用于新建文章，一般可以简写为 hexo n<br>创建命令：hexo new [layout] </p><ul><li>默认一般是post，在__config.yml中的 default_layout: post可以看到。</li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>如何利用github搭建博客</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>opengl在编译的过程中，glad使用</title>
    <link href="/2023/opengl%E5%9C%A8%E7%BC%96%E8%AF%91%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8Cglad%E4%BD%BF%E7%94%A8/"/>
    <url>/2023/opengl%E5%9C%A8%E7%BC%96%E8%AF%91%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%EF%BC%8Cglad%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>我在编译的过程中，遇到：无法找到 -lglad这个错误。最后才发现对于glad的使用不能用-lglad。因为我们通过glad的<a href="https://glad.dav1d.de/" target="_blank">在线服务</a>可以得到一些文件，其中glad.c文件我们是需要放在我们的项目下面的。之后在编译的过程中使用下面这个命令：</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">g++ mian.cpp glad.c -o main.exe </pre></div><p>这样，我们就可以使用glad这个库了。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>glad库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>一些git使用命令</title>
    <link href="/2023/%E4%B8%80%E4%BA%9Bgit%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <url>/2023/%E4%B8%80%E4%BA%9Bgit%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[<p>1、新建仓库</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">git init</pre></div><p>2、如果要本地更改文件，需要更新到远端。</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">git status # 查看当前文件状态 git add -A  # "git add -A" 命令用于将工作目录中所有已修改、已删除、和新增的文件和目录添加到 Git 的暂存区中。其中，"-A" 表示 all，即全部添加。git commit -m "更新文件"git push origin master # 用于将本地 Git 仓库中的 "master" 分支推送到名为 "origin" 的远程 Git 仓库中</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>描述图像全局信息的方法</title>
    <link href="/2023/%E6%8F%8F%E8%BF%B0%E5%9B%BE%E5%83%8F%E5%85%A8%E5%B1%80%E4%BF%A1%E6%81%AF%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <url>/2023/%E6%8F%8F%E8%BF%B0%E5%9B%BE%E5%83%8F%E5%85%A8%E5%B1%80%E4%BF%A1%E6%81%AF%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h2 id="直方图"><a href="#直方图" class="headerlink" title="直方图"></a>直方图</h2><p><a href="https://opencc.icu/2022/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/">我之前写的博客</a></p><h2 id="共生矩阵"><a href="#共生矩阵" class="headerlink" title="共生矩阵"></a>共生矩阵</h2><p><a href="https://www.cnblogs.com/xixixing/p/5856118.html">一篇很详细的博客</a></p><ul><li>共生矩阵用两个位置的象素的联合概率密度来定义，它不仅反映亮度的分布特性，也反映具有同样亮度或接近亮度的象素之间的位置分布特性，是有关图象亮度变化的二阶统计特征。它是定义一组纹理特征的基础。 </li><li>图像的灰度共生矩阵是像素距离和角度的矩阵函数，它通过计算图像中一定距离和一定方向的两点灰度之间的相关性，来反映图像在方向、间隔、变化幅度及快慢上的综合信息。</li></ul><h2 id="积分图像"><a href="#积分图像" class="headerlink" title="积分图像"></a>积分图像</h2><p>积分图是一种能够描述全局信息的矩阵表示方法，其构造方式是积分图像上位置$（i，j）$处的值$ii（i，j）$是原图像$（i，j）$左上角方向所有像素的和。</p><p>$ii(i, j)&#x3D;\sum_{k \leq i, l \leq j} f(k, l)$</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>共生矩阵</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>数字图像性质</title>
    <link href="/2023/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E6%80%A7%E8%B4%A8/"/>
    <url>/2023/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E6%80%A7%E8%B4%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ul><li><a href="#1.1">信息熵</a></li><li><a href="#1.2">高斯噪声</a></li><li><a href="#1.3">图像噪声</a></li><li><a href="#1.4">离散傅里叶变换</a></li></ul><h2 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a><h1 id="1.1">信息熵</h2><img src="/2023/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E6%80%A7%E8%B4%A8/%E4%BF%A1%E6%81%AF%E7%86%B5.jpg" class="" title="信息熵"><p>熵可以作为一种<strong>“失调”</strong>的度量，熵的值越大表明这个事件就越难以预料。<br>当前这个公式底为2，表明当前熵的单位是位（bits）。<br>应用：为了压缩一幅图像，可以用熵来估计一幅图像的冗余性。</p><h2 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a><h1 id="1.2">高斯噪声</h2><img src="/2023/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E6%80%A7%E8%B4%A8/%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83.jpg" class="" title="信息熵"><p>白噪声的一个特例–高斯噪声。<br>上图计算公式是一个服从高斯（正态）分布的随机变量具有高斯曲线型的概率密度函数。<br><strong>白噪声：</strong>噪声在所有频率上出现且强度相同。</p><h2 id="图像噪声"><a href="#图像噪声" class="headerlink" title="图像噪声"></a><h1 id="1.3">图像噪声</h2><h3 id="信噪比"><a href="#信噪比" class="headerlink" title="信噪比"></a>信噪比</h3><p>各种噪声总和计算：$E&#x3D;\sum {v^2 (x,y)} $ </p><p>观察到的信号计算（也就是出现在图像上的所有信号进行计算）：$F&#x3D;\sum {f^2 (x,y)} $ </p><p>信噪比：$SNR&#x3D;F &#x2F; E$ </p><p>定义：就是计算噪声贡献的所有平方和与观察到的信号的所有平方和做比较，其值越大，表明图像品质越“好”。</p><h3 id="量化噪声"><a href="#量化噪声" class="headerlink" title="量化噪声"></a>量化噪声</h3><p>定义：量化级别不足时出现</p><h3 id="冲击噪声"><a href="#冲击噪声" class="headerlink" title="冲击噪声"></a>冲击噪声</h3><p>定义：是指一幅图像被个别噪声像素破坏，这些像素的亮度与其领域的显著不同。</p><h3 id="胡椒盐噪声"><a href="#胡椒盐噪声" class="headerlink" title="胡椒盐噪声"></a>胡椒盐噪声</h3><p>定义：是指饱和的冲击噪声，这时图像被一些白的或者黑的像素所破坏。胡椒盐噪声会使二值图像退化。</p><h2 id="离散傅里叶变换"><a href="#离散傅里叶变换" class="headerlink" title="离散傅里叶变换"></a><h1 id="1.4"><a href="https://zh.wikipedia.org/zh-cn/%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2">离散傅里叶变换</a></h2><p>离散傅里叶变换（Discrete Fourier Transform，DFT）就是先将信号在时域离散化，求其连续傅里叶变换后，再在频域离散化的结果。</p><p><strong>应用领域</strong>：边缘检测、数据压缩(去掉人类无法感知的高频部分信号)、图像复原和边界特性描述等。</p><ul><li><p>用于边缘检测</p><p>  在对图像进行FFT（快速傅立叶变换）后，我们需要对FFT变换后的图像应用高通滤波器。该滤波器会阻止所有低频，仅允许高频通过。<br>  最后，我们对经过了滤波器的图像进行逆FFT，就会得到原始图像中一些明显的边缘特征。</p>  <img src="/2023/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E6%80%A7%E8%B4%A8/img_fft.png" class="" title="img">  <img src="/2023/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E6%80%A7%E8%B4%A8/%E5%BB%BA%E7%AD%91_FFT.png" class="" title="img"><ul><li>Code  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>img = cv2.imread(<span class="hljs-string">r&#x27;img.png&#x27;</span>, <span class="hljs-number">0</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;img:&quot;</span>,img)<br>dft = cv2.dft(np.float32(img), flags=cv2.DFT_COMPLEX_OUTPUT)<br>dft_shift = np.fft.fftshift(dft)<br>magnitude_spectrum = <span class="hljs-number">20</span> * np.log(cv2.magnitude(dft_shift[:, :, <span class="hljs-number">0</span>], dft_shift[:, :, <span class="hljs-number">1</span>]))<br><br>rows, cols = img.shape<br>crow, ccol = <span class="hljs-built_in">int</span>(rows / <span class="hljs-number">2</span>), <span class="hljs-built_in">int</span>(cols / <span class="hljs-number">2</span>) <span class="hljs-comment"># center</span><br><span class="hljs-comment"># Circular HPF mask, center circle is 0, remaining all ones</span><br>mask = np.ones((rows, cols, <span class="hljs-number">2</span>), np.uint8)<br>r = <span class="hljs-number">80</span><br>center = [crow, ccol]<br>x, y = np.ogrid[:rows, :cols]<br>mask_area = (x - center[<span class="hljs-number">0</span>]) ** <span class="hljs-number">2</span> + (y - center[<span class="hljs-number">1</span>]) ** <span class="hljs-number">2</span> &lt;= r*r<br><span class="hljs-comment"># apply mask and inverse DFT</span><br>fshift = dft_shift * mask<br>fshift_mask_mag = <span class="hljs-number">2000</span> * np.log(cv2.magnitude(fshift[:, :, <span class="hljs-number">0</span>], fshift[:, :, <span class="hljs-number">1</span>]))<br>f_ishift = np.fft.ifftshift(fshift)<br>img_back = cv2.idft(f_ishift)<br>img_back = cv2.magnitude(img_back[:, :, <span class="hljs-number">0</span>], img_back[:, :, <span class="hljs-number">1</span>])<br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>), plt.imshow(img, cmap=<span class="hljs-string">&#x27;gray&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;Input Image&#x27;</span>), plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>), plt.imshow(magnitude_spectrum, cmap=<span class="hljs-string">&#x27;gray&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;After FFT&#x27;</span>), plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>), plt.imshow(fshift_mask_mag, cmap=<span class="hljs-string">&#x27;gray&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;FFT + Mask&#x27;</span>), plt.xticks([]), plt.yticks([])<br>plt.subplot(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>), plt.imshow(img_back, cmap=<span class="hljs-string">&#x27;gray&#x27;</span>)<br>plt.title(<span class="hljs-string">&#x27;After FFT Inverse&#x27;</span>), plt.xticks([]), plt.yticks([])<br>plt.show()<br></code></pre></td></tr></table></figure></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>信息熵</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>拉普拉斯算子图像增强</title>
    <link href="/2022/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%AE%97%E5%AD%90%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/"/>
    <url>/2022/%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E7%AE%97%E5%AD%90%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/</url>
    
    <content type="html"><![CDATA[<p>1、利用拉普拉斯算子进行图像增强本质是利用图像的二次微分对图像进行蜕化（图像锐化处理的作用是使灰度反差增强，从而使模糊图像变得更加清晰），在图像领域中微分是锐化，积分是模糊，利用二次微分对图像进行蜕化即利用邻域像素提高对比度，该算法也是工程数学中常用的一种积分变换，也可以用于边缘检测，图像增强、角点检测等等。</p><p>2、二阶导数定义为：</p><p><img src="/2023/image/1218402-20221203110644056-1579119878.png" alt="" width="207" height="64" /></p><p>python code：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;">  cv2</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as nppath </span>= r<span style="color: #800000;">"</span><span style="color: #800000;">people.jpg</span><span style="color: #800000;">"</span><span style="color: #000000;">path1 </span>= r<span style="color: #800000;">"</span><span style="color: #800000;">people3.jpg</span><span style="color: #800000;">"</span><span style="color: #000000;">img </span>=<span style="color: #000000;"> cv2.imread(path)im_gray </span>=<span style="color: #000000;"> cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)kernel </span>= np.array([[0, -1, 0], [0, 3, 0], [0, -1, 0]])<span style="color: #008000;">#</span><span style="color: #008000;">定义卷积核</span>imageEnhance = cv2.filter2D(img,-1, kernel)<span style="color: #008000;">#</span><span style="color: #008000;">进行卷积运算</span><span style="color: #0000ff;">print</span><span style="color: #000000;">(imageEnhance.shape)cv2.imwrite(path1,imageEnhance)</span></pre></div><p>结果：</p><table border="0"><tbody><tr><td style="text-align: center;">原图<pre>[[0, 0, 0], [0, 0, 0], [0, 0, 0]]</pre> </td><td style="text-align: center;">卷积核<pre>[[0, -1, 0], [0, 2, 0], [0, -1, 0]]</pre></td><td style="text-align: center;">卷积核<pre>[[0, -1, 0], [0, 3, 0], [0, -1, 0]]</pre></td></tr><tr><td style="text-align: center;"><img src="/2023/image/1218402-20221203110024228-1843686792.jpg" alt="" width="432" height="243" /></td><td style="text-align: center;"><img src="/2023/image/1218402-20221203110113250-1910608671.jpg" alt="" width="405" height="228" /></td><td style="text-align: center;"><img src="/2023/image/1218402-20221203110130961-513311167.jpg" alt="" width="378" height="212" /></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>拉普拉斯算子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>直方图均衡化图像增强</title>
    <link href="/2022/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/"/>
    <url>/2022/%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA/</url>
    
    <content type="html"><![CDATA[<p>1、原理：将原始图像的灰度图从比较<span style="color: #ff0000;">集中</span>的某个灰度区间<span style="color: #ff0000;">均匀</span>分布在整个灰度空间中，实现对图像的非线性拉伸，重新分配图像像素值。</p><p>2、应用场景：对于图像背景或者前景太亮（曝光严重）可以得到较好的显示。</p><p>3、算法特点：直方图均衡化保证在图像像素映射过程中原来的大小关系保持不变，即较亮的区域依旧较亮，较暗的依旧较暗，只是对比度增加，不能明暗颠倒；保证像素映射函数的值域在0和255之间。累积分布函数是单增长函数，并且值域是0到1。</p><p>4、算法流程：（下图可以具体理解）</p><p>　　1）统计直方图中每个灰度级出现的次数，计算原始灰度图像的像素概率分布</p><p>&nbsp;　　2）根据像素概率分布获取图像累积分布函数</p><p>　　3）根据映射函数获取变换后的图像</p><p><img src="/2023/image/1218402-20221202161727574-1483062538.png" alt="" width="589" height="302" /></p><p>5、利用库函数代码实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br>path = <span class="hljs-string">r&quot;people.jpg&quot;</span><br>path1 = <span class="hljs-string">r&quot;people1.jpg&quot;</span><br>path2 = <span class="hljs-string">r&quot;people2.jpg&quot;</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">ku</span>(): <span class="hljs-comment"># 库函数</span><br>    img = cv2.imread(path)<br>    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  <span class="hljs-comment"># 可以转换为灰度图</span><br>    <span class="hljs-comment"># 彩色图像均衡化,需要分解通道 对每一个通道均衡化</span><br>    (b, g, r) = cv2.split(img)<br><br>    gray = cv2.equalizeHist(gray)<br><br>    bH = cv2.equalizeHist(b)<br>    gH = cv2.equalizeHist(g)<br>    rH = cv2.equalizeHist(r)<br>    <span class="hljs-comment"># 合并每一个通道</span><br>    result = cv2.merge((bH, gH, rH))<br>    cv2.imwrite(path1, result)<br>    cv2.imwrite(path2, gray)<br></code></pre></td></tr></table></figure><p>结果：</p><table border="0"><tbody><tr><td style="text-align: center;">原图</td><td style="text-align: center;">灰度图结果　</td><td style="text-align: center;">彩色图结果</td></tr><tr><td style="text-align: center;"><img src="/2023/image/1218402-20221202162138025-1070262251.jpg" alt="" width="429" height="241" />&nbsp;</td><td style="text-align: center;"><img src="/2023/image/1218402-20221202162150749-1866371937.jpg" alt="" width="414" height="233" /></td><td style="text-align: center;"><img src="/2023/image/1218402-20221202162200749-121528006.jpg" alt="" width="408" height="230" />&nbsp;</td></tr><tr><td style="text-align: center;">原图灰度级</td><td style="text-align: center;">直方图均衡化后灰度级</td><td style="text-align: center;">&nbsp;</td></tr><tr><td style="text-align: center;"><img src="/2023/image/1218402-20221202162214616-1567652621.png" alt="" width="408" height="278" /></td><td style="text-align: center;"><img src="/2023/image/1218402-20221202162221413-137134520.png" alt="" width="382" height="269" /></td><td style="text-align: center;">&nbsp;</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>直方图均衡化图像增强</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习模型优化策略</title>
    <link href="/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/"/>
    <url>/2022/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E7%AD%96%E7%95%A5/</url>
    
    <content type="html"><![CDATA[<p class="md-end-block md-p"><span class="md-plain md-expand">对于深度学习模型优化，通常从以下几点进行：</span></p><p class="md-end-block md-p"><span class="md-plain">1、数据方面：</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; 1）数据预处理：比如可以进行重采样；设置图像强度阈值。</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; 2）数据增广：对于图像来说，可以对图像进行平移、旋转、镜像、添加噪声，改变对比度等方法进行数据扩充。这是一个对图像数据进行扩充的一些库：<span class="md-link md-pair-s"><a href="https://github.com/albumentations-team/albumentations">https://github.com/albumentations-team/albumentations</a></span></span></p><p class="md-end-block md-p md-focus"><span class="md-plain md-expand">&nbsp; &nbsp; 3）补充其他相似性数据集</span></p><p class="md-end-block md-p"><span class="md-plain">2、模型方面：</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; &nbsp;1）可以选择适合的与训练模型</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; &nbsp;2）对模型结构进行调整优化。比如可以将普通卷积换成高效的Shuffle model、Mobile Model、ESP Model、Ghost Model。</span></p><p class="md-end-block md-p"><span class="md-plain">3、损失函数：选择合适的损失函数用于不同的任务</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; &nbsp;1）目标检测：一般采用smooth L1 Loss，Focal Loss</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; &nbsp;2）图像分割：一般采用Dice Loss，CE Loss</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; &nbsp;3）图像分类：一般采用交叉熵损失（CE）函数，Focal Loss</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; &nbsp;4）图像降噪：一般采用L2 Loss</span></p><p class="md-end-block md-p"><span class="md-plain">4、优化算法</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; 1）选择合适的学习率与batchsize。对于学习率选择合适的学习率衰减算法，batchsize就看你的显卡能支持多大了。太小的话，最好网络中不要使用BatchNorm。</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; 2）采用对抗学习</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; 3）采用随机权重平均策略（SWA），就是你训练过程中可以分为两个阶段进行，这两个阶段的优化器和学习率都不同。只不过SWA阶段的训练是依赖于第一阶段训练的模型的（感觉类似一个教师模型，就是你先训练好一个模型，然后我们重新选择一个优化器和学习率（一般改为初始值的一半）再继续训练）。该方法确实能提点，就是比较费时间。</span></p><p class="md-end-block md-p"><span class="md-plain">5、正则化</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; 1）dropout，其实就是一种对于网络的集成策略。因为你每次随机丢掉的神经元都不一样（也不是丢掉，就是将这个神经元激活值置为0，但是在推理阶段这些神经元可是会参与推理的，并不会丢掉），所以可以达到多个网络的集成效果。但是对于数据量小的情况下训练，不建议使用，因为好不容易学习到的特征给丢了，很可能造成精度下降。</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; 2）early stop，这个方法一般是应用于模型过拟合的情况下，当模型对于训练集拟合的很好，但是测试集很差。我们不需要他继续学习下去了，因为很可能会把其他噪音学习进去。</span></p><p class="md-end-block md-p"><span class="md-plain">6、测试扩充</span></p><p class="md-end-block md-p"><span class="md-plain">&nbsp; &nbsp; &nbsp; 我们可以在推理阶段，对每一次预测的值输出时进行一些图像变换（镜像，翻转）等方法，然后再送入推理模型进行预测，利用多次预测的效果，从而提高最终的预测结果。对于小模型预测，这个过程还是挺快的，但是对大模型采用测试扩充，那就太耗时间了，如果对推理时间有要求，不建议采用这种优化策略。</span></p><p class="md-end-block md-p"><span class="md-plain">7、后处理</span></p><p class="md-end-block md-p"><span class="md-plain md-expand">&nbsp; &nbsp; &nbsp;这个阶段通常是在推理阶段结束之后进行的，对预测的结果进行后处理，一般可以采用阈值优化，这样会剔除掉一些不想关的噪音。比如对于脑肿瘤来说，他是一个连续的区域，如果存在不连续的区域，那么我们就认为该区域预测错了，剔除它。</span></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型优化</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>三种回归损失函数</title>
    <link href="/2022/%E4%B8%89%E7%A7%8D%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/"/>
    <url>/2022/%E4%B8%89%E7%A7%8D%E5%9B%9E%E5%BD%92%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p><a href="https://blog.csdn.net/nefetaria/article/details/111238515" target="_blank">详细介绍</a>这里，清楚的介绍了三种损失函数。我这里重点记录一下他们的异同，方便自己消化理解。</p><p>1、对于回归损失函数，通常主要有MSE（均方误差），MAE（平均绝对误差），Huber Loss。其中，Huber Loss（也叫smooth L1 Loss）是为了消除二者的缺点而提出来的。</p><p>2、通常MSE Loss也称为L2 Loss；MAE Loss也称为L1 Loss。对于大多数CNN网络，一般是使用L2-loss而不是L1-loss，因为L2-loss的收敛速度要比L1-loss要快得多。</p><p><img src="/2023/image/1218402-20221119200355115-748021459.jpg" alt="" width="315" height="233" /></p><p>&nbsp;</p><p>3、</p><table border="0"><tbody><tr><td style="text-align: center;">函数名　</td><td style="text-align: center;">公式</td><td style="text-align: center;">函数图像</td><td style="text-align: center;">备注</td></tr><tr><td>MSE</td><td><img src="/2023/image/1218402-20221119195349039-1347582527.png" alt="" width="238" height="58" /></td><td><img src="/2023/image/1218402-20221119195509421-1912912398.png" alt="" width="244" height="149" /><p>&nbsp;</p></td><td rowspan="3"><p>他们的共同点就是计算模型预测值与真实值之间的距离。</p><p>MSE：求距离平方的平均值；</p><p>MAE：求距离的平均值；</p><p>HuberLoss：看&delta;值的设定。</p></td></tr><tr><td>MAE</td><td><img src="/2023/image/1218402-20221119195404237-1795429201.png" alt="" width="232" height="56" /></td><td><img src="/2023/image/1218402-20221119195532798-1112642909.png" alt="" width="240" height="152" /><p>&nbsp;</p></td></tr><tr><td>Huber Loss</td><td><img src="/2023/image/1218402-20221119195438790-702228124.png" alt="" width="338" height="45" /></td><td><img src="/2023/image/1218402-20221119195558933-1386652253.png" alt="" width="253" height="159" /><p>&nbsp;</p></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>损失函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图像分类评价指标</title>
    <link href="/2022/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <url>/2022/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<p>图像分割是建立在图像分类和目标检测的基础之上。所以难度也要比图像分类要难。同时，两个任务在评价指标上其实也就存在一些相同，比如都会用到混淆矩阵，准确率，精确率，召回率，F1-score，IOU等评价指标，这些指标的计算我已经在之前<a href="https://www.cnblogs.com/peixu/p/16905960.html" target="_blank">图像分割评价指标</a>介绍过了。下面就介绍一下图像分割中没介绍，但是在图像分类任务中需要的评价指标：ROC曲线，AUC曲线，PR曲线，AP曲线，mAP。</p><p><strong>1.ROC曲线，</strong>主要是通过真阳性率（TPR）和假阳性率（FPR）的曲线图，直观的发现分类效果如何。</p><p><img src="/2023/image/1218402-20221119154205882-1564316498.png" alt="" width="513" height="242" /></p><p>通过公式，我们也可以直观的看出来：</p><p><img src="/2023/image/1218402-20221119154758221-1836353768.png" alt="" width="113" height="91" /></p><p>其中TPR也称为灵敏度，表示将正例分对的概率（希望这个值尽可能大）；</p><p>FPR，表示将负例分为正例的概率（我们希望这个值尽可能小）。</p><p>所以对于（FPR，TPR）就有四个点，即：</p><table border="0"><tbody><tr><td>FPR</td><td>TPR</td><td>&nbsp;</td></tr><tr><td>0</td><td>1</td><td>所有样本都分类真确</td></tr><tr><td>1</td><td>0</td><td>最差的分类器，完美的避开了所有正确选项</td></tr><tr><td>0</td><td>0</td><td>分类器预测所有样本都是负样本</td></tr><tr><td>1</td><td>1</td><td>分类器预测的样本都是正样本</td></tr></tbody></table><p>&nbsp;结论：ROC曲线越接近左上角，分类性能越好。</p><p>1）ROC还有啥优点呢？</p><p>a.容易找到不同阈值对于学习器的泛化性能影响；</p><p>b.有助于选择最佳的阈值，ROC曲线越靠近左上角，模型的查全率就越高。最靠近左上角的ROC曲线上的点是分类错误最少的最好阈值，其假正例和假反例总数最少。</p><p>c.可以对不同的学习器比较性能。将各个学习器的ROC曲线绘制到同一坐标中，直观地鉴别优劣，靠近左上角的ROC曲所代表的学习器准确性最高。</p><p><strong>2、AUC</strong></p><p>AUC（area under curve），是ROC曲线下的面积（&lt;=1）。所以就是AUC越大，那么这个分类器性能就越好（这样描述的话，ROC其实就可以完成这个任务了，为什么还要多此一举搞个AUC）。</p><p><span style="color: #ff0000;"><span style="color: #000000;">1）</span>为什么要计算AUC呢？</span></p><p>&nbsp; &nbsp; &nbsp;优点： 因为AUC对于正负样本是否均衡，其实是不敏感的（这个优点简直不要太棒）。因为我们在做模型测试的时候，或多或少都会遇到样本不平衡的情况发生（负样本太多，正样本太少。或者正样本太多，负样本太少（其实测试的时候还是比较喜欢这种情况的，但是训练的话，那就完蛋了））。所以无论正负样本是否均衡，最后AUC都会对于分类器给出一个公正的评价。</p><p>&nbsp; &nbsp; &nbsp;缺点：但是由于这种对于正负样本不平衡性不敏感的特性，所以它反映的是模型的整体性能，看不出在不同点击率区间上的误差情况。</p><p><strong>&nbsp;3、PR曲线</strong></p><p>详细介绍<a href="https://www.cnblogs.com/laozhanghahaha/p/12383363.html" target="_blank">【1】</a></p><p>所谓PR曲线就是精确率（precision）和查全率（recall）组成的坐标轴。x轴：查全率；y轴：精确率。</p><p><img src="/2023/image/1218402-20221119164031205-1535508873.png" alt="" width="336" height="109" /></p><p>&nbsp;</p><p><img src="/2023/image/1218402-20221119162903626-597358479.png" alt="" width="392" height="296" /></p><p><span style="color: #ff0000;">如何确定哪一个PR曲线好（同时也代表分类器好）？</span>通过PR曲线可以直观看出，当查全率变大时，精确率保持在一个较高的水平，说明该分类器很好。图中可以看到，A曲线要比B,C都要好。</p><p><strong>4、AP（Average Precision）和mAP（mean Average Precision），其中mAP经常作为目标检测的评价指标。</strong></p><p>AP是PR曲线下的面。所mAP就是所有类AP的算术平均。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分类评价指标</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图像分割评价指标</title>
    <link href="/2022/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/"/>
    <url>/2022/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</url>
    
    <content type="html"><![CDATA[<p>对于图像分割，首先可能会想到TP（True Positives）， TN(True Negatives)， FP(False Positives)，FN(False Negatives)这几个单词，但实际上由他们几个单词组成的混淆矩阵（confusion matrix）才是重点。</p><table border="0"><tbody><tr><td rowspan="2">&nbsp;真实</td><td colspan="2">预测</td></tr><tr><td style="text-align: left;">正例　</td><td>反例</td></tr><tr><td>正例</td><td>TP　</td><td>FN</td></tr><tr><td>反例</td><td>FP</td><td>TN</td></tr></tbody></table><div style="text-align: left;">1、准确率（accuracy）,精确率（Precision），召回率（Recall）。</div><div style="text-align: left;"><img src="/2023/image/1218402-20221119133935604-845224995.png" alt="" width="374" height="171" /></div><div style="text-align: left;">公式Accuraccy，对应语义分割中的像素准确率PA，它描述的是<span style="color: #ff0000;">预测结果中</span>，正确的占总预测值的比例。</div><div style="text-align: left;">公式Precision，它也叫查准率，它描述的是<span style="color: #ff0000;">预测结果中</span>某类别预测正确的概率。</div><div style="text-align: left;">公式Recall，他也叫查全率，它描述的是<span style="color: #ff0000;">真实值中</span>某类别被预测正确的概率。</div><div style="text-align: left;">2、IOU（Intersection over Union），他表示模型对于某一类别预测结果和真实值的交集和并集的比值。对于目标检测来说，就是检测框与真实框之间的交并比；对于图像分割来说，就是预测mask与真实mask之间的交并比。</div><div style="text-align: left;"><img src="/2023/image/1218402-20221119140713600-1324440620.png" alt="" width="279" height="224" /><p>所以计算公式为：</p><p><img src="/2023/image/1218402-20221119140340716-344189641.png" alt="" width="201" height="60" /></p><p>举个iou计算例子<a href="https://chih-sheng-huang821.medium.com/%E5%BD%B1%E5%83%8F%E5%88%87%E5%89%B2%E4%BB%BB%E5%8B%99%E5%B8%B8%E7%94%A8%E7%9A%84%E6%8C%87%E6%A8%99-iou%E5%92%8Cdice-coefficient-3fcc1a89cd1c" target="_blank">[1]</a>,下图可见：</p><p><img src="/2023/image/1218402-20221119142601454-1870944575.png" alt="" width="359" height="269" /></p><p>&nbsp;</p><p>3、通常在三维医学图像分割中，对于模型的评价指标是Dice（Dice similarity coefficient）也称为F1-Score。</p><p><img src="/2023/image/1218402-20221119141526376-2106749835.png" alt="" width="291" height="65" /></p><p>但实际上该公式是由两个公式得到，即真阳性率（TPR）和阳性预测值（PPV）的调和平均数（harmonic mean）得到：</p><p><img src="/2023/image/1218402-20221119143347497-1554427685.png" alt="" width="386" height="105" /></p><p>发现其实和IOU有一点相似，我们可以在改写一下：</p><p><img src="/2023/image/1218402-20221119141614287-1492190813.png" alt="" width="180" height="69" /></p><p>这样就比较清楚了。发现可以建立Dice和IOU之间的关系。<span style="color: #ff0000;">相比较IOU，DIce可以获得一个更高的指标分数（啊，这，难道就是为了好看吗？可能不能这样理解，在实际的实验中，Dice损失函数明显更好）</span>。当IOU=0.925时，Dice=0.961.</p><p>&nbsp;Dice系数的实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">dice_coeff</span>(<span class="hljs-params">pred, target</span>):<br>    smooth = <span class="hljs-number">1.</span><br>    num = pred.size(<span class="hljs-number">0</span>)<br>    m1 = pred.view(num, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># Flatten</span><br>    m2 = target.view(num, -<span class="hljs-number">1</span>)  <span class="hljs-comment"># Flatten</span><br>    intersection = (m1 * m2).<span class="hljs-built_in">sum</span>()<br> <br>    <span class="hljs-keyword">return</span> (<span class="hljs-number">2.</span> * intersection + smooth) / (m1.<span class="hljs-built_in">sum</span>() + m2.<span class="hljs-built_in">sum</span>() + smooth)<br></code></pre></td></tr></table></figure><p><span style="color: #0000ff;">注：调和平均数：</span>调和平均数是将所有数值取倒数并求其算术平均数后，再将此算术平均数取倒数而得，其结果等于数值的个数除以数值倒数的总和。</p><p>比如求x1和x2两个数的调和平均数H：</p><p><img src="/2023/image/1218402-20221119143927066-669454571.png" alt="" width="233" height="89" /></p><p>&nbsp;</p><p>&nbsp;</p></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分割评价指标</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HOG算法的笔记与python实现</title>
    <link href="/2022/HOG%E7%AE%97%E6%B3%95%E7%9A%84%E7%AC%94%E8%AE%B0%E4%B8%8Epython%E5%AE%9E%E7%8E%B0/"/>
    <url>/2022/HOG%E7%AE%97%E6%B3%95%E7%9A%84%E7%AC%94%E8%AE%B0%E4%B8%8Epython%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p><strong>这两篇<a href="https://cloud.tencent.com/developer/article/1678210" target="_blank">[1]</a><a href="https://developer.aliyun.com/article/325510" target="_blank">【2】</a>博客写的都非常详细。这里做个笔记记录一下。</strong></p><p>HOG称为方向梯度直方图（Histogram of Oriented Gradient），主要是为了对图像进行特征提取。所以在传统目标检测算法中经常与SVM结合用于行人识别任务（当前都是基于深度学习来做了，毕竟效果不要太好了，并且省去了繁琐的特征检测过程）。</p><p>HOG主要是计算图像中每个像素的梯度值和梯度方向，从而来获得梯度特征，是一种特征描述子<a href="https://cloud.tencent.com/developer/article/1678210" target="_blank">[1]</a>。</p><h1 id="HOG%E7%89%B9%E7%82%B9">HOG特点</h1><p>1.由于计算局部直方图和归一化，所以它对图像几何的和光学的形变都能保持很好的不变性；</p><p>2.细微的动作可以被忽略而不影响检测效果。</p><h1 id="HOG%E8%AE%A1%E7%AE%97%E6%AD%A5%E9%AA%A4">HOG计算步骤</h1><p>1.对输入图像进行灰度化</p><p>2.利用gamma校正法对图像进行颜色空间归一化；（伽玛校正就是对图像的伽玛曲线进行编辑，以对图像进行非线性色调编辑的方法，检出图像信号中的深色部分和浅色部分，并使两者比例增大，从而提高图像对比度效果。主要是为了降低图像局部的阴影和光照变化所造成的影响，同时可以抑制噪音的干扰；）</p><p>3.计算图像中每个像素的梯度大小和方向；（主要是为了捕获轮廓信息，同时进一步弱化光照的干扰）</p><p>4.将图像划分cells，计算每个cell内的梯度直方图；</p><p>5.将每几个cell组成一个block，计算每个block内的梯度特征；</p><p>6.将每几个cell组成一个block（例如3*3个cell/block），一个block内所有cell的特征descriptor串联起来便得到该block的HOG特征描述子；</p><p>7.将图像image内的所有block的HOG特征描述子串联起来就可以得到该image（你要检测的目标）的HOG特征描述子了。这个就是最终的可供分类使用的特征向量了<a href="https://developer.aliyun.com/article/325510" target="_blank">【2】</a>。</p><p><img src="/2023/image/1218402-20221118232730625-1932613845.jpg" alt="" /></p><p>&nbsp;</p><div><span style="font-size: 18pt;"><strong>&nbsp;算法实现</strong></span></div><div class="image-block">&nbsp;<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding:utf-8</span><br><span class="hljs-comment">#手敲的hog算法，跑通了，效果还行</span><br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> math<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Hog_descriptor</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, img, cell_size=<span class="hljs-number">16</span>, bin_size=<span class="hljs-number">8</span></span>):<br>        self.img = img<br>        self.img = np.sqrt(img / np.<span class="hljs-built_in">max</span>(img)) <span class="hljs-comment"># 做完归一化取根号，取值范围[0,1]</span><br>        self.img = img * <span class="hljs-number">255</span><br>        self.cell_size = cell_size<br>        self.bin_size = bin_size<br>        self.angle_unit = <span class="hljs-number">360</span> / self.bin_size<br><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">extract</span>(<span class="hljs-params">self</span>):<br>        height, width = self.img.shape<br>        <span class="hljs-comment"># 计算图像的梯度大小和方向</span><br>        gradient_magnitude, gradient_angle = self.global_gradient()<br>        gradient_magnitude = <span class="hljs-built_in">abs</span>(gradient_magnitude)<br>        cell_gradient_vector = np.zeros((<span class="hljs-built_in">int</span>(height / self.cell_size), <span class="hljs-built_in">int</span>(width / self.cell_size), self.bin_size))<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_gradient_vector.shape[<span class="hljs-number">0</span>]):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_gradient_vector.shape[<span class="hljs-number">1</span>]):<br>                <span class="hljs-comment"># cell内的梯度大小</span><br>                cell_magnitude = gradient_magnitude[i * self.cell_size:(i + <span class="hljs-number">1</span>) * self.cell_size,<br>                                 j * self.cell_size:(j + <span class="hljs-number">1</span>) * self.cell_size]<br>                <span class="hljs-comment"># cell内的梯度方向</span><br>                cell_angle = gradient_angle[i * self.cell_size:(i + <span class="hljs-number">1</span>) * self.cell_size,<br>                             j * self.cell_size:(j + <span class="hljs-number">1</span>) * self.cell_size]<br>                <span class="hljs-comment"># 转化为梯度直方图格式</span><br>                cell_gradient_vector[i][j] = self.cell_gradient(cell_magnitude, cell_angle)<br><br>        <span class="hljs-comment"># 绘制梯度直方图</span><br>        hog_image = self.render_gradient(np.zeros([height, width]), cell_gradient_vector)<br><br>        <span class="hljs-comment"># block组合、归一化</span><br>        hog_vector = []<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_gradient_vector.shape[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span>):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_gradient_vector.shape[<span class="hljs-number">1</span>] - <span class="hljs-number">1</span>):<br>                block_vector = []<br>                block_vector.extend(cell_gradient_vector[i][j])<br>                block_vector.extend(cell_gradient_vector[i][j + <span class="hljs-number">1</span>])<br>                block_vector.extend(cell_gradient_vector[i + <span class="hljs-number">1</span>][j])<br>                block_vector.extend(cell_gradient_vector[i + <span class="hljs-number">1</span>][j + <span class="hljs-number">1</span>])<br>                mag = <span class="hljs-keyword">lambda</span> vector: math.sqrt(<span class="hljs-built_in">sum</span>(i ** <span class="hljs-number">2</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> vector))<br>                magnitude = mag(block_vector)<br>                <span class="hljs-keyword">if</span> magnitude != <span class="hljs-number">0</span>:<br>                    normalize = <span class="hljs-keyword">lambda</span> block_vector, magnitude: [element / magnitude <span class="hljs-keyword">for</span> element <span class="hljs-keyword">in</span> block_vector]<br>                    block_vector = normalize(block_vector, magnitude)<br>                hog_vector.append(block_vector)<br>        <span class="hljs-keyword">return</span> hog_vector, hog_image<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">global_gradient</span>(<span class="hljs-params">self</span>):<br>        gradient_values_x = cv2.Sobel(self.img, cv2.CV_64F, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, ksize=<span class="hljs-number">5</span>)<br>        gradient_values_y = cv2.Sobel(self.img, cv2.CV_64F, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>, ksize=<span class="hljs-number">5</span>)<br>        gradient_magnitude = cv2.addWeighted(gradient_values_x, <span class="hljs-number">0.5</span>, gradient_values_y, <span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>)<br>        gradient_angle = cv2.phase(gradient_values_x, gradient_values_y, angleInDegrees=<span class="hljs-literal">True</span>)<br>        <span class="hljs-keyword">return</span> gradient_magnitude, gradient_angle<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">cell_gradient</span>(<span class="hljs-params">self, cell_magnitude, cell_angle</span>):<br>        orientation_centers = [<span class="hljs-number">0</span>] * self.bin_size<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_magnitude.shape[<span class="hljs-number">0</span>]):<br>            <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_magnitude.shape[<span class="hljs-number">1</span>]):<br>                gradient_strength = cell_magnitude[i][j]<br>                gradient_angle = cell_angle[i][j]<br>                min_angle, max_angle, mod = self.get_closest_bins(gradient_angle)<br>                orientation_centers[min_angle] += (gradient_strength * (<span class="hljs-number">1</span> - (mod / self.angle_unit)))<br>                orientation_centers[max_angle] += (gradient_strength * (mod / self.angle_unit))<br>        <span class="hljs-keyword">return</span> orientation_centers<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_closest_bins</span>(<span class="hljs-params">self, gradient_angle</span>):<br>        idx = <span class="hljs-built_in">int</span>(gradient_angle / self.angle_unit)<br>        mod = gradient_angle % self.angle_unit<br>        <span class="hljs-keyword">return</span> idx, (idx + <span class="hljs-number">1</span>) % self.bin_size, mod<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">render_gradient</span>(<span class="hljs-params">self, image, cell_gradient</span>):<br>        cell_width = self.cell_size / <span class="hljs-number">2</span><br>        max_mag = np.array(cell_gradient).<span class="hljs-built_in">max</span>()<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_gradient.shape[<span class="hljs-number">0</span>]):<br>            <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(cell_gradient.shape[<span class="hljs-number">1</span>]):<br>                cell_grad = cell_gradient[x][y]<br>                cell_grad /= max_mag<br>                angle = <span class="hljs-number">0</span><br>                angle_gap = self.angle_unit<br>                <span class="hljs-keyword">for</span> magnitude <span class="hljs-keyword">in</span> cell_grad:<br>                    angle_radian = math.radians(angle)<br>                    x1 = <span class="hljs-built_in">int</span>(x * self.cell_size + magnitude * cell_width * math.cos(angle_radian))<br>                    y1 = <span class="hljs-built_in">int</span>(y * self.cell_size + magnitude * cell_width * math.sin(angle_radian))<br>                    x2 = <span class="hljs-built_in">int</span>(x * self.cell_size - magnitude * cell_width * math.cos(angle_radian))<br>                    y2 = <span class="hljs-built_in">int</span>(y * self.cell_size - magnitude * cell_width * math.sin(angle_radian))<br>                    cv2.line(image, (y1, x1), (y2, x2), <span class="hljs-built_in">int</span>(<span class="hljs-number">255</span> * math.sqrt(magnitude)))<br>                    angle += angle_gap<br>        <span class="hljs-keyword">return</span> image<br><br>img = cv2.imread(<span class="hljs-string">&#x27;qiao.jpg&#x27;</span>, cv2.IMREAD_GRAYSCALE)<br><span class="hljs-comment"># v2.IMREAD_COLOR:读取一副彩色图片，图片的透明度会被忽略，默认为该值，实际取值为1；</span><br><span class="hljs-comment"># cv2.IMREAD_GRAYSCALE:以灰度模式读取一张图片，实际取值为0</span><br><span class="hljs-comment"># cv2.IMREAD_UNCHANGED:加载一副彩色图像，透明度不会被忽略。</span><br>hog = Hog_descriptor(img, cell_size=<span class="hljs-number">8</span>, bin_size=<span class="hljs-number">9</span>)<br>vector, image = hog.extract()<br><br><span class="hljs-comment"># 输出图像的特征向量shape</span><br><span class="hljs-built_in">print</span>(np.array(vector).shape)<br>plt.imshow(image, cmap=plt.cm.gray)<br>plt.show()<br></code></pre></td></tr></table></figure><div class="image-block"><p>结果：</p><table border="0"><tbody><tr><td style="text-align: center;">原图</td><td style="text-align: center;">特征</td></tr><tr><td><img src="/2023/image/1218402-20221118230930324-2003338663.jpg" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20221118235712682-1068826816.png" alt="" /><p>&nbsp;</p></td></tr></tbody></table><p>&nbsp;</p></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HOG算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对于ChannelNet的一点理解</title>
    <link href="/2022/%E5%AF%B9%E4%BA%8EChannelNet%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3/"/>
    <url>/2022/%E5%AF%B9%E4%BA%8EChannelNet%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>主要是为了个人理解，做个笔记</p><p><a href="https://github.com/GenDisc/ChannelNet/blob/ee09e2fef7415f051eb49657b06edfd5773d7941/channelnet.py#L34" target="_blank">1、Pytorch代码</a></p><p><a href="https://arxiv.org/pdf/1809.01330.pdf" target="_blank">2、论文出处</a></p><p>3、<a href="https://zhuanlan.zhihu.com/p/426653247" target="_blank">详细介绍</a></p><p>这篇论文在2018年发出来，而ShuffleNet是从2017年由旷视发出来。起初了解shufflenet的提出，<span style="color: #ff0000;">主要是为了解决分组卷积所导致的不同分组间信息无法交流的问题</span>，所以采用了channel shuffle操作（主要采用转置）。今天看到ChannelNet，发现也是解决分组之间信息无法交流的问题（ps：以为和shufflenet一样，只是对分组进行shuffle。结果人家采用的是<span style="color: #ff0000;">卷积进行shuffle，并且只是对通道进行卷积</span>）。</p><p>进行channel-wise有什么好处呢？我们知道，MobileNet是采用深度可分离卷积和point-wise卷积来实现轻量化模型的设计。但是point-wise存在一个缺点，就是全连接。如图1。而Channel-Net呢，他采用channel-wise卷积（就是在通道上卷积，比如输入：N*C*W*W-&gt;N*1*C*W*H，然后利用nn.Conv3d()在通道维度上进行卷积，卷积核设置为（dc*1*1），code中Group Channel-Wise Convolutions之后给出的输出是：N*2*C*W*H），稀疏了全连接，这样就会在很大程度上降低参数量和计算量（论文中有给出的）。</p><table style="height: 506px; width: 1473px;" border="0"><tbody><tr><td><div style="text-align: center;">图1：point-wise</div></td><td><div style="text-align: center;">图2：channel-shuffle</div></td><td><div style="text-align: center;">图3：channel-wise</div></td></tr><tr><td style="text-align: center;"><img src="/2023/image/1218402-20221115171933562-1961992985.png" alt="" width="166" height="153" /></td><td style="text-align: center;"><p><img src="/2023/image/1218402-20221115172653026-1275182630.png" alt="" width="408" height="129" /></p></td><td style="text-align: center;"><p><img src="/2023/image/1218402-20221115172424615-1394561668.png" alt="" width="196" height="159" /></p></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ChannelNet</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>MobileNetV2中InvertedResidual实现</title>
    <link href="/2022/MobileNet%20V2%E4%B8%ADInvertedResidual%E5%AE%9E%E7%8E%B0/"/>
    <url>/2022/MobileNet%20V2%E4%B8%ADInvertedResidual%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>1、为了方便理解其本身结构，找到<a href="https://github.com/d-li14/mobilenetv2.pytorch/blob/1733532bd43743442077326e1efc556d7cfd025d/models/imagenet/mobilenetv2.py#L43" target="_blank">源码</a>理解一下。</p><p>2、<a href="http://arxiv.org/pdf/1801.04381.pdf">论文地址</a></p><p>3、V2相比较V1增加了<strong>倒残差</strong>结构和线性瓶颈层。整个结构按照维度来看，类似一个中间宽，两边窄的结构。其中最后一层使用linear卷积（没有使用ReLU进行非线性激活，也就是线性了），主要是考虑到ReLU对于高维激活可以得到很好的非线性特征信息，但是低维采用非线性就行破坏特征信息（也称为数据坍塌，就是有一部分特征被毁掉了），虽然在高维经常使用ReLU，但是不像在低维造成很大的特征丢失情况（因为可能丢掉一部分不重要的特征，对最终结果没啥影响）。因此采用线性（就不加ReLU）。至于为什么叫倒残差，可能也是由于该结构的形状吧，便于与残差结构区分。毕竟原始残差结构是中间窄，两边宽。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">InvertedResidual</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, inp, oup, stride, expand_ratio</span>):<br>        <span class="hljs-built_in">super</span>(InvertedResidual, self).__init__()<br>        <span class="hljs-keyword">assert</span> stride <span class="hljs-keyword">in</span> [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>]<br><br>        hidden_dim = <span class="hljs-built_in">round</span>(inp * expand_ratio)<br>        self.identity = stride == <span class="hljs-number">1</span> <span class="hljs-keyword">and</span> inp == oup<br><br>        <span class="hljs-keyword">if</span> expand_ratio == <span class="hljs-number">1</span>:<br>            self.conv = nn.Sequential(<br>                <span class="hljs-comment"># dw</span><br>                nn.Conv2d(hidden_dim, hidden_dim, <span class="hljs-number">3</span>, stride, <span class="hljs-number">1</span>, groups=hidden_dim, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(hidden_dim),<br>                nn.ReLU6(inplace=<span class="hljs-literal">True</span>),<br>                <span class="hljs-comment"># pw-linear</span><br>                nn.Conv2d(hidden_dim, oup, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(oup),<br>            )<br>        <span class="hljs-keyword">else</span>:<br>            self.conv = nn.Sequential(<br>                <span class="hljs-comment"># pw</span><br>                nn.Conv2d(inp, hidden_dim, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(hidden_dim),<br>                nn.ReLU6(inplace=<span class="hljs-literal">True</span>),<br>                <span class="hljs-comment"># dw</span><br>                nn.Conv2d(hidden_dim, hidden_dim, <span class="hljs-number">3</span>, stride, <span class="hljs-number">1</span>, groups=hidden_dim, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(hidden_dim),<br>                nn.ReLU6(inplace=<span class="hljs-literal">True</span>),<br>                <span class="hljs-comment"># pw-linear</span><br>                nn.Conv2d(hidden_dim, oup, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, bias=<span class="hljs-literal">False</span>),<br>                nn.BatchNorm2d(oup),<br>            )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">if</span> self.identity:<br>            <span class="hljs-keyword">return</span> x + self.conv(x)<br>        <span class="hljs-keyword">else</span>:<br>            <span class="hljs-keyword">return</span> self.conv(x)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MobileNetV2</tag>
      
      <tag>InvertedResidual实现</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传统图像分割算法基于区域的分割算法</title>
    <link href="/2022/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95-%E5%9F%BA%E4%BA%8E%E5%8C%BA%E5%9F%9F%E7%9A%84%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95/"/>
    <url>/2022/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95-%E5%9F%BA%E4%BA%8E%E5%8C%BA%E5%9F%9F%E7%9A%84%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><span style="color: #ff0000;">这类方法按照图像的相似性准则划分不同的区域块。其中较为典型的方法优：种子区域生长法、分水岭法、区域分裂合并法。</span></p><p><span style="color: #ff0000;">种子区域生长法：</span>首先通过一组表示不同区域的种子像素开始，逐步合并与种子周围相似的像素，从而扩大区域，直到无法合并像素点或者区域为止。这个相似性度量可以采用平均灰度值、纹理、颜色等信息。<span style="color: #ff0000;">该方法的关键就是如何选择初始的种子像素以及生长准则。</span></p><p><span style="color: #ff0000;">区域分裂合并法：<span style="color: #000000;">该方法首先要确定分裂合并的准则，然后对图像进行分裂（1-&gt;4;4-&gt;16...），直到相邻区域满足一致性特征时，将他们合并为一个大区域，直到所有区域不满足分裂合并准则为止。分裂的最差一种情况就是，分裂到单个像素级别，这就类似种子区域生长法了，合并与种子周围相似的像素。但是该方法不同于种子生长法，该方法可以从一个大的区域开始生长，而种子区域生长法只能从一个像素开始。</span></span></p><p><span style="color: #000000;"><span style="color: #ff0000;">分水岭法</span>：我们可以获取到图像中某个区域的中的最小灰度值（局部极小值），而这个像素点与周围的环境形成一个集水盆。而这个算法要做的就是不停的像这个集水盆中倒水，如果水位达到一定高度就会溢出，我们在这个溢出的位置修建堤坝。重复这个过程，知道图像中的所有点都被淹没，这时候所建立的堤坝就是分开各个盆地的分水岭。从而实现了图像的分割。该方法对于弱边缘有着较好的分割，但是图像中的噪声会造成过分割现象。</span></p><p><span style="color: #000000;">基于种子区域生长法Code实现：</span></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-comment">#首先是区域生长一些函数的定义：</span><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Point</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,x,y</span>):<br>        self.x = x<br>        self.y = y<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">getX</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.x<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">getY</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">return</span> self.y<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">getGrayDiff</span>(<span class="hljs-params">img,currentPoint,tmpPoint</span>):<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">abs</span>(<span class="hljs-built_in">int</span>(img[currentPoint.x,currentPoint.y]) - <span class="hljs-built_in">int</span>(img[tmpPoint.x,tmpPoint.y]))<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">selectConnects</span>(<span class="hljs-params">p</span>):<br>    <span class="hljs-keyword">if</span> p != <span class="hljs-number">0</span>:<br>        connects = [Point(-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>), Point(<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>), Point(<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>), Point(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>), Point(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), \<br>                    Point(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), Point(-<span class="hljs-number">1</span>, <span class="hljs-number">1</span>), Point(-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)]<br>    <span class="hljs-keyword">else</span>:<br>        connects = [ Point(<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>),  Point(<span class="hljs-number">1</span>, <span class="hljs-number">0</span>),Point(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>), Point(-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>)]<br>    <span class="hljs-keyword">return</span> connects<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">regionGrow</span>(<span class="hljs-params">img,seeds,thresh,p = <span class="hljs-number">1</span></span>):<br>    height, weight = img.shape<br>    seedMark = np.zeros(img.shape)<br>    seedList = []<br>    <span class="hljs-keyword">for</span> seed <span class="hljs-keyword">in</span> seeds:<br>        seedList.append(seed)<br>    label = <span class="hljs-number">1</span><br>    connects = selectConnects(p)<br>    <span class="hljs-keyword">while</span>(<span class="hljs-built_in">len</span>(seedList)&gt;<span class="hljs-number">0</span>):<br>        currentPoint = seedList.pop(<span class="hljs-number">0</span>)<br><br>        seedMark[currentPoint.x,currentPoint.y] = label<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">8</span>):<br>            tmpX = currentPoint.x + connects[i].x<br>            tmpY = currentPoint.y + connects[i].y<br>            <span class="hljs-keyword">if</span> tmpX &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> tmpY &lt; <span class="hljs-number">0</span> <span class="hljs-keyword">or</span> tmpX &gt;= height <span class="hljs-keyword">or</span> tmpY &gt;= weight:<br>                <span class="hljs-keyword">continue</span><br>            grayDiff = getGrayDiff(img,currentPoint,Point(tmpX,tmpY))<br>            <span class="hljs-keyword">if</span> grayDiff &lt; thresh <span class="hljs-keyword">and</span> seedMark[tmpX,tmpY] == <span class="hljs-number">0</span>:<br>                seedMark[tmpX,tmpY] = label<br>                seedList.append(Point(tmpX,tmpY))<br>    <span class="hljs-keyword">return</span> seedMark<br><br><span class="hljs-comment"># 创建一个图像</span><br>image = np.ones((<span class="hljs-number">256</span>, <span class="hljs-number">256</span>))<br>cv2.circle(image, (<span class="hljs-number">256</span>//<span class="hljs-number">2</span>, <span class="hljs-number">256</span>//<span class="hljs-number">2</span>), <span class="hljs-built_in">int</span>(<span class="hljs-number">100</span>), (<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>), -<span class="hljs-number">1</span>)<br>cv2.circle(image, (<span class="hljs-number">256</span>//<span class="hljs-number">2</span>, <span class="hljs-number">256</span>//<span class="hljs-number">2</span>), <span class="hljs-built_in">int</span>(<span class="hljs-number">50</span>), (<span class="hljs-number">255</span>,<span class="hljs-number">255</span>,<span class="hljs-number">255</span>), -<span class="hljs-number">1</span>)<br>cv2.imwrite(<span class="hljs-string">&#x27;test.png&#x27;</span>, <span class="hljs-number">255</span>*image)<br><span class="hljs-comment"># 分割中间白色部分</span><br>image_copy = image.copy()//<span class="hljs-number">255</span><br>seeds = [Point(<span class="hljs-number">256</span>//<span class="hljs-number">2</span>,<span class="hljs-number">256</span>//<span class="hljs-number">2</span>)]<br>binaryImg = regionGrow(image_copy,seeds,<span class="hljs-number">1</span>)<br>cv2.imwrite(<span class="hljs-string">&#x27;test1.png&#x27;</span>, <span class="hljs-number">255</span> * binaryImg)<br></code></pre></td></tr></table></figure><p>&nbsp;结果：</p><table border="0"><tbody><tr><td style="text-align: center;">原图</td><td style="text-align: center;">结果</td></tr><tr><td><img src="/2023/image/1218402-20221121000309984-189066015.png" alt="" /></td><td><img src="/2023/image/1218402-20221121000317598-872766856.png" alt="" /></td></tr></tbody></table><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><p><span style="color: #000000;">&nbsp;</span></p><p><span style="color: #000000;">&nbsp;</span></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>传统分割算法</tag>
      
      <tag>区域分割算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传统图像分割算法基于边缘检测的图像分割</title>
    <link href="/2022/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95-%E5%9F%BA%E4%BA%8E%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    <url>/2022/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E7%AE%97%E6%B3%95-%E5%9F%BA%E4%BA%8E%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/</url>
    
    <content type="html"><![CDATA[<p>1、基于边缘检测的图像语义分割算法试图<span style="color: #ff0000;">通过检测包含不同区域的边缘</span>来解决分割问题。它可以说是人们最先想到也是研究最多的方法之一。通常不<span style="color: #ff0000;">同区域的边界上像素的灰度值变化比较剧烈，</span>如果将图片从空间域通过傅里叶变换到频率域，<span style="color: #ff0000;">边缘就对应着高频部分</span>，这是一种非常简单的边缘检测算法。最简单的边缘检测方法是并行微分算子法，它利用<span style="color: #ff0000;">相邻区域的像素值不连续的性质</span>，采用一阶或者二阶导数来检测边缘点。</p><p>2、一阶导数和二阶导数的不同显示</p><p><img src="/2023/image/1218402-20221031144310220-1541265531.png" alt="" /></p><p>3、常用的一阶微分算子有Roberts、Prewitt、Sobel等算子，常用的二阶微分算子有Laplace和Kirsh等算子。在实际处理操作中常用模板矩阵与图像像素值矩阵卷积来实现微分运算。</p><p><img src="/2023/image/1218402-20221031161210550-937709616.png" alt="" /></p><p>&nbsp;</p><p>4、<a href="https://blog.csdn.net/weixin_53598445/article/details/120855003" target="_blank">Kirsch算子在</a>这篇博客进行了实现。</p><p>5、Canny是当前最为流行的一种边缘检测方法。由1986年由JOHN CANNY首次在论文《A Computational Approach to Edge Detection》中提出。其中Canny使用了变分法。Canny检测器中的最优函数使用四个指数项的和来描述，它可以由高斯函数的一阶导数来近似。这个<a href="https://blog.csdn.net/qq_29462849/article/details/81050212" target="_blank">博客对canny算子</a>六个步骤进行了详细的介绍，可以看看。</p><p><span style="color: #ff0000;">个人理解canny算子每个步骤：<a href="https://www.cnblogs.com/king-lps/p/8007134.html" target="_blank">python实现</a></span></p><p>1)、因为使用该方法，颜色对于边缘检测作用不是很大，所以一般会将其先从RGB图像转换为灰度图。gray=0.3*R+0.59*G+0.11*B</p><p>2)、采用高斯滤波器平滑图像。这一步骤主要是为了降低图像中阴影部分或者光照对于检测的影响，具体就是太黑的变亮一点，太亮的变黑一点，不要使他们太剧烈（从图像上看，理解可能有误，有了解的，评论区给点建议）。其次采用高斯滤波可以消除一些噪音。（但是很有可能将一些边缘也消除掉）</p><p>3）计算图像每个像素的梯度幅值和方向</p><p>3)、采用非极大值抑制。这一步主要是为了细化边缘，只保留幅值局部变化变化最大的点。</p><p>4)、双阈值检测与链接。就是为了将边缘划分为不是边缘，弱边缘和强边缘。小于低阈值的不是边缘，大于低阈值小于高阈值是弱边缘，大于高阈值的是强边缘。</p><p>5）、抑制孤立的弱边缘完成边缘检测。这句话很明白，就是第四步怎么都会产生一些弱边缘，那么我们就将一些孤立的弱边缘排除掉，而把其他的弱边缘保留下（其实就另类的当做强边缘输出了）。</p><p>&nbsp;</p><p>6、sobel算子具体计算过程：</p><p><img src="/2023/image/1218402-20221107105131051-1649544808.png" alt="" width="870" height="310" /></p><p>&nbsp;一些简单实现：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">put</span>(<span class="hljs-params">path</span>):<br>    <span class="hljs-comment"># 读取图像</span><br>    img = cv2.imread(path)<br>    b, g, r = cv2.split(img)<br>    img2 = cv2.merge([r, g, b])<br><br>    <span class="hljs-comment"># 灰度化处理图像</span><br>    grayImage = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)<br><br>    <span class="hljs-comment"># 高斯滤波</span><br>    gaussianBlur = cv2.GaussianBlur(grayImage, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># 二值化</span><br>    ret, binary = cv2.threshold(grayImage, <span class="hljs-number">127</span>, <span class="hljs-number">255</span>, cv2.THRESH_BINARY)<br><br>    <span class="hljs-comment"># Sobel算子</span><br>    x = cv2.Sobel(grayImage, cv2.CV_16S, <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)  <span class="hljs-comment"># 对x求一阶导</span><br>    y = cv2.Sobel(grayImage, cv2.CV_16S, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>)  <span class="hljs-comment"># 对y求一阶导</span><br>    absX = cv2.convertScaleAbs(x)<br>    absY = cv2.convertScaleAbs(y)<br>    Sobel = cv2.addWeighted(absX, <span class="hljs-number">0.5</span>, absY, <span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># Roberts算子</span><br>    kernelx = np.array([[-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">1</span>]], dtype=<span class="hljs-built_in">int</span>)<br>    kernely = np.array([[<span class="hljs-number">0</span>, -<span class="hljs-number">1</span>], [<span class="hljs-number">1</span>, <span class="hljs-number">0</span>]], dtype=<span class="hljs-built_in">int</span>)<br>    x = cv2.filter2D(grayImage, cv2.CV_16S, kernelx)<br>    y = cv2.filter2D(grayImage, cv2.CV_16S, kernely)<br>    <span class="hljs-comment"># 转uint8</span><br>    absX = cv2.convertScaleAbs(x)<br>    absY = cv2.convertScaleAbs(y)<br>    Roberts = cv2.addWeighted(absX, <span class="hljs-number">0.5</span>, absY, <span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># 拉普拉斯算子</span><br>    dst = cv2.Laplacian(grayImage, cv2.CV_16S, ksize=<span class="hljs-number">3</span>)<br>    Laplacian = cv2.convertScaleAbs(dst)<br><br>    <span class="hljs-comment"># 高斯滤波降噪</span><br>    gaussian = cv2.GaussianBlur(grayImage, (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>), <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># Canny算子</span><br>    Canny = cv2.Canny(gaussian, <span class="hljs-number">50</span>, <span class="hljs-number">150</span>)<br><br>    <span class="hljs-comment"># Prewitt算子</span><br>    kernelx = np.array([[<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">1</span>], [<span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>], [-<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>, -<span class="hljs-number">1</span>]], dtype=<span class="hljs-built_in">int</span>)<br>    kernely = np.array([[-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>], [-<span class="hljs-number">1</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>]], dtype=<span class="hljs-built_in">int</span>)<br>    x = cv2.filter2D(grayImage, cv2.CV_16S, kernelx)<br>    y = cv2.filter2D(grayImage, cv2.CV_16S, kernely)<br>    <span class="hljs-comment"># 转uint8</span><br>    absX = cv2.convertScaleAbs(x)<br>    absY = cv2.convertScaleAbs(y)<br>    Prewitt = cv2.addWeighted(absX, <span class="hljs-number">0.5</span>, absY, <span class="hljs-number">0.5</span>, <span class="hljs-number">0</span>)<br><br>    <span class="hljs-comment"># 高斯拉普拉斯算子</span><br>    gaussian = cv2.GaussianBlur(grayImage, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>), <span class="hljs-number">0</span>)  <span class="hljs-comment"># 先通过高斯滤波降噪</span><br>    dst = cv2.Laplacian(gaussian, cv2.CV_16S, ksize=<span class="hljs-number">3</span>)  <span class="hljs-comment"># 再通过拉普拉斯算子做边缘检测</span><br>    LOG = cv2.convertScaleAbs(dst)<br><br>    <span class="hljs-comment"># 用来正常显示中文标签</span><br>    plt.rcParams[<span class="hljs-string">&#x27;font.sans-serif&#x27;</span>] = [<span class="hljs-string">&#x27;SimHei&#x27;</span>]<br><br>    <span class="hljs-comment"># 显示图形</span><br>    plt.subplot(<span class="hljs-number">241</span>), plt.imshow(img2), plt.title(<span class="hljs-string">&#x27;原始图像&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">242</span>), plt.imshow(binary, plt.cm.gray), plt.title(<span class="hljs-string">&#x27;二值图&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">243</span>), plt.imshow(Sobel, plt.cm.gray), plt.title(<span class="hljs-string">&#x27;Sobel算子&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">244</span>), plt.imshow(Roberts, plt.cm.gray), plt.title(<span class="hljs-string">&#x27;Roberts算子&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">245</span>), plt.imshow(Laplacian, plt.cm.gray), plt.title(<span class="hljs-string">&#x27;拉普拉斯算子&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">246</span>), plt.imshow(Canny, plt.cm.gray), plt.title(<span class="hljs-string">&#x27;Canny算子&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">247</span>), plt.imshow(Prewitt, plt.cm.gray), plt.title(<span class="hljs-string">&#x27;Prewitt算子&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br>    plt.subplot(<span class="hljs-number">248</span>), plt.imshow(LOG, plt.cm.gray), plt.title(<span class="hljs-string">&#x27;高斯拉普拉斯算子&#x27;</span>), plt.axis(<span class="hljs-string">&#x27;off&#x27;</span>)<br><br>    <span class="hljs-comment"># plt.savefig(&#x27;1.new-2.jpg&#x27;)</span><br>    plt.show()<br><br><span class="hljs-comment"># 图像处理函数，要传入路径</span><br>put(<span class="hljs-string">r&#x27;laohu.jpg&#x27;</span>)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2023/image/1218402-20221111223247284-256386211.png" alt="" /></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>传统分割算法</tag>
      
      <tag>边缘检测</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>传统图像分割方法（基于阈值分割）</title>
    <link href="/2022/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E4%BA%8E%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2%EF%BC%89/"/>
    <url>/2022/%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E6%96%B9%E6%B3%95%EF%BC%88%E5%9F%BA%E4%BA%8E%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>阈值法：基本思想是基于图像的<span style="color: #ff0000;">灰度特征</span>来计算一个或多个灰度阈值，并将图像中<span style="color: #ff0000;">每个像素的灰度值与阈值相比较</span>，最后将像素根据比较结果分到合适的类别中。因此，<span style="color: #ff0000;">该类方法最为关键的一步就是按照某个准则函数来求解最佳灰度阈值。</span></p><p>&nbsp;</p><p><img src="/2023/image/1218402-20221031142818940-51960334.png" alt="" /></p><p>&nbsp;一个简单实现：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> cv2</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as np</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> matplotlib.pyplot as plt</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> collections as colpath </span>= r<span style="color: #800000;">"</span><span style="color: #800000;">laohu.jpg</span><span style="color: #800000;">"</span><span style="color: #000000;">path1 </span>= r<span style="color: #800000;">"</span><span style="color: #800000;">laohu1.jpg</span><span style="color: #800000;">"</span><span style="color: #000000;">image </span>=<span style="color: #000000;"> cv2.imread(path)temp </span>= np.zeros((image.shape[0], image.shape[1], 1<span style="color: #000000;">))<br /># gray=0.3 * r + 0.59*g + 0.11 * btemp[:,:, 0] </span>= image[:,:, 0] * 0.11 + image[:,:, 1] * 0.59 + image[:,:, 2] * 0.3<span style="color: #008000;">#</span><span style="color: #008000;"> 绘制双峰图</span>y =<span style="color: #000000;"> list()</span><span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> range(image.shape[0]):    </span><span style="color: #0000ff;">for</span> j <span style="color: #0000ff;">in</span> range(image.shape[1<span style="color: #000000;">]):        y.append(int(temp[i, j, 0]))yy </span>=<span style="color: #000000;"> col.Counter(y)yyy </span>=<span style="color: #000000;"> list()xxx </span>=<span style="color: #000000;"> list()</span><span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> sorted(yy):    xxx.append(i)    yyy.append(yy[i])</span><span style="color: #0000ff;">print</span><span style="color: #000000;">(yyy)<p>x </span>&#x3D; [i <span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span> range(256<span style="color: #000000;">)]<br>plt.bar(xxx, yyy, width</span>&#x3D;2, fc&#x3D;<span style="color: #800000;">“</span><span style="color: #800000;">gray</span><span style="color: #800000;">“</span><span style="color: #000000;">)<br>plt.show()<br>plt.savefig(</span><span style="color: #800000;">“</span><span style="color: #800000;">bar.jpg</span><span style="color: #800000;">“</span><span style="color: #000000;">)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 找到最低点，设置阈值</span><br>temp &#x3D; np.where(temp &gt; 115<span style="color: #000000;">, temp, 0)<br>cv2.imwrite(path1, temp)</span></pre></p></div><p>&nbsp;</p><p>结果：</p><table border="0"><tbody><tr><td>before</td><td>after</td><td>&nbsp;</td></tr><tr><td><img src="/2023/image/1218402-20221111220313900-1998068712.jpg" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20221111223818410-7371975.jpg" alt="" /><br /><br /><p>&nbsp;</p></td><td><p><img src="/2023/image/1218402-20221111223833390-881251902.png" alt="" width="261" height="134" /></p></td></tr><tr><td><p><img src="/2023/image/1218402-20221111224947534-2116380485.jpg" alt="" /></p><p>&nbsp;</p></td><td>&nbsp;<img src="/2023/image/1218402-20221111224958107-846218826.jpg" alt="" /><p>&nbsp;</p></td><td>&nbsp;<img src="/2023/image/1218402-20221111225008172-1550009781.png" alt="" width="381" height="197" /><p>&nbsp;</p></td></tr></tbody></table><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>传统分割算法</tag>
      
      <tag>阈值分割</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于Transformer中feedforwardlayer理解</title>
    <link href="/2022/%E5%85%B3%E4%BA%8ETransformer%E4%B8%ADfeed%20forward%20layer%E7%90%86%E8%A7%A3/"/>
    <url>/2022/%E5%85%B3%E4%BA%8ETransformer%E4%B8%ADfeed%20forward%20layer%E7%90%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>今天记录一下个人关于Transformer中前馈神经网络（FFN）的一点理解。</p><p>第一点，我们知道，FFN之前是有一个多头注意力机制的模块。我们可以想想一下，如果这个模块直接输出，不经过FFN层会发生什么，要知道多头注意力（MH）是没有激活函数的，那么最后只有一个结果，那就是很多头的输出就是一个极为相似的结果。这并不是我们想要的结果，所以这个时候，我们可以考虑使用FFN层，因为这个结构可以提供更好的特征表达能力（也就是提供了非线性，非线性很重要，不然DL就没法搞那么深了）。</p><p>第二点，关于self-attention这个模块，该模块其实就是学习某个特征与其余其他特征之间的相似度分数，然后利用softmax归一化成注意力分数，之后对某个特征与其他特征的相似性进行加权输出。而这个过程就意味着self-attention输出的并不是上下文语义嵌入，而是原始上下文本身（就是怎么输进去就怎么输出来，只不过输出来的值是带有权重的，比如，我去店里买咖啡，从店里出来时我带着咖啡这个权重，只不过我还是我，并没有变。感觉这比喻有点问题，但是我只能这么理解了）。所以这个时候就需要考虑利用FNN考察特征语义不同部分之间的关系（通过非线性变换来实现）。感觉有点像self-attention先去前方打探好多个敌人的不同情况，之后FFN根据不同的敌人做调整。</p><p>第三点、在使用self-attention实际上是做了一个线性变换，也就是第一点提到的，训练到后期，输出值都相似。所以之后需要加入FNN提高特征的表达能力（也就是添加非线性ReLU）。其次self-attention只解决了特征之间的长远距离依赖关系，并没有对特征进行提取，也就是第二点提到的。</p><p>以上就是我的个人参考一些资料的理解，之后再有新的想法，继续补充。有人知道其他原因的话，欢迎评论区。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Transformer</tag>
      
      <tag>feedforwardlayer</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于softmax在CV多通道中的理解</title>
    <link href="/2022/%E5%85%B3%E4%BA%8Esoftmax%E5%9C%A8CV%E5%A4%9A%E9%80%9A%E9%81%93%E4%B8%AD%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <url>/2022/%E5%85%B3%E4%BA%8Esoftmax%E5%9C%A8CV%E5%A4%9A%E9%80%9A%E9%81%93%E4%B8%AD%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>1、采用分类任务时，我们通常会采用逻辑回归算法，最关键的步骤就是将线性模型输出的实数域映射到[0, 1]表示概率分布的有效实数空间，其中Sigmoid函数刚好具有这样的功能。但是这通常只适用于二分类问题。要多多分类任务各个输出节点的输出值范围映射到[0, 1]，通常可以采用softmax。</p><p>2、所谓的softmax主要分类两个部分解答，soft也就是软的意思，与之相对的就是hard，通常可以采用np.max()等方法实现，这个方法就是获取的最大值。而我们在多分类任务中，更期望得到这个类的置信度（个人理解，就是一个可行的范围，并不局限于一个值）。（懒得敲公式了，直接cc+cv了）</p><p><img src="/2023/image/1218402-20221030200402129-2128918290.png" alt="" width="695" height="82" /></p><p>3、我们在DL分类任务中经常用到这个函数。我做了一下实现。</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch.nn.functional as Fimage </span>= torch.randn((3,3,3))<span style="color: #008000;">#</span><span style="color: #008000;">这里可以理解为一个3通道的3x3图像</span>softmax = F.softmax(image, dim=0) <span style="color: #008000;">#</span><span style="color: #008000;">在第一个维度进行计算，可以得到每个通到的softmax结果</span></pre></div><p>&nbsp;</p><table border="0"><tbody><tr><td>softmax之前</td><td><table border="0"><tbody><tr><td>softmax之后</td></tr></tbody></table></td></tr><tr><td><img src="/2023/image/1218402-20221030200828623-1750525957.png" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20221030200843304-1717860675.png" alt="" /><p>&nbsp;</p></td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>softmax</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用3Dslice提取血管中心线</title>
    <link href="/2022/%E5%88%A9%E7%94%A83Dslice%E6%8F%90%E5%8F%96%E8%A1%80%E7%AE%A1%E4%B8%AD%E5%BF%83%E7%BA%BF/"/>
    <url>/2022/%E5%88%A9%E7%94%A83Dslice%E6%8F%90%E5%8F%96%E8%A1%80%E7%AE%A1%E4%B8%AD%E5%BF%83%E7%BA%BF/</url>
    
    <content type="html"><![CDATA[<p>1.首先进入<a href="https://download.slicer.org/" target="_blank">官网</a>下载你需要的版本。你也可以安装老版本，我已经用红色框框出来了。</p><p><img src="/2023/image/1218402-20220917150152473-1858304206.png" alt="" width="853" height="469" /></p><p>&nbsp;</p><p>2.开始安装，等个几十秒钟就ok了。</p><p>3.当然要实现提取中心线，还需要&nbsp;VMTK 这个玩意，</p><p>打开应用，找到 install slicer extension 这个选项，下载咱需要的一下插件：</p><p><img src="/2023/image/1218402-20220917150549376-876103761.png" alt="" /></p><p>4.完了只有应用 restart一下。</p><p>5. 看这个<a href="https://github.com/vmtk/SlicerExtension-VMTK#the-vmtk-extension-for-3d-slicer" target="_blank">教程</a>，去提取血管中心线吧。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3Dslice</tag>
      
      <tag>血管中心线提取</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用SourceTree管理仓库代码</title>
    <link href="/2022/%E4%BD%BF%E7%94%A8SourceTree%E7%AE%A1%E7%90%86%E4%BB%93%E5%BA%93%E4%BB%A3%E7%A0%81/"/>
    <url>/2022/%E4%BD%BF%E7%94%A8SourceTree%E7%AE%A1%E7%90%86%E4%BB%93%E5%BA%93%E4%BB%A3%E7%A0%81/</url>
    
    <content type="html"><![CDATA[<p>1.首先我们需要下载sourcetree，你可以去<a href="https://www.sourcetreeapp.com/" target="_blank">官网</a>下载自己需要的版本。</p><p><img src="/2023/image/1218402-20220915161356703-1157469014.png" alt="" width="672" height="306" /></p><p>2.安装完毕之后，我们需要获取ssh密钥与github关联上才能使用</p><p>&nbsp;按下面的操作开始执行。确定之后，会出现一个字符界面，输入你一般使用ssh链接克隆代码的密码。就ok了</p><p><img src="/2023/image/1218402-20220915161733118-943013363.png" alt="" width="906" height="595" /></p><p>&nbsp;<img src="/2023/image/1218402-20220915162554637-1147340819.png" alt="" width="903" height="436" /></p><p>&nbsp;</p><p>4，这下你就可以开始clone代码了。并且可以时事提交更新。并且你可以创建新的分支，在不干扰主分支代码的情况下，更新自己的分支。</p><p><img src="/2023/image/1218402-20220915162206327-1268072056.png" alt="" width="728" height="344" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
      <tag>sourcetree</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>window10任务栏图标不见了（如何修复）</title>
    <link href="/2022/window10%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%9B%BE%E6%A0%87%E4%B8%8D%E8%A7%81%E4%BA%86%EF%BC%88%E5%A6%82%E4%BD%95%E4%BF%AE%E5%A4%8D%EF%BC%89/"/>
    <url>/2022/window10%E4%BB%BB%E5%8A%A1%E6%A0%8F%E5%9B%BE%E6%A0%87%E4%B8%8D%E8%A7%81%E4%BA%86%EF%BC%88%E5%A6%82%E4%BD%95%E4%BF%AE%E5%A4%8D%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>1.按&nbsp;<strong>Windows键+ R</strong>&nbsp;</p><p>2.写&nbsp;<strong>％temp％</strong>&nbsp;在其中，然后单击&ldquo;确定&rdquo;。</p><p>3.删除其中的所有内容以清除临时文件。</p><p>4.重启</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Windows</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>c++批量修改文件名</title>
    <link href="/2022/%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%90%8D/"/>
    <url>/2022/%E6%89%B9%E9%87%8F%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E5%90%8D/</url>
    
    <content type="html"><![CDATA[<p>在网上找了很久如何利用c++批量修改文件名，但是很不幸，找到的都不全，或者跑起来没效果。我就整合了以下批量修改文件名的代码（我跑完之后，文件名并没有改，好奇怪，你们可以试着找一下错误，我感觉没有错啊，为啥改不了。欢迎在评论区解惑）</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c++"><span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">rename_main</span><span class="hljs-params">()</span></span>&#123;<br>    std::vector&amp;lt;std::string&amp;gt; mesh_dir;<br>    std::vector&amp;lt;std::string&amp;gt; keypoint_dir;<br>    std::vector&amp;lt;std::string&amp;gt; obj_dir;<br>    std::string m = <span class="hljs-string">&quot;/Users/wpx/Documents/data/nose_validata/mesh&quot;</span>;<br>    std::string key = <span class="hljs-string">&quot;/Users/wpx/Documents/data/nose_validata/keypoint&quot;</span>;<br>    std::string o = <span class="hljs-string">&quot;/Users/wpx/Documents/data/nose_validata/obj&quot;</span>;<br>    std::string output_root = <span class="hljs-string">&quot;/Users/wpx/Documents/data/nose_validata/output_obj&quot;</span>;<br>    mesh_dir = <span class="hljs-built_in">getFilesList</span>(m);<br>    keypoint_dir = <span class="hljs-built_in">getFilesList</span>(key);<br>    obj_dir = <span class="hljs-built_in">getFilesList</span>(o);<br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k=<span class="hljs-number">0</span>; k&amp;lt;mesh_dir.<span class="hljs-built_in">size</span>(); k++)&#123;<br>        std::string mesh_name     =  mesh_dir.<span class="hljs-built_in">at</span>(k);<br>        std::string keypoint_name = keypoint_dir.<span class="hljs-built_in">at</span>(k);<br>        std::string obj_name      = obj_dir.<span class="hljs-built_in">at</span>(k);<br>        std::string keypoint_path = <span class="hljs-string">&quot;/Users/wpx/Documents/data/nose_validata/keypoint/&quot;</span> + keypoint_name;<br>        std::string mesh_path     = <span class="hljs-string">&quot;/Users/wpx/Documents/data/nose_validata/mesh/&quot;</span> + mesh_name;<br>        std::string obj_path     = o + <span class="hljs-string">&quot;/&quot;</span> + obj_name;<br>        <span class="hljs-comment">// 我需要删除文件名中的&amp;ldquo;_keypoint&amp;rdquo; 和文件名中的&amp;ldquo;_mesh&amp;rdquo;</span><br>        <span class="hljs-type">int</span> pos_key = keypoint_path.<span class="hljs-built_in">find</span>(<span class="hljs-string">&quot;_keypoint&quot;</span>);  <span class="hljs-comment">//找到 &quot;_keypoint&quot;位置下标，因为需要截断</span><br>        <span class="hljs-type">int</span> pos_mesh = mesh_path.<span class="hljs-built_in">find</span>(<span class="hljs-string">&quot;_mesh&quot;</span>);  <span class="hljs-comment">// 类似上面</span><br>        std::string sub_file_key = keypoint_path.<span class="hljs-built_in">substr</span>(pos_key, <span class="hljs-number">9</span>);  <span class="hljs-comment">// 从pos_key开始，数9个字符，因为_keypoint 是9个</span><br>        std::string sub_file_mesh = mesh_path.<span class="hljs-built_in">substr</span>(pos_mesh, <span class="hljs-number">5</span>);  <span class="hljs-comment">//同上</span><br>        <span class="hljs-comment">// std::cout&amp;lt;&amp;lt;&quot;pos:&quot;&amp;lt;&amp;lt;sub_file_key&amp;lt;&amp;lt;std::endl;</span><br>        <span class="hljs-comment">// std::cout&amp;lt;&amp;lt;&quot;mesh:&quot;&amp;lt;&amp;lt;sub_file_mesh&amp;lt;&amp;lt;std::endl;</span><br>        std::string new_key = keypoint_path.<span class="hljs-built_in">replace</span>(pos_key, <span class="hljs-number">9</span>, <span class="hljs-string">&quot;&quot;</span>);  <span class="hljs-comment">// 找到_keypoint之后，替换为空字符</span><br>        std::string new_mesh = mesh_path.<span class="hljs-built_in">replace</span>(pos_mesh, <span class="hljs-number">5</span>, <span class="hljs-string">&quot;&quot;</span>); <span class="hljs-comment">// 同上</span><br>        std::cout&amp;lt;&amp;lt;new_key&amp;lt;&amp;lt;std::endl;<br>        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">rename</span>(keypoint_path.<span class="hljs-built_in">c_str</span>(), new_key.<span class="hljs-built_in">c_str</span>()))  <span class="hljs-comment">// 之后利用c++中的rename方法，进行修改，结果修改错误，娘希匹，搞不定了。</span><br>        &#123;<br>            std::cout &amp;lt;&amp;lt; <span class="hljs-string">&quot;rename success &quot;</span>&amp;lt;&amp;lt; std::endl;<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            std::cout &amp;lt;&amp;lt; <span class="hljs-string">&quot;rename error &quot;</span>&amp;lt;&amp;lt; std::endl;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (!<span class="hljs-built_in">rename</span>(mesh_path.<span class="hljs-built_in">c_str</span>(), new_mesh.<span class="hljs-built_in">c_str</span>()))<br>        &#123;<br>            std::cout &amp;lt;&amp;lt; <span class="hljs-string">&quot;rename success &quot;</span>&amp;lt;&amp;lt; std::endl;<br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>            std::cout &amp;lt;&amp;lt; <span class="hljs-string">&quot;rename error &quot;</span>&amp;lt;&amp;lt; std::endl;<br>        &#125;<br>    <br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>修改文件名</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git工具sourcetree使用中的部分问题</title>
    <link href="/2022/git%E5%B7%A5%E5%85%B7%EF%BC%9Asourcetree%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E9%83%A8%E5%88%86%E9%97%AE%E9%A2%98/"/>
    <url>/2022/git%E5%B7%A5%E5%85%B7%EF%BC%9Asourcetree%E4%BD%BF%E7%94%A8%E4%B8%AD%E7%9A%84%E9%83%A8%E5%88%86%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>这段时间经常用到这个工具。就当记个笔记，记录一下我的一些问题。</p><p>问题一：</p><p>如果想要拉取远端更新：</p><p>第一步：先登陆sourcetree，点击&rdquo;抓取&ldquo;。</p><p>第二步：在终端输入：git submodule update --init（我一般是在项目的终端下输入的，其他位置没试过）。</p><p>问题二：</p><p>如果发现自己的项目推不上去了，那可能是你的本地仓库和远端仓库根本就不是互相跟踪的关系，建议删除本地仓库（前提做好备份），然后重新建仓库（一定要与你要时刻<span style="color: #ff6600;">跟踪</span>的分支建立联系），我之前就是跟踪的master分支，结果非要向其他分支上传，结果找bug真心累。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
      <tag>sourcetree</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Eigen矩阵除法</title>
    <link href="/2022/Eigen%E7%9F%A9%E9%98%B5%E9%99%A4%E6%B3%95/"/>
    <url>/2022/Eigen%E7%9F%A9%E9%98%B5%E9%99%A4%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>看了网上很多帖子，很多都没有说Eigen如何做矩阵除法。我这里补充一下。其他运算一般都可以查到；</p><p>对于Matrix来说，我们需要先将其转换成数组，因为Eigen矩阵不能做除法（很烦）。</p><p>比如我们一个2x4的矩阵，除以1x4的矩阵，python是可以使用numpy实现的（其实也是用的数组形式）。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs c++">Eigen::Matrix&lt;<span class="hljs-type">double</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>&gt; mat; <span class="hljs-comment">// 生成两行四列的矩阵</span><br>    Eigen::Matrix&lt;<span class="hljs-type">double</span>, <span class="hljs-number">1</span>, <span class="hljs-number">4</span>&gt; v;   <span class="hljs-comment">// 生成一行四列的矩阵，主要目的是为了存储mat中要除的某一行，或者某一列。我这里主要是为了除以某一行</span><br> <br>    mat &lt;&lt; <span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<span class="hljs-number">2</span>,<br>            <span class="hljs-number">2</span>,<span class="hljs-number">4</span>,<span class="hljs-number">6</span>,<span class="hljs-number">8</span>;<br>    v &lt;&lt; mat.<span class="hljs-built_in">row</span>(<span class="hljs-number">0</span>);      <span class="hljs-comment">// 假设我们需要mat除以mat第一行所有数据。   </span><br>    mat.<span class="hljs-built_in">array</span>().<span class="hljs-built_in">rowwise</span>() /= v.<span class="hljs-built_in">array</span>().<span class="hljs-built_in">row</span>(<span class="hljs-number">0</span>);  <span class="hljs-comment">//这里先转成数组，然后再除。</span><br>    std::cout &lt;&lt; <span class="hljs-string">&quot;Broadcasting result: &quot;</span> &lt;&lt; std::endl;<br>    std::cout &lt;&lt; mat &lt;&lt; std::endl;<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2023/image/1218402-20220807122426552-813168882.jpg" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Eigen</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于CycleGAN损失函数的可视化理解</title>
    <link href="/2022/%E5%85%B3%E4%BA%8ECycleGAN%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E7%90%86%E8%A7%A3/"/>
    <url>/2022/%E5%85%B3%E4%BA%8ECycleGAN%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E7%9A%84%E5%8F%AF%E8%A7%86%E5%8C%96%E7%90%86%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>看了《<a href="https://arxiv.org/pdf/1703.10593.pdf" target="_blank">Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks</a>》这篇论文，大致了解了CycleGAN的工作原理，为了更好的理解他损失函数的设计，结合提供的代码，我绘制了损失函数的流程图，并且用maps跑了代码，图中的图片就是测试集挑选出来的。通过看代码，我发现他的输入是不配对的，也就是real_B并不是并不是real_A的标签图。当然你可以设置opt.serial_batches=True，这样输入 real_B就是real_A的标签图，当然False训练结果其实也可以，和True差别不大。没理解这其中的含义，后续在了解了解。</p><p>其中idt_A,idt_B, cycle_A,cycle_B都是通过L1损失计算出来的。</p><p><img src="/2023/image/1218402-20220622165315859-332183189.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>损失函数</tag>
      
      <tag>CycleGAN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对于python中GIL的一些理解与代码实现</title>
    <link href="/2022/%E5%AF%B9%E4%BA%8Epython%E4%B8%ADGIL%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/"/>
    <url>/2022/%E5%AF%B9%E4%BA%8Epython%E4%B8%ADGIL%E7%9A%84%E4%B8%80%E4%BA%9B%E7%90%86%E8%A7%A3%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<p>&nbsp;</p><p>近期看了一些关于<a href="https://www.oschina.net/translate/pythons-hardest-problem" target="_blank">GIL的一些内容</a>，敲一下代码看看效果。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-comment"># GIL(Global Interpreter Lock):他只允许任何时刻只有一个线程处于执行状态，即使是在具有多个CPU内核的多线程架构中。</span><br><span class="hljs-comment"># 为什么没有删除GIL，因为现在的python已经严重依赖GIL提供的解决方案。如果删除会破坏现有的C扩展。（free threading 就是删除的案例，他会导致单线程任务速度降低40%。）</span><br><span class="hljs-comment"># 释放GIL：以前版本是采用计数策略删除，如果该线程计数为0，则删除。现在采用固定时间间隔，到了时间点就删除。</span><br><span class="hljs-keyword">import</span> time<br><span class="hljs-keyword">from</span> threading <span class="hljs-keyword">import</span> Thread<br><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Pool<br>Count = <span class="hljs-number">50000000</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">countdown</span>(<span class="hljs-params">n</span>):<br>    <span class="hljs-keyword">while</span> n&gt;<span class="hljs-number">0</span>:<br>         n-=<span class="hljs-number">1</span><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># 不采用多进程和多线程</span><br>    start1 = time.time()<br>    countdown(Count)<br>    end1 = time.time()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;2:&quot;</span>, end1 - start1)  <span class="hljs-comment"># 2.538</span><br><br>    <span class="hljs-comment"># 采用多线程</span><br>    <span class="hljs-comment"># t1 = Thread(target=countdown, args=(Count // 2,))</span><br>    <span class="hljs-comment"># t2 = Thread(target=countdown, args=(Count // 2,))</span><br>    <span class="hljs-comment"># start = time.time()</span><br>    <span class="hljs-comment"># t1.start()</span><br>    <span class="hljs-comment"># t2.start()</span><br>    <span class="hljs-comment"># t1.join()  # join 所完成的工作就是线程同步，即主线程任务结束以后，进入堵塞状态，一直等待所有的子线程结束以后，主线程再终止</span><br>    <span class="hljs-comment"># t2.join()  # 至于为什么，我觉得可能是为了防止同一时刻有多个线程访问资源。</span><br>    <span class="hljs-comment"># end = time.time()</span><br>    <span class="hljs-comment"># print(&quot;1:&quot;, end - start)  # 2.717</span><br><br>    <span class="hljs-comment"># 采用多进程</span><br>    <span class="hljs-comment"># pool = Pool(processes=2)</span><br>    <span class="hljs-comment"># start2 = time.time()</span><br>    <span class="hljs-comment"># r1 = pool.apply_async(countdown, [Count//2])</span><br>    <span class="hljs-comment"># r2 = pool.apply_async(countdown, [Count//2])</span><br>    <span class="hljs-comment"># pool.close()</span><br>    <span class="hljs-comment"># pool.join()</span><br>    <span class="hljs-comment"># end2 = time.time()</span><br>    <span class="hljs-comment"># print(&quot;3:&quot;,end2-start2)  # 1.617</span><br></code></pre></td></tr></table></figure><p>结果发现，采用多进程的确会好点。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GIL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>可视化UNet编码器每层的输出（在已经训练好的模型下展示，并不是初始训练阶段展示）</title>
    <link href="/2022/%E5%8F%AF%E8%A7%86%E5%8C%96U-Net%E7%BC%96%E7%A0%81%E5%99%A8%E6%AF%8F%E5%B1%82%E7%9A%84%E8%BE%93%E5%87%BA%EF%BC%88%E5%9C%A8%E5%B7%B2%E7%BB%8F%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%B8%8B%E5%B1%95%E7%A4%BA%EF%BC%8C%E5%B9%B6%E4%B8%8D%E6%98%AF%E5%88%9D%E5%A7%8B%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E5%B1%95%E7%A4%BA%EF%BC%89/"/>
    <url>/2022/%E5%8F%AF%E8%A7%86%E5%8C%96U-Net%E7%BC%96%E7%A0%81%E5%99%A8%E6%AF%8F%E5%B1%82%E7%9A%84%E8%BE%93%E5%87%BA%EF%BC%88%E5%9C%A8%E5%B7%B2%E7%BB%8F%E8%AE%AD%E7%BB%83%E5%A5%BD%E7%9A%84%E6%A8%A1%E5%9E%8B%E4%B8%8B%E5%B1%95%E7%A4%BA%EF%BC%8C%E5%B9%B6%E4%B8%8D%E6%98%AF%E5%88%9D%E5%A7%8B%E8%AE%AD%E7%BB%83%E9%98%B6%E6%AE%B5%E5%B1%95%E7%A4%BA%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>想看一下对于一个训练好的模型，其每一层编码阶段的可视化输出是什么样子的。我以3Dircabd肝脏血管分割为例，训练好了一个U-Net模型。然后使用该模型在推理阶段使用，并可视化了每一层编码器。</p><p>分割结果：</p><p><img src="/2023/image/1218402-20220528163208505-1676482114.png" alt="" /></p><p>可视化分为两个展示，分别是有原图和没有原图作为背景的。</p><table border="0" align="center"><tbody><tr><td>无背景</td><td><img src="/2023/image/1218402-20220528163516897-91443912.png" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20220528163527935-2000398132.png" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20220528163535223-1976255210.png" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20220528163541792-1829258852.png" alt="" /><p>&nbsp;</p></td></tr><tr><td>&nbsp;</td><td>encoder第一层</td><td>encoder第二层</td><td>encoder第三层</td><td>encoder第四层</td></tr><tr><td>有背景</td><td><img src="/2023/image/1218402-20220528163551612-1633815942.png" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20220528163558784-861260975.png" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20220528163605616-963735541.png" alt="" /><p>&nbsp;</p></td><td><img src="/2023/image/1218402-20220528163613272-1942642703.png" alt="" /><p>&nbsp;</p></td></tr><tr><td>&nbsp;</td><td>encoder第一层</td><td>encoder第二层</td><td>encoder第三层</td><td>encoder第四层</td></tr></tbody></table>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>UNet</tag>
      
      <tag>编码层特征显示</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对抗生成网络（GAN）简单介绍</title>
    <link href="/2022/%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C%EF%BC%88GAN%EF%BC%89%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/"/>
    <url>/2022/%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C%EF%BC%88GAN%EF%BC%89%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<p>对抗生成网络主要由生成网络和判别网络构成，GAN在图像领域使用较多。利用生成网络生成假的图像，然后利用判别器是否能判断该图像是假的。</p><p>1、用于医学图像分割，一般我们可以利用一个U-Net网络生成分割结果，但是结果或许分割的不是很好。我们这时候就可以利用GAN的优势。通过将分割的结果放入GAN网络中进行对抗学习，优化生成器，这样相当于训练了一个另类的后处理网络。</p><p>2、第一种是利用U-Net生成分割图，然后在优化生成器。还有一种就是以U-Net结构作为生成器，然后在利用生成的分割图与真实图，共同送入到判别器中。（这种方法比较常用）</p><p>大家可以主要看以下博客，应该可以加深GAN的理解。（主要也是为了我方便查找，毕竟每一次查找好的资源都不容易）</p><p><a href="http://cp0000.github.io/2020/08/30/GAN-introdcution/" target="_blank">博客一</a>：更加生动的讲解了GAN，方便理解。</p><p><a href="https://zhuanlan.zhihu.com/p/28853704" target="_blank">博客二</a>：对公式进行了详细介绍。</p><p><a href="https://blog.csdn.net/qq_14845119/article/details/80787753?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522165346093316782246445568%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&amp;request_id=165346093316782246445568&amp;biz_id=0&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-1-80787753-null-null.nonecase&amp;utm_term=%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0&amp;spm=1018.2226.3001.4450" target="_blank">博客三</a>：这个博客里提到的二分类交叉熵损失函数一般是应用在<a href="https://github.com/tensorflow/gan/blob/master/tensorflow_gan/python/losses/losses_impl.py" target="_blank">GAN</a>当中。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GAN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图像形态学操作（cv2库实现）</title>
    <link href="/2022/%E5%9B%BE%E5%83%8F%E5%BD%A2%E6%80%81%E5%AD%A6%E6%93%8D%E4%BD%9C%EF%BC%88cv2%E5%BA%93%E5%AE%9E%E7%8E%B0%EF%BC%89/"/>
    <url>/2022/%E5%9B%BE%E5%83%8F%E5%BD%A2%E6%80%81%E5%AD%A6%E6%93%8D%E4%BD%9C%EF%BC%88cv2%E5%BA%93%E5%AE%9E%E7%8E%B0%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding:utf-8</span><br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br><span class="hljs-comment"># 膨胀</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dilateion</span>(<span class="hljs-params">image</span>):<br>    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="hljs-number">5</span>,<span class="hljs-number">5</span>))<br>    <span class="hljs-comment"># dilate = cv2.dilate(image, kernel, iterations=1)</span><br>    dilate = cv2.morphologyEx(image, cv2.MORPH_DILATE, kernel)<br>    <span class="hljs-keyword">return</span> dilate<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">erode</span>(<span class="hljs-params">image</span>):<br>    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="hljs-number">3</span>,<span class="hljs-number">3</span>))<br>    <span class="hljs-comment"># erode = cv2.erode(image, kernel, iterations=1)</span><br>    erode = cv2.morphologyEx(image, cv2.MORPH_ERODE, kernel)<br>    <span class="hljs-keyword">return</span> erode<br><span class="hljs-comment"># 形态学梯度</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">edge</span>(<span class="hljs-params">image</span>):<br>    SE = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>    img_grad = cv2.morphologyEx(image, cv2.MORPH_GRADIENT, SE)<br>    <span class="hljs-keyword">return</span> img_grad<br><span class="hljs-comment"># 开运算</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">openOpreation</span>(<span class="hljs-params">image</span>):<br>    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="hljs-number">3</span>, <span class="hljs-number">3</span>))<br>    <span class="hljs-built_in">open</span> = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)<br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">open</span><br><span class="hljs-comment"># 闭运算</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">closeOperation</span>(<span class="hljs-params">image</span>):<br>    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>))<br>    close = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)<br>    <span class="hljs-keyword">return</span> close<br><span class="hljs-comment"># 读取3D图像，对每一个slice进行形态学变化</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_3D</span>(<span class="hljs-params">image, model=<span class="hljs-string">&quot;closeOperation&quot;</span></span>):<br>    slices = image.shape[<span class="hljs-number">0</span>]<br>    result = np.zeros(img_num.shape)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(slices):<br>        sli = img_num[i:i + <span class="hljs-number">1</span>, ...]<br>        s = sli[<span class="hljs-number">0</span>, ...]<br>        <span class="hljs-keyword">if</span> model == <span class="hljs-string">&quot;dilateion&quot;</span>:<br>            <span class="hljs-built_in">slice</span> = dilateion(s)<br>        <span class="hljs-keyword">elif</span> model ==<span class="hljs-string">&quot;edge&quot;</span>:<br>            <span class="hljs-built_in">slice</span> = edge(s)<br>        <span class="hljs-keyword">elif</span> model == <span class="hljs-string">&quot;erode&quot;</span>:<br>            <span class="hljs-built_in">slice</span> = erode(s)<br>        <span class="hljs-keyword">elif</span> model == <span class="hljs-string">&quot;edge&quot;</span>:<br>            <span class="hljs-built_in">slice</span> = edge(s)<br>        <span class="hljs-keyword">elif</span> model == <span class="hljs-string">&quot;openOpreation&quot;</span>:<br>            <span class="hljs-built_in">slice</span> = openOpreation(s)<br>        <span class="hljs-keyword">elif</span> model == <span class="hljs-string">&quot;closeOperation&quot;</span>:<br>            <span class="hljs-built_in">slice</span> = closeOperation(s)<br>        result[i, ...] = <span class="hljs-built_in">slice</span><br>    <span class="hljs-keyword">return</span> result<br><span class="hljs-comment"># 保存图像</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">x, path</span>):<br>    predict_seg = sitk.GetImageFromArray(x)<br>    sitk.WriteImage(predict_seg, path)<br><span class="hljs-comment"># 读取 nii文件</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_nii</span>(<span class="hljs-params">path</span>):<br>    image = sitk.ReadImage(path)<br>    img_num = sitk.GetArrayFromImage(image)<br>    <span class="hljs-keyword">return</span> img_num<br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    path = <span class="hljs-string">r&quot;D:\myProject\HDC_vessel_seg\datasets\nii\image\vessel_12.nii&quot;</span><br>    imgpath = <span class="hljs-string">r&quot;D:\myProject\HDC_vessel_seg\datasets\nii\image\image_12.nii&quot;</span><br>    img_num = read_nii(path)<br>    img = read_nii(imgpath)<br>    img_num = img_num[<span class="hljs-number">10</span>:<span class="hljs-number">260</span>,...]<br>    img = img[<span class="hljs-number">10</span>:<span class="hljs-number">260</span>,...]<br>    result = read_3D(img_num)<br>    name = <span class="hljs-string">&quot;closeOperation_&quot;</span><br>    save(result, path.replace(<span class="hljs-string">&quot;vessel_12&quot;</span>, name + <span class="hljs-string">&quot;vessel&quot;</span>))<br>    <span class="hljs-comment"># save(img_num, path.replace(&quot;vessel_12&quot;, &quot;pre_vessel&quot;))</span><br>    <span class="hljs-comment"># save(img, imgpath.replace(&quot;image_12&quot;, &quot;pre_image&quot;))</span><br></code></pre></td></tr></table></figure><table border="0"><tbody><tr><td><img src="/2023/image/1218402-20220525164419600-904871557.png" alt="" /></td><td><img src="/2023/image/1218402-20220525164435424-314363314.png" alt="" /></td><td><img src="/2023/image/1218402-20220525164444079-677908876.png" alt="" /></td><td><img src="/2023/image/1218402-20220525164452974-1654089967.png" alt="" /></td><td><img src="/2023/image/1218402-20220525164500199-557805773.png" alt="" /></td><td><img src="/2023/image/1218402-20220525164507530-1567196474.png" alt="" /></td></tr><tr><td><div style="text-align: center;">原图</div></td><td style="text-align: center;"><div>膨胀</div></td><td style="text-align: center;"><div>腐蚀</div></td><td style="text-align: center;"><div>形态学梯度</div></td><td style="text-align: center;"><div>先开后闭</div></td><td style="text-align: center;"><div>先闭后开</div></td></tr></tbody></table><div style="text-align: center;">&nbsp;</div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图像膨胀</tag>
      
      <tag>图像腐蚀</tag>
      
      <tag>读取nii</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>过拟合一些解决方案</title>
    <link href="/2022/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%80%E4%BA%9B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"/>
    <url>/2022/%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%80%E4%BA%9B%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url>
    
    <content type="html"><![CDATA[<img src="/2023/image/1218402-20220522162722698-1555354996.png" alt="" /><p><strong>过拟合原因：</strong></p><p>1. 训练集的数量级和模型的复杂度不匹配。训练集的数量级要小于模型的复杂度；（模型太复杂，参数就会太大，然而你的数据量又很小）</p><p>2. 训练集和测试集特征分布不一致；（用分类猫的训练集，去拟合分类狗的）</p><p>3. 样本里的噪音数据干扰过大，大到模型过分记住了噪音特征，反而忽略了真实的输入输出间的关系；（数据量太小，或许只学到了噪音，而没有学到希望学到的特征）</p><p>4. 权值学习迭代次数足够多(Overtraining)，拟合了训练数据中的噪声和训练样例中没有代表性的特征。<br /><br /></p><p><strong>解决方案：</strong></p><p>1、简化模型结构：比如减小网络深度。</p><p>2、多来一些数据增广，比如flip、rotate，镜像，高斯噪音，随机裁剪，缩放。</p><p>3、正则化：比如添加L1和L2正则。（L2正则也称为权重衰减 weight decay ）</p><p><span style="color: #ff0000;">L2范数</span>是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0。因为一般认为参数值小的模型比较简单，能适应不同的数据集，也在一定程度上避免了过拟合现象。<span style="color: #ff0000;">可以设想一下对于一个线性回归方程，若参数很大，那么只要数据偏移一点点，就会对结果造成很大的影响；但如果参数足够小，数据偏移得多一点也不会对结果造成什么影响，专业一点的说法是『抗扰动能力强』</span></p><p>4、Dropout：丢弃网络中的一些神经元。（或许有用，别丢太多，好不容易训练出来的参数）</p><p>5、早停（early stopping）：这就需要有验证集，当验证集的Dice值达到最优的时候，就停止训练，减少训练时间。（通常在找到最优epoch之后，在跑10-50epoch，确定是最优，再停止）。</p><p>6、<a href="https://zh.wikipedia.org/zh-cn/%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0" target="_blank">ensemble</a>、集成多个模型结果，减少过拟合造成的影响。但是这种方法太花费时间了。<span style="color: #ff0000;">集成类型：贝叶斯最优分类器、Bootstrap聚合（Bagging）、Boosting、贝叶斯参数平均、贝叶斯模型组合、桶模型、Stacking。</span></p><p>7、重新对数据进行清洗。但是对于深度学习视觉任务来说，这个过程一般在数据预处理阶段完成。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>解决过拟合</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用cv2.morphologyEx提取图像边界</title>
    <link href="/2022/%E5%88%A9%E7%94%A8cv2.morphologyEx%E6%8F%90%E5%8F%96%E5%9B%BE%E5%83%8F%E8%BE%B9%E7%95%8C/"/>
    <url>/2022/%E5%88%A9%E7%94%A8cv2.morphologyEx%E6%8F%90%E5%8F%96%E5%9B%BE%E5%83%8F%E8%BE%B9%E7%95%8C/</url>
    
    <content type="html"><![CDATA[<pre>cv2.morphologyEx(image, cv2.MORPH_GRADIENT, SE)可以参考这篇<a href="https://blog.csdn.net/qq_39507748/article/details/104539673" target="_blank">博客</a><br /><br />cv2.MORPH_GRADIENT：形态学梯度(morph-grad)，可以突出团块(blob)的边缘， 保留物体的边缘轮廓。</pre><div class="cnblogs_code"><pre><span style="color: #008000;">#</span><span style="color: #008000;">coding:utf-8</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> SimpleITK as sitk</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as np</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> cv2<p></span><span style="color: #0000ff;">def</span><span style="color: #000000;"> edge(image):<br>    SE </span>&#x3D; cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3<span style="color: #000000;">))<br>    img_grad </span>&#x3D;<span style="color: #000000;"> cv2.morphologyEx(image, cv2.MORPH_GRADIENT, SE)<br>    </span><span style="color: #0000ff;">return</span><span style="color: #000000;"> img_grad</p><p></span><span style="color: #0000ff;">def</span><span style="color: #000000;"> save(x, path):<br>    predict_seg </span>&#x3D;<span style="color: #000000;"> sitk.GetImageFromArray(x)<br>    sitk.WriteImage(predict_seg, path)<br></span><span style="color: #0000ff;">def</span><span style="color: #000000;"> read_nii(path):<br>    image </span>&#x3D;<span style="color: #000000;"> sitk.ReadImage(path)<br>    img_num </span>&#x3D;<span style="color: #000000;"> sitk.GetArrayFromImage(image)<br>    </span><span style="color: #0000ff;">return</span><span style="color: #000000;"> img_num<br></span><span style="color: #0000ff;">if</span> <span style="color: #800080;"><strong>name</strong></span> &#x3D;&#x3D; <span style="color: #800000;">“</span><span style="color: #800000;"><strong>main</strong></span><span style="color: #800000;">“</span><span style="color: #000000;">:<br>    path </span>&#x3D; r<span style="color: #800000;">“</span><span style="color: #800000;">D:\myProject\HDC_vessel_seg\datasets\nii\vessel_1.nii</span><span style="color: #800000;">“</span><span style="color: #000000;"><br>    img_num </span>&#x3D;<span style="color: #000000;"> read_nii(path)<br>    img_num </span>&#x3D; img_num[20:84<span style="color: #000000;">,…]<br>    slices </span>&#x3D;<span style="color: #000000;"> img_num.shape[0]<br>    result </span>&#x3D;<span style="color: #000000;"> np.zeros(img_num.shape)<br>    </span><span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> range(slices):<br>        sli </span>&#x3D; img_num[i:i+1<span style="color: #000000;">, …]<br>        s </span>&#x3D;<span style="color: #000000;"> sli[0,…]<br>        slice </span>&#x3D;<span style="color: #000000;"> edge(s)<br>        result[i,…] </span>&#x3D;<span style="color: #000000;"> slice<br>    save(result, path.replace(</span><span style="color: #800000;">“</span><span style="color: #800000;">vessel_1</span><span style="color: #800000;">“</span>, <span style="color: #800000;">“</span><span style="color: #800000;">edge_vessel_1</span><span style="color: #800000;">“</span><span style="color: #000000;">))<br>    save(img_num, path.replace(</span><span style="color: #800000;">“</span><span style="color: #800000;">vessel_1</span><span style="color: #800000;">“</span>, <span style="color: #800000;">“</span><span style="color: #800000;">pre_vessel_1</span><span style="color: #800000;">“</span><span style="color: #000000;">))<br>    </span><span style="color: #0000ff;">print</span>(slices)</pre></p></div><p>结果：</p><p>原始图像：</p><p><img src="/2023/image/1218402-20220521163605681-1581908661.png" alt="" /></p><p>提取边缘：</p><p><img src="/2023/image/1218402-20220521163623704-162415417.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>opencv</tag>
      
      <tag>提取图像边界</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用cv2.dilate对图像进行膨胀</title>
    <link href="/2022/%E5%88%A9%E7%94%A8cv2.dilate%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E8%86%A8%E8%83%80/"/>
    <url>/2022/%E5%88%A9%E7%94%A8cv2.dilate%E5%AF%B9%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E8%86%A8%E8%83%80/</url>
    
    <content type="html"><![CDATA[<p>cv2.getStructuringElement(cv2.MORPH_RECT, (7,7))介绍，<a href="https://blog.csdn.net/duwangthefirst/article/details/80001590" target="_blank">请看这个博客</a>。我简要说一下cv2.getStructuringElement，可用于构造一个特定大小和形状的结构元素，用于图像形态学处理。其中 MORPH_RECT 就是构造一个全1方形矩阵。<br><br />代码如下：</pre></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding:utf-8</span><br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> cv2<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dilateion</span>(<span class="hljs-params">image</span>):<br>    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (<span class="hljs-number">7</span>,<span class="hljs-number">7</span>))<br>    dilate = cv2.dilate(image, kernel, iterations=<span class="hljs-number">1</span>)<br>    <span class="hljs-keyword">return</span> dilate<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">x, path</span>):<br>    predict_seg = sitk.GetImageFromArray(x)<br>    sitk.WriteImage(predict_seg, path)<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_nii</span>(<span class="hljs-params">path</span>):<br>    image = sitk.ReadImage(path)<br>    img_num = sitk.GetArrayFromImage(image)<br>    <span class="hljs-keyword">return</span> img_num<br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    path = <span class="hljs-string">r&quot;D:\myProject\HDC_vessel_seg\datasets\nii\vessel_1.nii&quot;</span><br>    img_num = read_nii(path)<br>    img_num = img_num[<span class="hljs-number">20</span>:<span class="hljs-number">84</span>,...]<br>    slices = img_num.shape[<span class="hljs-number">0</span>]<br>    result = np.zeros(img_num.shape)<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(slices):<br>        sli = img_num[i:i+<span class="hljs-number">1</span>, ...]<br>        s = sli[<span class="hljs-number">0</span>,...]<br>        <span class="hljs-built_in">slice</span> = dilateion(s)<br>        result[i,...] = <span class="hljs-built_in">slice</span><br>    save(result, path.replace(<span class="hljs-string">&quot;vessel_1&quot;</span>, <span class="hljs-string">&quot;dilate_vessel_1&quot;</span>))<br>    save(img_num, path.replace(<span class="hljs-string">&quot;vessel_1&quot;</span>, <span class="hljs-string">&quot;pre_vessel_1&quot;</span>))<br>    <span class="hljs-built_in">print</span>(slices)<br></code></pre></td></tr></table></figure><p>结果：</p><p>未扩张之前：</p><p><img src="/2023/image/1218402-20220521161402224-1022967343.png" alt="" /></p><p>扩张之后：</p><p><img src="/2023/image/1218402-20220521161413788-355952186.png" alt="" /></p><p>&nbsp;</p><div id="translate-man-app" class="content-3WfBL_0" style="background-color: #ffffff; left: -1345px; top: 15px;"><div class="outputBox-qe9A4_0" data-v-2868eb04=""><div class="outputBox-3oESn_0" data-v-2868eb04=""><span class="outputBox-13Ovx_0" data-v-2868eb04="">请看这个博客</span></div><div class="outputBox-1GLb__0" data-v-2868eb04=""><div class="outputBox-it-2__0" data-v-2868eb04="">[Qǐng k&agrave;n zh&egrave;ge b&oacute;k&egrave;]</div><div class="icon-tprjJ_0 outputBox-onVZH_0" data-v-2868eb04=""><img src="chrome-extension://fapgabkkfcaejckbfmfcdgnfefbmlion/static/sound.svg" class="icon-tprjJ_0" /></div></div><div class="outputBox-2sJgr_0" data-v-2868eb04=""><div class="outputBox-GomOI_0" data-v-2868eb04=""><span class="outputBox-2liU7_0" data-v-2868eb04="">Please see this blog</span></div></div><div class="outputBox-17RAm_0" style="display: none;" data-v-2868eb04="">&nbsp;</div></div></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>opencv</tag>
      
      <tag>图像膨胀</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于BarchNorm的一些学习</title>
    <link href="/2022/%E5%85%B3%E4%BA%8EBarchNorm%E7%9A%84%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0/"/>
    <url>/2022/%E5%85%B3%E4%BA%8EBarchNorm%E7%9A%84%E4%B8%80%E4%BA%9B%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p>《<a href="https://arxiv.org/pdf/1502.03167.pdf" target="_blank">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a>》</p><p>1、Batch Normalization 并不能缓解深度网络梯度爆炸问题，反而是梯度爆炸的原因。一般通多跳跃连接，或者残差连接解决这个问题。参考论文《<a href="https://arxiv.org/abs/1902.08129" target="_blank">A Mean Field Theory of Batch Normalization</a>》</p><p>2、Batch Normalization 成功的一个原因可能是将权重向量进行了解耦，分别解耦成方向和长度，然后分别训练。这可以加快收敛</p><p>3、Batch Normalization 并不能缓解<a href="https://blog.csdn.net/boke14122621/article/details/104331385" target="_blank">内部协变量偏移</a>。参考论文《<a href="https://arxiv.org/abs/1805.11604" target="_blank">How Does Batch Normalization Help Optimization?</a>》，<a href="https://www.cnblogs.com/guoyaohua/p/8724433.html" target="_blank">这篇文章</a>也在一定程度上解释了这个问题。</p><p>4、Batch Normalization 另一个成功的原因可能是产生了更平滑的参数空间和更平滑的梯度。参考论文《<a href="https://arxiv.org/abs/1805.11604" target="_blank">How Does Batch Normalization Help Optimization?</a>》</p><p>5、Batch Normalization 可以缓解梯度消失问题。在网络层数加深的时候，会影响我们每一层输出的数据分布。而之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近（以Sigmoid函数为例），所以这导致后向传播时低层神经网络的梯度很小甚至消失，这是训练深层神经网络收敛越来越慢的本质原因，而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，所以就可以让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。</p><p>6、Batch Normalization：训练阶段使用Batch Normalization，推理阶段不使用Batch Normalization（由于在推理阶段，输入实例只有一个，看不到Mini-Batch其他实例，所以无法得到均值和方差。但是我们可以从训练实例中获得Mini-Batch里面m个训练实例获得的均值和方差的统计量。我们可以获取到训练实例全局统计量，对这些均值和方差求出其对应的数学期望，就可以得到我们需要的均值和期望，然后利用每个层已经有对应训练好的scale和shift，就可以在推理阶段对每个神经元的激活数据计算NB进行变换了。</p><div id="translate-man-app" class="content-3WfBL_0" style="background-color: #ffffff; left: -1041px; top: 37px;"><div class="outputBox-qe9A4_0" data-v-2868eb04=""><div class="outputBox-2sJgr_0" data-v-2868eb04=""><div class="outputBox-GomOI_0" data-v-2868eb04="">&nbsp;</div></div><div class="outputBox-17RAm_0" style="display: none;" data-v-2868eb04="">&nbsp;</div></div></div>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>BarchNorm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CNN每层卷积结果视觉展示（3Dircadb肝脏数据为例）</title>
    <link href="/2022/CNN%E6%AF%8F%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%BB%93%E6%9E%9C%E8%A7%86%E8%A7%89%E5%B1%95%E7%A4%BA%EF%BC%883Dircadb%E8%82%9D%E8%84%8F%E6%95%B0%E6%8D%AE%E4%B8%BA%E4%BE%8B%EF%BC%89/"/>
    <url>/2022/CNN%E6%AF%8F%E5%B1%82%E5%8D%B7%E7%A7%AF%E7%BB%93%E6%9E%9C%E8%A7%86%E8%A7%89%E5%B1%95%E7%A4%BA%EF%BC%883Dircadb%E8%82%9D%E8%84%8F%E6%95%B0%E6%8D%AE%E4%B8%BA%E4%BE%8B%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p>试着展示了肝脏每层卷积之后的结果。代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn<br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br> <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">change_indenty</span>(<span class="hljs-params">ct</span>):<br>    ct[ct &lt; <span class="hljs-number">40</span>] = <span class="hljs-number">40</span><br>    ct[ct &gt; <span class="hljs-number">400</span>] = <span class="hljs-number">400</span><br>    <span class="hljs-keyword">return</span> ct<br> <br><span class="hljs-keyword">class</span> <span class="hljs-title class_">Dialte</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num</span>):<br>        <span class="hljs-built_in">super</span>(Dialte, self).__init__()<br>        self.num= num<br>        self.act = nn.ReLU(inplace=<span class="hljs-literal">False</span>)<br>        self.norm = nn.BatchNorm3d<br>        self.conv1 = nn.Sequential(<br>            nn.Conv3d(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>, kernel_size=<span class="hljs-number">3</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">1</span>),<br>            self.act,<br>            self.norm(<span class="hljs-number">1</span>)<br>        )<br> <br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num):<br>            x = self.conv1(x)<br>        <span class="hljs-keyword">return</span> x<br> <br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    path = <span class="hljs-string">r&quot;D:\myProject\HDC_vessel_seg\datasets\nii\image_2.nii&quot;</span><br>    image = sitk.ReadImage(path)<br>    img_num = sitk.GetArrayFromImage(image)<br>    img_num = change_indenty(img_num)<br>    img_num = np.expand_dims(np.expand_dims(img_num, axis=<span class="hljs-number">0</span>), axis=<span class="hljs-number">0</span>).astype(np.float32)<br>    img_num = torch.from_numpy(img_num)<br>    <span class="hljs-built_in">print</span>(img_num.shape)<br> <br>    <span class="hljs-comment"># image = torch.randn(1*3*8*8*8).reshape(1,3,8,8,8)</span><br>    model = Dialte(num=<span class="hljs-number">5</span>)<br>    x = model(img_num)<br>    <span class="hljs-comment"># x = img_num  # 展示原始图像</span><br>    x = x[<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,...]<br>    x = x.cpu().data.numpy()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;x&quot;</span>,x.shape)<br>    predict_seg = sitk.GetImageFromArray(x)<br>    predict_seg.SetSpacing(image.GetSpacing())<br>    predict_seg.SetOrigin(image.GetOrigin())<br>    predict_seg.SetDirection(image.GetDirection())<br>    <span class="hljs-comment"># sitk.WriteImage(predict_seg, path.replace(&quot;vessel&quot;, &quot;dialte&quot;))</span><br>    sitk.WriteImage(predict_seg, path.replace(<span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;pre_image&quot;</span>))<br></code></pre></td></tr></table></figure><p>　　结果：</p><p>原始<img src="/2023/image/1218402-20220516183503773-1798622121.png" alt="" /></p><p>&nbsp;</p><p>第一层：<img src="/2023/image/1218402-20220516183510870-1651924415.png" alt="" /></p><p>&nbsp;</p><p>第二层：<img src="/2023/image/1218402-20220516183518411-233374015.png" alt="" /></p><p>&nbsp;</p><p>第三层：<img src="/2023/image/1218402-20220516183527263-789460457.png" alt="" /></p><p>&nbsp;</p><p>第四层：<img src="/2023/image/1218402-20220516183536872-1634414705.png" alt="" /></p><p>&nbsp;</p><p>第五层：<img src="/2023/image/1218402-20220516183547097-96024417.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CNN</tag>
      
      <tag>卷积结果视觉展示</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用csv文件信息，将图片名信息保存到csv文件当中</title>
    <link href="/2022/%E5%88%A9%E7%94%A8csv%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%B0%86%E5%9B%BE%E7%89%87%E5%90%8D%E4%BF%A1%E6%81%AF%E4%BF%9D%E5%AD%98%E5%88%B0csv%E6%96%87%E4%BB%B6%E5%BD%93%E4%B8%AD/"/>
    <url>/2022/%E5%88%A9%E7%94%A8csv%E6%96%87%E4%BB%B6%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%B0%86%E5%9B%BE%E7%89%87%E5%90%8D%E4%BF%A1%E6%81%AF%E4%BF%9D%E5%AD%98%E5%88%B0csv%E6%96%87%E4%BB%B6%E5%BD%93%E4%B8%AD/</url>
    
    <content type="html"><![CDATA[<p>我们可以利用train.csv文件信息，&nbsp;再结合给定的文件路径（path）信息，可以将给定字目录下的图片名信息整合到scv文件当中。</p><p>train.csv文件格式：</p><p><img src="/2023/image/1218402-20220507201606154-770923107.png" alt="" /></p><p>图片名信息：</p><p><img src="/2023/image/1218402-20220507201658992-453440219.png" alt="" /></p><p>代码如下:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> glob <span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><span class="hljs-keyword">import</span> os<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">enrich_data</span>(<span class="hljs-params">df, sdir=<span class="hljs-string">&quot;train&quot;</span></span>):<br>    imgs = glob(os.path.join(DATASET_FOLDER, sdir, <span class="hljs-string">&quot;case*&quot;</span>, <span class="hljs-string">&quot;case*_day*&quot;</span>, <span class="hljs-string">&quot;scans&quot;</span>, <span class="hljs-string">&quot;*.png&quot;</span>))<br>    img_folders = [os.path.dirname(p).split(os.path.sep) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> imgs]<br>    img_names = [os.path.splitext(os.path.basename(p))[<span class="hljs-number">0</span>].split(<span class="hljs-string">&quot;_&quot;</span>) <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> imgs]<br>    img_keys = [<span class="hljs-string">f&quot;<span class="hljs-subst">&#123;f[-<span class="hljs-number">2</span>]&#125;</span>_slice_<span class="hljs-subst">&#123;n[<span class="hljs-number">1</span>]&#125;</span>&quot;</span> <span class="hljs-keyword">for</span> f, n <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_folders, img_names)]<br><br>    <span class="hljs-comment"># print(img_keys[:5])</span><br>    df[<span class="hljs-string">&quot;img_path&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].<span class="hljs-built_in">map</span>(&#123;k: p <span class="hljs-keyword">for</span> k, p <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_keys, imgs)&#125;)<br>    df[<span class="hljs-string">&quot;Case_Day&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].<span class="hljs-built_in">map</span>(&#123;k: f[-<span class="hljs-number">2</span>] <span class="hljs-keyword">for</span> k, f <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_keys, img_folders)&#125;)<br>    df[<span class="hljs-string">&quot;Case&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x.split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">0</span>].replace(<span class="hljs-string">&quot;case&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)))<br>    df[<span class="hljs-string">&quot;Day&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].apply(<span class="hljs-keyword">lambda</span> x: <span class="hljs-built_in">int</span>(x.split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">1</span>].replace(<span class="hljs-string">&quot;day&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)))<br>    df[<span class="hljs-string">&quot;Slice&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].<span class="hljs-built_in">map</span>(&#123;k: <span class="hljs-built_in">int</span>(n[<span class="hljs-number">1</span>]) <span class="hljs-keyword">for</span> k, n <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_keys, img_names)&#125;)<br>    df[<span class="hljs-string">&quot;width&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].<span class="hljs-built_in">map</span>(&#123;k: <span class="hljs-built_in">int</span>(n[<span class="hljs-number">2</span>]) <span class="hljs-keyword">for</span> k, n <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_keys, img_names)&#125;)<br>    df[<span class="hljs-string">&quot;height&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].<span class="hljs-built_in">map</span>(&#123;k: <span class="hljs-built_in">int</span>(n[<span class="hljs-number">3</span>]) <span class="hljs-keyword">for</span> k, n <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_keys, img_names)&#125;)<br>    df[<span class="hljs-string">&quot;spacing1&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].<span class="hljs-built_in">map</span>(&#123;k: <span class="hljs-built_in">float</span>(n[<span class="hljs-number">4</span>]) <span class="hljs-keyword">for</span> k, n <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_keys, img_names)&#125;)<br>    df[<span class="hljs-string">&quot;spacing2&quot;</span>] = df[<span class="hljs-string">&quot;id&quot;</span>].<span class="hljs-built_in">map</span>(&#123;k: <span class="hljs-built_in">float</span>(n[<span class="hljs-number">5</span>]) <span class="hljs-keyword">for</span> k, n <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(img_keys, img_names)&#125;)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-comment"># df_ssub = pd.read_csv(os.path.join(DATASET_FOLDER, &quot;sample_submission.csv&quot;))</span><br>    DATASET_FOLDER = <span class="hljs-string">&quot;D:\compation\kaggle&quot;</span><br>    df_ssub = pd.read_csv(os.path.join(DATASET_FOLDER, <span class="hljs-string">&quot;train.csv&quot;</span>,<span class="hljs-string">&quot;traines.csv&quot;</span>))<br>    enrich_data(df_ssub,<span class="hljs-string">&quot;traines&quot;</span>)<br>    df_ssub.to_csv(<span class="hljs-string">&quot;df.csv&quot;</span>)<br>    <span class="hljs-built_in">print</span>(df_ssub[<span class="hljs-string">&quot;Case_Day&quot;</span>][<span class="hljs-number">4</span>])<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2023/image/1218402-20220507202035257-1005878810.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>csv文件读取</tag>
      
      <tag>csv文件存储</tag>
      
      <tag>图片名保存到csv文件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用3D标签，生成RLE标签编码，并保存到csv文件</title>
    <link href="/2022/%E5%88%A9%E7%94%A83D%E6%A0%87%E7%AD%BE%EF%BC%8C%E7%94%9F%E6%88%90RLE%E6%A0%87%E7%AD%BE%E7%BC%96%E7%A0%81%EF%BC%8C%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%88%B0csv%E6%96%87%E4%BB%B6/"/>
    <url>/2022/%E5%88%A9%E7%94%A83D%E6%A0%87%E7%AD%BE%EF%BC%8C%E7%94%9F%E6%88%90RLE%E6%A0%87%E7%AD%BE%E7%BC%96%E7%A0%81%EF%BC%8C%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%88%B0csv%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8from glob import globimport osimport SimpleITK as sitkfrom pathlib import Pathimport numpy as npimport imageioimport pandas as pd</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rle_encode</span>(<span class="hljs-params">mask, bg = <span class="hljs-number">0</span></span>) -&gt; <span class="hljs-built_in">dict</span>:<br>    vec = mask.flatten()<br>    nb = <span class="hljs-built_in">len</span>(vec)<br>    where = np.flatnonzero<br>    starts = np.r_[<span class="hljs-number">0</span>, where(~np.isclose(vec[<span class="hljs-number">1</span>:], vec[:-<span class="hljs-number">1</span>], equal_nan=<span class="hljs-literal">True</span>)) + <span class="hljs-number">2</span>]<br>    lengths = np.diff(np.r_[starts, nb])<br>    values = vec[starts]<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(starts) == <span class="hljs-built_in">len</span>(lengths) == <span class="hljs-built_in">len</span>(values)<br>    rle = &#123;&#125;<br>    <span class="hljs-keyword">for</span> start, length, val <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(starts, lengths, values):<br>        <span class="hljs-keyword">if</span> val == bg:<br>            <span class="hljs-keyword">continue</span><br>        rle[val] = rle.get(val, []) + [<span class="hljs-built_in">str</span>(start), length]<br>    <span class="hljs-comment"># post-processing</span><br>    rle = &#123;lb: <span class="hljs-string">&quot; &quot;</span>.join(<span class="hljs-built_in">map</span>(<span class="hljs-built_in">str</span>, id_lens)) <span class="hljs-keyword">for</span> lb, id_lens <span class="hljs-keyword">in</span> rle.items()&#125;<br>    <span class="hljs-keyword">return</span> rle<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_rel</span>(<span class="hljs-params">LABELS, path</span>):<br>    preds = []<br><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(path)):<br>        file = path[i]<br>        file_name = file.split(<span class="hljs-string">&quot;\\&quot;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot;_seg&quot;</span>)[<span class="hljs-number">0</span>]<br>        <span class="hljs-keyword">case</span> = file_name.split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">0</span>]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;case:&#123;&#125;, file_name:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-keyword">case</span>, file_name))<br>        seg = sitk.ReadImage(file)<br>        seg = sitk.GetArrayFromImage(seg)<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(seg.shape[<span class="hljs-number">0</span>]):<br>            <span class="hljs-keyword">if</span> j&gt;=<span class="hljs-number">0</span> <span class="hljs-keyword">and</span> j&lt;<span class="hljs-number">9</span>:<br>                number = <span class="hljs-built_in">str</span>(<span class="hljs-number">0</span>)+<span class="hljs-built_in">str</span>(<span class="hljs-number">0</span>)+<span class="hljs-built_in">str</span>(<span class="hljs-number">0</span>)+<span class="hljs-built_in">str</span>(j+<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">elif</span> j&gt;=<span class="hljs-number">9</span> <span class="hljs-keyword">and</span> j&lt;<span class="hljs-number">99</span>:<br>                number = <span class="hljs-built_in">str</span>(<span class="hljs-number">0</span>)+<span class="hljs-built_in">str</span>(<span class="hljs-number">0</span>) + <span class="hljs-built_in">str</span>(j+<span class="hljs-number">1</span>)<br>            <span class="hljs-keyword">else</span>:<br>                number = <span class="hljs-built_in">str</span>(<span class="hljs-number">0</span>) + <span class="hljs-built_in">str</span>(j+<span class="hljs-number">1</span>)<br>            name = file_name+<span class="hljs-string">&quot;_slice_&quot;</span>+number<br>            output = seg[j, ...]<br>            Snapshot_img = np.zeros(shape=(seg.shape[<span class="hljs-number">1</span>],seg.shape[<span class="hljs-number">2</span>],<span class="hljs-number">3</span>), dtype=np.uint8)  <span class="hljs-comment"># png设置为3通道</span><br>            Snapshot_img[:, :, <span class="hljs-number">0</span>][np.where(output == <span class="hljs-number">1</span>)] = <span class="hljs-number">1</span>   <span class="hljs-comment">#我们也有3个标签，其中值分别为1,2,3，所以我们需要给每个标签都赋予不同的通道</span><br>            Snapshot_img[:, :, <span class="hljs-number">1</span>][np.where(output == <span class="hljs-number">2</span>)] = <span class="hljs-number">1</span><br>            Snapshot_img[:, :, <span class="hljs-number">2</span>][np.where(output == <span class="hljs-number">3</span>)] = <span class="hljs-number">1</span><br>            rle_lb = rle_encode(Snapshot_img[:, :, <span class="hljs-number">0</span>]) <span class="hljs-keyword">if</span> np.<span class="hljs-built_in">sum</span>(Snapshot_img[:, :, <span class="hljs-number">0</span>]) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> &#123;&#125;<br>            rle_sb = rle_encode(Snapshot_img[:, :, <span class="hljs-number">1</span>]) <span class="hljs-keyword">if</span> np.<span class="hljs-built_in">sum</span>(Snapshot_img[:, :, <span class="hljs-number">1</span>]) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> &#123;&#125;<br>            rle_sto = rle_encode(Snapshot_img[:, :, <span class="hljs-number">2</span>]) <span class="hljs-keyword">if</span> np.<span class="hljs-built_in">sum</span>(Snapshot_img[:, :, <span class="hljs-number">2</span>]) &gt; <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> &#123;&#125;<br>            index = (<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)<br>            rel = [rle_lb, rle_sb, rle_sto]<br>            preds += [&#123;<span class="hljs-string">&quot;id&quot;</span>: name, <span class="hljs-string">&quot;class&quot;</span>: lb, <span class="hljs-string">&quot;predicted&quot;</span>: rle.get(<span class="hljs-number">1</span>, <span class="hljs-string">&quot;&quot;</span>)&#125; <span class="hljs-keyword">for</span> i, rle, lb <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(index, rel, LABELS)]<br>        df_pred = pd.DataFrame(preds)<br>        df_pred.to_csv(<span class="hljs-string">&quot;submission.csv&quot;</span>, index=<span class="hljs-literal">False</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    pred_file = glob(<span class="hljs-string">r&quot;D:\compation\kaggle\3D_preprocess\a\*&quot;</span>)  <span class="hljs-comment"># 获取到该文件夹下所有的标签（3D nii文件）</span><br>    LABELS = (<span class="hljs-string">&quot;large_bowel&quot;</span>, <span class="hljs-string">&quot;small_bowel&quot;</span>, <span class="hljs-string">&quot;stomach&quot;</span>)<br>    generate_rel(LABELS, pred_file)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2023/image/1218402-20220506201537896-1102425362.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>csv文件读取</tag>
      
      <tag>3D标签</tag>
      
      <tag>RLE标签编码</tag>
      
      <tag>csv文件存储</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>主要将子文件下大量图片进行路径编号，并保存到csv文件当中。方便直接从文件读取图片路径以及其他图片信息</title>
    <link href="/2022/%E4%B8%BB%E8%A6%81%E5%B0%86%E5%AD%90%E6%96%87%E4%BB%B6%E4%B8%8B%E5%A4%A7%E9%87%8F%E5%9B%BE%E7%89%87%E8%BF%9B%E8%A1%8C%E8%B7%AF%E5%BE%84%E7%BC%96%E5%8F%B7%EF%BC%8C%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%88%B0csv%E6%96%87%E4%BB%B6%E5%BD%93%E4%B8%AD%E3%80%82%E6%96%B9%E4%BE%BF%E7%9B%B4%E6%8E%A5%E4%BB%8E%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E5%9B%BE%E7%89%87%E8%B7%AF%E5%BE%84%E4%BB%A5%E5%8F%8A%E5%85%B6%E4%BB%96%E5%9B%BE%E7%89%87%E4%BF%A1%E6%81%AF/"/>
    <url>/2022/%E4%B8%BB%E8%A6%81%E5%B0%86%E5%AD%90%E6%96%87%E4%BB%B6%E4%B8%8B%E5%A4%A7%E9%87%8F%E5%9B%BE%E7%89%87%E8%BF%9B%E8%A1%8C%E8%B7%AF%E5%BE%84%E7%BC%96%E5%8F%B7%EF%BC%8C%E5%B9%B6%E4%BF%9D%E5%AD%98%E5%88%B0csv%E6%96%87%E4%BB%B6%E5%BD%93%E4%B8%AD%E3%80%82%E6%96%B9%E4%BE%BF%E7%9B%B4%E6%8E%A5%E4%BB%8E%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96%E5%9B%BE%E7%89%87%E8%B7%AF%E5%BE%84%E4%BB%A5%E5%8F%8A%E5%85%B6%E4%BB%96%E5%9B%BE%E7%89%87%E4%BF%A1%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding: utf-8</span><br><span class="hljs-comment">#主要将子文件下大量图片进行路径编号，并保存到csv文件当中。方便直接从文件读取图片路径以及其他图片信息。</span><br><span class="hljs-comment">#我做的是图像分割，所以存在三类分割区域：[&quot;large_bowel&quot;, &quot;small_bowel&quot;, &quot;stomach&quot;]。</span><br><span class="hljs-comment">#文件路径：train\case*\case*_day*\scans\*</span><br><span class="hljs-keyword">from</span> glob <span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">generate_sub</span>(<span class="hljs-params"><span class="hljs-keyword">case</span></span>):<br>    LABELS = [<span class="hljs-string">&quot;large_bowel&quot;</span>, <span class="hljs-string">&quot;small_bowel&quot;</span>, <span class="hljs-string">&quot;stomach&quot;</span>]  <span class="hljs-comment">#</span><br>    preds = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(<span class="hljs-keyword">case</span>)):<br>        cases = <span class="hljs-keyword">case</span>[i]<br>        case_day = glob(os.path.join(cases, <span class="hljs-string">&quot;*&quot;</span>))<br>        <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(case_day)):<br>            scan = case_day[j]<br>            case_day_name = scan.split(<span class="hljs-string">&quot;\\&quot;</span>)[-<span class="hljs-number">1</span>]<br>            scans = glob(os.path.join(os.path.join(scan, <span class="hljs-string">&quot;scans&quot;</span>), <span class="hljs-string">&quot;*&quot;</span>))<br>            <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(scans)):<br>                file_name_slice = scans[k].split(<span class="hljs-string">&quot;\\&quot;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">1</span>]<br>                fileN = case_day_name+<span class="hljs-string">&quot;_slice_&quot;</span>+ file_name_slice<br>                <span class="hljs-built_in">print</span>(fileN)<br>                preds += [&#123;<span class="hljs-string">&quot;id&quot;</span>: fileN, <span class="hljs-string">&quot;class&quot;</span>: LABELS[i], <span class="hljs-string">&quot;predicted&quot;</span>: <span class="hljs-literal">None</span>&#125; <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(LABELS))]<br>    df_pred = pd.DataFrame(preds)<br>    df_pred.to_csv(<span class="hljs-string">&quot;sample_submission.csv&quot;</span>, index=<span class="hljs-literal">False</span>)<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    <span class="hljs-keyword">case</span> = glob(<span class="hljs-string">r&quot;D:\compation\kaggle\traines\*&quot;</span>)<br>    generate_sub(<span class="hljs-keyword">case</span>)<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2023/image/1218402-20220506200636514-5718321.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>csv文件读取</tag>
      
      <tag>路径存储csv</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用3Dnii标签文件，生成png图片</title>
    <link href="/2022/%E5%88%A9%E7%94%A83Dnii%E6%A0%87%E7%AD%BE%E6%96%87%E4%BB%B6%EF%BC%8C%E7%94%9F%E6%88%90png%E5%9B%BE%E7%89%87/"/>
    <url>/2022/%E5%88%A9%E7%94%A83Dnii%E6%A0%87%E7%AD%BE%E6%96%87%E4%BB%B6%EF%BC%8C%E7%94%9F%E6%88%90png%E5%9B%BE%E7%89%87/</url>
    
    <content type="html"><![CDATA[<p>为了便于直观的看到2D标签，通常会将其转化为png图像，具体代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-keyword">from</span> glob <span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br><span class="hljs-keyword">from</span> pathlib <span class="hljs-keyword">import</span> Path<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> imageio<br>path = glob(<span class="hljs-string">r&quot;D:\compation\kaggle\3D_preprocess\a\*&quot;</span>) <span class="hljs-comment"># 获取到该文件夹下所有的标签（3D nii文件）</span><br>save = Path(<span class="hljs-string">r&quot;D:\compation\kaggle\3D_preprocess\a&quot;</span>)  <span class="hljs-comment"># 保存路径</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(path)):<br>    file = path[i]<br>    file_name = file.split(<span class="hljs-string">&quot;\\&quot;</span>)[-<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot;_seg&quot;</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-keyword">case</span> = file_name.split(<span class="hljs-string">&quot;_&quot;</span>)[<span class="hljs-number">0</span>]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;case:&#123;&#125;, file_name:&#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(<span class="hljs-keyword">case</span>, file_name))<br>    seg = sitk.ReadImage(file)<br>    seg = sitk.GetArrayFromImage(seg)<br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(seg.shape[<span class="hljs-number">0</span>]):<br>        <span class="hljs-comment"># png = np.zeros((seg.shape[1:]))</span><br>        <span class="hljs-comment"># print(&quot;j:&quot;,j)</span><br>        save_path = save / <span class="hljs-keyword">case</span> / file_name /<span class="hljs-string">&quot;scans&quot;</span><br>        name = <span class="hljs-string">&quot;slice_&quot;</span>+<span class="hljs-built_in">str</span>(j)+<span class="hljs-built_in">str</span>(seg.shape[<span class="hljs-number">1</span>]) +<span class="hljs-string">&quot;_&quot;</span>+<span class="hljs-built_in">str</span>(seg.shape[<span class="hljs-number">2</span>])+<span class="hljs-string">&quot;_&quot;</span>+<span class="hljs-built_in">str</span>(<span class="hljs-number">1.5</span>)+<span class="hljs-string">&quot;_&quot;</span>+<span class="hljs-built_in">str</span>(<span class="hljs-number">1.5</span>)<br>        output = seg[j, ...]<br>        Snapshot_img = np.zeros(shape=(seg.shape[<span class="hljs-number">1</span>],seg.shape[<span class="hljs-number">2</span>],<span class="hljs-number">3</span>), dtype=np.uint8)  <span class="hljs-comment"># png设置为3通道</span><br>        Snapshot_img[:, :, <span class="hljs-number">0</span>][np.where(output == <span class="hljs-number">1</span>)] = <span class="hljs-number">255</span>   <span class="hljs-comment">#我们也有3个标签，其中值分别为1,2,3，所以我们需要给每个标签都赋予不同的通道</span><br>        Snapshot_img[:, :, <span class="hljs-number">1</span>][np.where(output == <span class="hljs-number">2</span>)] = <span class="hljs-number">255</span><br>        Snapshot_img[:, :, <span class="hljs-number">2</span>][np.where(output == <span class="hljs-number">3</span>)] = <span class="hljs-number">255</span><br><br><br>        os.makedirs(save_path, exist_ok=<span class="hljs-literal">True</span>)<br>        imageio.imwrite(os.path.join(save_path, name + <span class="hljs-string">&#x27;.png&#x27;</span>), Snapshot_img[:, :, :])<br></code></pre></td></tr></table></figure><p>结果：</p><p><img src="/2023/image/1218402-20220504123559355-111855367.png" alt="" /></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>nii</tag>
      
      <tag>3D</tag>
      
      <tag>nii2png</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用CSV路径文件和.png图像，生成3D原图。并展示部分分割图像</title>
    <link href="/2022/%E5%88%A9%E7%94%A8CSV%E8%B7%AF%E5%BE%84%E6%96%87%E4%BB%B6%E5%92%8C.png%E5%9B%BE%E5%83%8F%EF%BC%8C%E7%94%9F%E6%88%903D%E5%8E%9F%E5%9B%BE%E3%80%82%E5%B9%B6%E5%B1%95%E7%A4%BA%E9%83%A8%E5%88%86%E5%88%86%E5%89%B2%E5%9B%BE%E5%83%8F/"/>
    <url>/2022/%E5%88%A9%E7%94%A8CSV%E8%B7%AF%E5%BE%84%E6%96%87%E4%BB%B6%E5%92%8C.png%E5%9B%BE%E5%83%8F%EF%BC%8C%E7%94%9F%E6%88%903D%E5%8E%9F%E5%9B%BE%E3%80%82%E5%B9%B6%E5%B1%95%E7%A4%BA%E9%83%A8%E5%88%86%E5%88%86%E5%89%B2%E5%9B%BE%E5%83%8F/</url>
    
    <content type="html"><![CDATA[<p>具体代码 ，请看的的<a href="https://gist.github.com/DreamOneYou/4f39272299055183f42cb03b8e98e4e0" target="_blank">github</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>  df = pd.read_csv(<span class="hljs-string">r&#x27;D:/compation/kaggle/train.csv/train.csv&#x27;</span>)  <span class="hljs-comment"># 路径文件</span><br>  list_images = glob(<span class="hljs-string">r&#x27;D:\\compation\\kaggle\\train\\*\\*\\scans\\*.png&#x27;</span>)  <span class="hljs-comment"># 利用glob列出所有.png文件</span><br>  <span class="hljs-comment"># print(df.head())</span><br>  mask_data_not_null = df[df[<span class="hljs-string">&#x27;segmentation&#x27;</span>].notnull()]  <span class="hljs-comment"># 只提取有分割结果的mask</span><br>  <span class="hljs-built_in">print</span>(mask_data_not_null)<br>  index_list = <span class="hljs-built_in">list</span>(mask_data_not_null.index)<br>  image_details = show_image(list_images,show=<span class="hljs-literal">True</span>,create_nii=<span class="hljs-literal">False</span>)   <span class="hljs-comment"># 展示image,可以选择是否保存成nii文件（3D文件）</span><br>  show_mask(index_list, image_details,mask_data_not_null, show=<span class="hljs-literal">True</span>)   <span class="hljs-comment">#展示mask，暂时不知道怎么搞成3D，有会的帮忙补充一下。</span><br></code></pre></td></tr></table></figure><p>train.csv:</p><p><img src="/2023/image/1218402-20220504123953403-781016233.png" alt="" /></p><p>&nbsp;</p><p>展示结果：</p><p><img src="/2023/image/1218402-20220502115145806-111739062.png" alt="" /></p><p><img src="/2023/image/1218402-20220502115210720-2137362928.png" alt="" /></p><p>生成3D图像：</p><p><img src="/2023/image/1218402-20220502115423691-1459085922.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>csv路径文件</tag>
      
      <tag>2Dto3D</tag>
      
      <tag>分割图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用nnUNet跑BraTS脑肿瘤分割预测TC和ET非常低的原因</title>
    <link href="/2022/%E4%BD%BF%E7%94%A8nnUNet%E8%B7%91BraTS%E8%84%91%E8%82%BF%E7%98%A4%E5%88%86%E5%89%B2%E9%A2%84%E6%B5%8BTC%E5%92%8CET%E9%9D%9E%E5%B8%B8%E4%BD%8E%E7%9A%84%E5%8E%9F%E5%9B%A0%E3%80%82/"/>
    <url>/2022/%E4%BD%BF%E7%94%A8nnUNet%E8%B7%91BraTS%E8%84%91%E8%82%BF%E7%98%A4%E5%88%86%E5%89%B2%E9%A2%84%E6%B5%8BTC%E5%92%8CET%E9%9D%9E%E5%B8%B8%E4%BD%8E%E7%9A%84%E5%8E%9F%E5%9B%A0%E3%80%82/</url>
    
    <content type="html"><![CDATA[<p>使用nnUNet跑BraTS脑肿瘤分割预测TC和ET非常低，原来是预测的时候，使用了预处理后的标签。原本标签是：2:WT, 1:TC, 4:ET。但是预处理之后变为：1:WT, 2:TC, 3:ET。所以我们对于最后预测完需要变回原来的标签值。nnUNet需要改动代码位置：<strong>nnunet/inference/segmentation_export.py</strong>。代码只写了我如何修改的。</p><div class="cnblogs_code"><pre>import torch<br />import numpy as np<br />one = torch.ones(9).reshape(1,3,3)<br />two = torch.ones(9).reshape(1,3,3) + 1<br />three = torch.ones(9).reshape(1,3,3) + 2<br />seg_old_size_postprocessed = torch.cat((one, two, three), dim=0)<br />#-----------------------需要添加的代码--------------------------------<br />h, w, t = seg_old_size_postprocessed.shape<br />pre = np.zeros((3, h, w, t), dtype=bool)<br />pre[0] = seg_old_size_postprocessed == 1<br />pre[1] = seg_old_size_postprocessed == 2<br />pre[2] = seg_old_size_postprocessed == 3<br /><br />et = pre[2]  # ET<br />net = np.logical_and(pre[1], np.logical_not(et))  # TC<br />ed = np.logical_and(pre[0], np.logical_not(pre[1]))  # WT<br />labmap = np.zeros(seg_old_size_postprocessed.shape)<br />labmap[et] = 4<br />labmap[net] = 1<br />labmap[ed] = 2<br />#-----------------------需要添加的代码--------------------------------<br />print("change before:\n", seg_old_size_postprocessed)<br />print("change after:\n", labmap)</pre></div><p>结果：<img src="/2023/image/1218402-20220429093338832-87457126.png" alt="" /><img src="/2023/image/1218402-20220429093350482-1394137763.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>nnUNe</tag>
      
      <tag>BraTS肿瘤分割</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python将文件从一个目录移动到另一个目录。附nnUnet使用</title>
    <link href="/2022/python%EF%BC%9A%E5%B0%86%E6%96%87%E4%BB%B6%E4%BB%8E%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E7%A7%BB%E5%8A%A8%E5%88%B0%E5%8F%A6%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E3%80%82%E9%99%84%EF%BC%9AnnUnet%E4%BD%BF%E7%94%A8/"/>
    <url>/2022/python%EF%BC%9A%E5%B0%86%E6%96%87%E4%BB%B6%E4%BB%8E%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E7%A7%BB%E5%8A%A8%E5%88%B0%E5%8F%A6%E4%B8%80%E4%B8%AA%E7%9B%AE%E5%BD%95%E3%80%82%E9%99%84%EF%BC%9AnnUnet%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>在使用nn-Unet做BraTS2019数据集预测时，预测文件分别生成了三类文件：.pkl&nbsp; .npz&nbsp; .nii.gz，我们需要的是.nii.gz文件。所以需要进行文件移动。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># coding:utf-8</span><br><span class="hljs-keyword">import</span> os,shutil<br><span class="hljs-keyword">import</span> time<br>src_path=<span class="hljs-string">f&quot;C:\\Users\\wpx\\Desktop\\result\\nnunet\BraTS2019\OUTPUT_FOLDER\\&quot;</span>  <span class="hljs-comment"># 当前文件所在目录</span><br>target_path=<span class="hljs-string">f&#x27;C:\\Users\\wpx\\Desktop\\result\\nnunet\\BraTS2019\\submit\\&#x27;</span>    <span class="hljs-comment">#移动的指定目录</span><br><span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>    time.sleep(<span class="hljs-number">3</span>)<br>    file_list=os.listdir(src_path)  <span class="hljs-comment"># 获取到当前目录下所有文件</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(file_list)&gt;<span class="hljs-number">0</span>:   <span class="hljs-comment"># 如果目录不为空，那么进行移动</span><br>        <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> file_list:<br>            file_end_name = file.split(<span class="hljs-string">&quot;.&quot;</span>)[-<span class="hljs-number">1</span>]<br>            <span class="hljs-keyword">if</span> file_end_name == <span class="hljs-string">&quot;gz&quot;</span>:  <span class="hljs-comment"># 判断我们需要移动的文件，这里我需要移动的是.gz文件，其他文件不需要移动</span><br>                shutil.move(src_path+file,target_path+file)   <span class="hljs-comment"># 利用这个方法进行移动</span><br>    exit(<span class="hljs-number">0</span>)  <span class="hljs-comment"># 移动完毕，进行退出</span><br></code></pre></td></tr></table></figure><p>如何使用nn-Unet，可以看这篇<a href="https://www.ucloud.cn/yun/122309.html" target="_blank">博客</a>。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>文件移动</tag>
      
      <tag>python实现文件移动</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用KFold交叉验证方法划分训练集和验证集</title>
    <link href="/2022/%E4%BD%BF%E7%94%A8KFold%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%96%B9%E6%B3%95%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E9%AA%8C%E8%AF%81%E9%9B%86/"/>
    <url>/2022/%E4%BD%BF%E7%94%A8KFold%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E6%96%B9%E6%B3%95%E5%88%92%E5%88%86%E8%AE%AD%E7%BB%83%E9%9B%86%E5%92%8C%E9%AA%8C%E8%AF%81%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<p>在进行深度学习时，为了提高精度，或者为了评估我们模型的优劣，以及如何选择一个更好的模型。这样我们就需要用到交叉验证方法。</p><p>我们主要实现如何使用KFold划分训练集和验证集</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">#coding:utf-8<br />from</span> sklearn.model_selection <span style="color: #0000ff;">import</span><span style="color: #000000;"> KFold</span><span style="color: #0000ff;">def</span><span style="color: #000000;"> select_train_val(all_path, seed):    kfold </span>= KFold(5, shuffle=True, random_state=<span style="color: #000000;">seed)    splits </span>=<span style="color: #000000;"> list(kfold.split(patients_dir))    train_datasets </span>=<span style="color: #000000;"> []    val_datasets </span>=<span style="color: #000000;"> []    </span><span style="color: #0000ff;">for</span> n <span style="color: #0000ff;">in</span><span style="color: #000000;"> range(0, fold_number):        train_idx, val_idx </span>=<span style="color: #000000;"> splits[n]        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">first idx of train</span><span style="color: #800000;">"</span><span style="color: #000000;">, train_idx[0])        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">first idx of test</span><span style="color: #800000;">"</span><span style="color: #000000;">, val_idx[0])        train </span>= [patients_dir[i] <span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> train_idx]        val </span>= [patients_dir[i] <span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> val_idx]    </span><span style="color: #0000ff;">return</span><span style="color: #000000;"> train_datasets, val_datasets</span><span style="color: #0000ff;">if</span> <span style="color: #800080;">__name__</span> == <span style="color: #800000;">"</span><span style="color: #800000;">__main__</span><span style="color: #800000;">"</span><span style="color: #000000;">:    </span><span style="color: #0000ff;">from</span> glob <span style="color: #0000ff;">import</span><span style="color: #000000;"> glob    path </span>= r<span style="color: #800000;">"</span><span style="color: #800000;">/home/wpx/BraTS2019/Train/*</span><span style="color: #800000;">"</span><span style="color: #000000;">    all_file </span>=<span style="color: #000000;"> glob(path)    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 这是获取到5折对应的训练集和验证集，我们如果只是的用来划分训练集和验证集，我们最终可以随机选择某一折，比如选第一折划分好的训练集和验证集，可以这样操作：</span>    <span style="color: #008000;">#</span><span style="color: #008000;">train_data, val_data = train_dataset[1], val_dataset[1]</span>    train_dataset, val_dataset = select_train_val(all_file,1234)  </pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>KFold交叉验证</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>三维医学图像数据扩充flipandrotate</title>
    <link href="/2022/%E4%B8%89%E7%BB%B4%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E6%89%A9%E5%85%85%EF%BC%9Aflip%20and%20rotate/"/>
    <url>/2022/%E4%B8%89%E7%BB%B4%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E6%95%B0%E6%8D%AE%E6%89%A9%E5%85%85%EF%BC%9Aflip%20and%20rotate/</url>
    
    <content type="html"><![CDATA[<p>对于小数据量医学图像进行深度学习使，会由于数据量过小而过拟合。因此我们需要采用数据扩充方法，而flip和rotate又是经常用到的，这里做一个简单的实现。</p><p>输入为[batchsize,height, width, channel]。这里是2D医学图像数据增强，我之前应该有写到3D增强，不过2D稍加改动也就可以用于3D。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">random_rotate_brain</span>(<span class="hljs-params">image, label</span>):<br>    bs = image.shape[<span class="hljs-number">0</span>] - <span class="hljs-number">1</span><br>    angle = np.random.randint(-<span class="hljs-number">20</span>, <span class="hljs-number">20</span>)  <span class="hljs-comment"># 设置旋转角度</span><br>    <span class="hljs-comment"># print(&quot;image:&#123;&#125;,label:&#123;&#125;&quot;.format(image.shape, label.shape))</span><br>    channel = [ndimage.rotate(image[bs,:,:, c], angle, order=<span class="hljs-number">0</span>, reshape=<span class="hljs-literal">False</span>) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(image.shape[<span class="hljs-number">3</span>])] <span class="hljs-comment"># 每个通道都做相同的旋转</span><br>    image[bs,...] = np.stack(channel, axis=-<span class="hljs-number">1</span>)<br>    chlabel = [ndimage.rotate(label[bs,:,:, c], angle, order=<span class="hljs-number">0</span>, reshape=<span class="hljs-literal">False</span>) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(label.shape[<span class="hljs-number">3</span>])]  <span class="hljs-comment"># 如果你不想你预测的结果和标签对不上，标签也要进行同样的旋转</span><br>    label[bs, ...] = np.stack(chlabel, axis=-<span class="hljs-number">1</span>) <br>    <span class="hljs-keyword">return</span> image, label<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">random_rot_flip_brain</span>(<span class="hljs-params">image, label</span>):<br>    axes = (<span class="hljs-number">1</span>,<span class="hljs-number">2</span>)  <span class="hljs-comment"># 由于我们需要对height和width做扩充，所以取1,2。如果你输入矩阵第一维就是height和width，那你就需要改动为（0,1）</span><br>    k = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">4</span>)<br>    image = np.rot90(image, k, axes)<br>    label = np.rot90(label, k, axes)<br>    <span class="hljs-comment"># print(&quot;k:&#123;&#125;,img:&#123;&#125;,lab:&#123;&#125;&quot;.format(k, image.shape,label.shape))</span><br>    axis = np.random.randint(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)  <span class="hljs-comment"># 同上，只需对1,2维做扩充</span><br>    image = np.flip(image, axis=axis).copy()<br>    label = np.flip(label, axis=axis).copy()<br>    <span class="hljs-keyword">return</span> image, label<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">RandomGenerator_brain</span>(<span class="hljs-params">x, y</span>):<br>        image, label =x, y<br>　　　　　<span class="hljs-comment"># 不可能全部图像都要做数据扩充吧，设置一个随机数</span><br>        <span class="hljs-keyword">if</span> random.random() &gt; <span class="hljs-number">0.5</span>:<br>            image, label = random_rot_flip_brain(image, label)<br>        <span class="hljs-keyword">elif</span> random.random() &gt; <span class="hljs-number">0.5</span>:<br>            image, label = random_rotate_brain(image, label)<br><br>        <span class="hljs-keyword">return</span> image, label<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据扩充方法</tag>
      
      <tag>三维医学图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python批量删除指定文件目录中多个文件</title>
    <link href="/2022/python%EF%BC%9A%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E4%B8%AD%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6/"/>
    <url>/2022/python%EF%BC%9A%E6%89%B9%E9%87%8F%E5%88%A0%E9%99%A4%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E7%9B%AE%E5%BD%95%E4%B8%AD%E5%A4%9A%E4%B8%AA%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding:utf-8# 任务需要，需要删除多余的文件，手动删除太麻烦，几行python搞定</span><br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> glob <span class="hljs-keyword">import</span> glob<br>path = <span class="hljs-string">r&quot;/media/icml-014/peixu/MyData/2019brain/valid/*&quot;</span> <span class="hljs-comment"># 获取到目录</span><br>all_file = glob(path)  <span class="hljs-comment"># 得到该目录下的所有文件</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(all_file)):<br>    filename = all_file[i]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;filename:&quot;</span>,filename) <span class="hljs-comment">#获取子目录文件名</span><br>    sub_file = os.path.join(path, filename)  <br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;sub_file:&quot;</span>, sub_file)<br>    all_sub_file = glob(os.path.join(sub_file,<span class="hljs-string">&quot;*&quot;</span>))  <span class="hljs-comment"># 得到子目录下所有文件</span><br>    <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(all_sub_file)):<br>        sub_file_name = all_sub_file[j]<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;sub_file_name:&quot;</span>, sub_file_name)<br>        name = sub_file_name.split(<span class="hljs-string">&quot;f32.&quot;</span>)[-<span class="hljs-number">1</span>] <br>        <span class="hljs-keyword">if</span> name ==<span class="hljs-string">&quot;pkl&quot;</span>: <span class="hljs-comment"># 找到自己要删出的文件类型，我删除的文件类型是.pkl文件。</span><br>            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;del_sub_file_name:&quot;</span>, sub_file_name)<br>            os.remove(sub_file_name)   <span class="hljs-comment"># 进行删除</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>批量删除文件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>将读取的.raw文件转换为tensor张量送入网络</title>
    <link href="/2022/%E5%B0%86%E8%AF%BB%E5%8F%96%E7%9A%84.raw%E6%96%87%E4%BB%B6%E8%BD%AC%E6%8D%A2%E4%B8%BAtensor%E5%BC%A0%E9%87%8F%E9%80%81%E5%85%A5%E7%BD%91%E7%BB%9C/"/>
    <url>/2022/%E5%B0%86%E8%AF%BB%E5%8F%96%E7%9A%84.raw%E6%96%87%E4%BB%B6%E8%BD%AC%E6%8D%A2%E4%B8%BAtensor%E5%BC%A0%E9%87%8F%E9%80%81%E5%85%A5%E7%BD%91%E7%BB%9C/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #008000;">#</span><span style="color: #008000;"> coding:utf-8</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as np</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch<p></span><span style="color: #008000;">#</span><span style="color: #008000;"> 首先确定原图片的基本信息：数据格式，行数列数，通道数</span><br>rows&#x3D;886<span style="color: #008000;">#</span><span style="color: #008000;">图像的行数</span><br>cols&#x3D;492<span style="color: #008000;">#</span><span style="color: #008000;">图像的列数</span><br>patchsx &#x3D;<span style="color: #000000;"> rows<br>patchsy </span>&#x3D;<span style="color: #000000;"> cols<br>batchsz </span>&#x3D; 16<span style="color: #000000;"><br>channels </span>&#x3D;1<span style="color: #008000;">#</span><span style="color: #008000;"> 图像的通道数，灰度图为1</span><br>path &#x3D; r<span style="color: #800000;">“</span><span style="color: #800000;">C:\Users\wpx\Desktop\111.raw</span><span style="color: #800000;">“</span><br><span style="color: #008000;">#</span><span style="color: #008000;"> 读取.raw文件到nparray类型</span><br>content &#x3D; open(path, <span style="color: #800000;">‘</span><span style="color: #800000;">rb</span><span style="color: #800000;">‘</span><span style="color: #000000;">).read()<br>samples_ref </span>&#x3D; np.frombuffer(content, dtype&#x3D;<span style="color: #800000;">‘</span><span style="color: #800000;">uint16</span><span style="color: #800000;">‘</span>).reshape((-1, 886, 492<span style="color: #000000;">))<br></span><span style="color: #008000;">#</span><span style="color: #008000;">创建一个类型为floap32的nparray类型，方便之后转换为tensor张量送入深度学习网络当中</span><br>batch_inp_np &#x3D; np.zeros((1, patchsx, patchsy), dtype &#x3D; <span style="color: #800000;">‘</span><span style="color: #800000;">float32</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 将我们读取出来的raw文件内容放入到我们创建的文件当中</span><br>batch_inp_np[0, :, :] &#x3D; np.float32(samples_ref[0,:, :]) * np.float32(1 &#x2F; 65536<span style="color: #000000;">)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> nparray -&gt; torch转换类型</span><br><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">img</span><span style="color: #800000;">“</span><span style="color: #000000;">,batch_inp_np.shape)<br>img_tensor </span>&#x3D;<span style="color: #000000;"> torch.from_numpy(batch_inp_np)<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">image_tensor</span><span style="color: #800000;">“</span>,img_tensor.shape)</pre></p></div><p>结果：</p><p><img src="/2023/image/1218402-20220319154434726-677137983.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>.raw数据转为tensor</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>读取.raw格式文件（学习记录）</title>
    <link href="/2022/%E8%AF%BB%E5%8F%96.raw%E6%A0%BC%E5%BC%8F%E6%96%87%E4%BB%B6%EF%BC%88%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%89/"/>
    <url>/2022/%E8%AF%BB%E5%8F%96.raw%E6%A0%BC%E5%BC%8F%E6%96%87%E4%BB%B6%EF%BC%88%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span> cv2  <span style="color: #008000;">#</span><span style="color: #008000;">OpenCV包</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as np<p></span><span style="color: #008000;">#</span><span style="color: #008000;"> 首先确定原图片的基本信息：数据格式，行数列数，通道数</span><br>rows&#x3D;886<span style="color: #008000;">#</span><span style="color: #008000;">图像的行数</span><br>cols&#x3D;492<span style="color: #008000;">#</span><span style="color: #008000;">图像的列数</span><br>channels &#x3D;1<span style="color: #008000;">#</span><span style="color: #008000;"> 图像的通道数，灰度图为1</span><br>path &#x3D; r<span style="color: #800000;">“</span><span style="color: #800000;">C:\Users\wpx\Desktop\111.raw</span><span style="color: #800000;">“</span><br><span style="color: #008000;">#</span><span style="color: #008000;"> 利用numpy的fromfile函数读取raw文件，并指定数据格式</span><br>img&#x3D;np.fromfile(path, dtype&#x3D;<span style="color: #800000;">‘</span><span style="color: #800000;">uint16</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 利用numpy中array的reshape函数将读取到的数据进行重新排列。</span><br>img&#x3D;<span style="color: #000000;">img.reshape(rows, cols, channels)</p><p></span><span style="color: #008000;">#</span><span style="color: #008000;"> 展示图像</span><br>cv2.imshow(<span style="color: #800000;">‘</span><span style="color: #800000;">Infared image-886*492-16bit</span><span style="color: #800000;">‘</span><span style="color: #000000;">,img)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 如果是uint16的数据请先转成uint8。不然的话，显示会出现问题。</span><br><span style="color: #000000;">cv2.waitKey()<br>cv2.destroyAllWindows()<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">ok</span><span style="color: #800000;">‘</span>)</pre></p></div><p>读取之前：</p><p><img src="/2023/image/1218402-20220317163354168-1364445161.png" alt="" /></p><p>&nbsp;</p><p>读取之后：</p><p><img src="/2023/image/1218402-20220317163341167-1821709368.png" alt="" /></p><p>问题是我读取的类型高错了，但是我试了很多类型依旧计算不对。懒得搞了，之后找到问题在解决。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>.raw文件操作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>三维医学图像深度学习，数据增强方法（monai）RandHistogramShiftD,Flipd,Rotate90d</title>
    <link href="/2022/%E4%B8%89%E7%BB%B4%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95%EF%BC%88monai%EF%BC%89%EF%BC%9ARandHistogramShiftD,%20Flipd,%20Rotate90d/"/>
    <url>/2022/%E4%B8%89%E7%BB%B4%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%EF%BC%8C%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95%EF%BC%88monai%EF%BC%89%EF%BC%9ARandHistogramShiftD,%20Flipd,%20Rotate90d/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding:utf-8</span><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> monai.transforms <span class="hljs-keyword">import</span> Compose, RandHistogramShiftD, Flipd, Rotate90d<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br><span class="hljs-comment"># start a chain of transforms</span><br>KEYS = (<span class="hljs-string">&quot;image&quot;</span>, <span class="hljs-string">&quot;label&quot;</span>)<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">aug</span>():<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        self.random_rotated = Compose([<br>            Rotate90d(KEYS, k=<span class="hljs-number">1</span>, spatial_axes=(<span class="hljs-number">2</span>,<span class="hljs-number">3</span>),allow_missing_keys=<span class="hljs-literal">True</span>),<br>            Flipd(KEYS, spatial_axis=(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>),allow_missing_keys=<span class="hljs-literal">True</span>),<br>            RandHistogramShiftD(KEYS,  prob=<span class="hljs-number">1</span>, num_control_points=<span class="hljs-number">30</span>, allow_missing_keys=<span class="hljs-literal">True</span>),<br>            <span class="hljs-comment"># ToTensorD(KEYS),</span><br>        ])<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self,x</span>):<br>        x = self.random_rotated(x)<br>        <span class="hljs-keyword">return</span> x<br><br><span class="hljs-comment"># start a dataset</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">before_x, after_x, new_path,new_name=<span class="hljs-string">&quot;&quot;</span></span>):<br>    after_x = after_x[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>,...]<br>    <span class="hljs-keyword">if</span> new_name==<span class="hljs-string">&quot;image&quot;</span>:<br>        ct = sitk.ReadImage(before_x, sitk.sitkInt16)<br>    <span class="hljs-keyword">else</span>:<br>        ct = sitk.ReadImage(before_x, sitk.sitkUInt8)<br>    predict_seg = sitk.GetImageFromArray(after_x)<br>    predict_seg.SetDirection(ct.GetDirection())<br>    predict_seg.SetOrigin(ct.GetOrigin())<br>    predict_seg.SetSpacing(ct.GetSpacing())<br><br>    sitk.WriteImage(predict_seg,new_path)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    image = <span class="hljs-string">r&quot;D:\MyData\3Dircadb1_fusion_date\image_2.nii&quot;</span>   <span class="hljs-comment"># 原图</span><br>    label = <span class="hljs-string">r&quot;D:\MyData\3Dircadb1_fusion_date\liver_2.nii&quot;</span>   <span class="hljs-comment">#标签</span><br>    new_path = <span class="hljs-string">r&quot;D:\MyData\3Dircadb1_fusion_date\image_0.nii&quot;</span>  <span class="hljs-comment">#增强后的原图</span><br>    new_path1 = <span class="hljs-string">r&quot;D:\MyData\3Dircadb1_fusion_date\liver_1.nii&quot;</span>  <span class="hljs-comment">#增强后的标签</span><br><br>    ct = sitk.ReadImage(image)<br>    ct1 = sitk.GetArrayFromImage(ct)<br>    seg = sitk.ReadImage(label)<br>    seg1 = sitk.GetArrayFromImage(seg)<br><br>    ct = ct1[<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>,...]<br>    seg = seg1[<span class="hljs-literal">None</span>, <span class="hljs-literal">None</span>,...]<br><br>    ct = torch.from_numpy(ct)<br>    seg = torch.from_numpy(seg)<br>    m = &#123;<span class="hljs-string">&quot;image&quot;</span>: ct,<br>         <span class="hljs-string">&quot;label&quot;</span>:seg&#125;<br>    augs = aug()<br>    <span class="hljs-built_in">print</span>(m[<span class="hljs-string">&quot;image&quot;</span>].shape)<br>    data_dict= augs.forward(m)<br><br>    save(image, data_dict[<span class="hljs-string">&quot;image&quot;</span>], new_path, <span class="hljs-string">&quot;image&quot;</span>)<br>    save(label, data_dict[<span class="hljs-string">&quot;label&quot;</span>], new_path1, <span class="hljs-string">&quot;label&quot;</span>)<br><br><br>    <span class="hljs-built_in">print</span>(data_dict[<span class="hljs-string">&quot;image&quot;</span>].shape)<br>    plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>);<br>    plt.imshow(ct1[<span class="hljs-number">66</span>,...])<br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>);<br>    plt.imshow(data_dict[<span class="hljs-string">&quot;image&quot;</span>][<span class="hljs-number">0</span>,<span class="hljs-number">0</span>, <span class="hljs-number">66</span>,...])<br>    plt.subplot(<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">3</span>);<br>    plt.imshow(data_dict[<span class="hljs-string">&quot;label&quot;</span>][<span class="hljs-number">0</span>,<span class="hljs-number">0</span>, <span class="hljs-number">66</span>,...])<br>    plt.show()<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数据扩充方法</tag>
      
      <tag>三维医学图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对三维医学图像进行拼接，调整窗宽窗位</title>
    <link href="/2022/%E5%AF%B9%E4%B8%89%E7%BB%B4%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5%EF%BC%8C%E8%B0%83%E6%95%B4%E7%AA%97%E5%AE%BD%E7%AA%97%E4%BD%8D%E3%80%82/"/>
    <url>/2022/%E5%AF%B9%E4%B8%89%E7%BB%B4%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E6%8B%BC%E6%8E%A5%EF%BC%8C%E8%B0%83%E6%95%B4%E7%AA%97%E5%AE%BD%E7%AA%97%E4%BD%8D%E3%80%82/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs python">窗宽指CT图像所显示的CT 值范围，在此CT值范围内的组织和病变均以不<br>同的模拟灰度显示窗位（窗中心）指窗宽范围内均值或中心值，如果窗宽<br>为100Hu，当窗位为中心 0Hu，则CT值的范围为-50Hu ~ +50Hu；当窗位<br>为中心 +35Hu，则CT值的范围为-15Hu ~ +85Hu；<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">infer_tumorandliver</span>(<span class="hljs-params">model, ct_array_nor, cube_shape=(<span class="hljs-params"><span class="hljs-number">129</span>, <span class="hljs-number">512</span>, <span class="hljs-number">512</span></span>)</span>):<br>    patch_size = cube_shape  <span class="hljs-comment"># 送入网络时的patch大小</span><br>    patch_stride = [<span class="hljs-number">60</span>, <span class="hljs-number">256</span>, <span class="hljs-number">256</span>] <span class="hljs-comment"># 重叠部位大小</span><br><br>    locations, image_shape = generate_test_locations(ct_array_nor, patch_size, patch_stride)  <span class="hljs-comment"># 生成步长与图像shape</span><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;location&#x27;</span>, locations, image_shape)<br><br>    image = np.zeros((<span class="hljs-number">1</span>,) + (ct_array_nor.shape)).astype(np.float32) <span class="hljs-comment"># 生成与原图对应大小的全0体积图像，用于保存预测结果图</span><br>    seg = np.zeros((ct_array_nor.shape)).astype(np.float32)<span class="hljs-comment"># 生成与原图对应大小的全0体积图像，用于除去重叠部位</span><br><br><br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&#x27;image shape&#x27;</span>, image.shape)<br><br>    <span class="hljs-keyword">for</span> z <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, locations[<span class="hljs-number">0</span>]):<br>        zs = <span class="hljs-built_in">min</span>(patch_stride[<span class="hljs-number">0</span>] * z, image_shape[<span class="hljs-number">0</span>] - patch_size[<span class="hljs-number">0</span>])<br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, locations[<span class="hljs-number">1</span>]):<br>            xs = <span class="hljs-built_in">min</span>(patch_stride[<span class="hljs-number">1</span>] * x, image_shape[<span class="hljs-number">1</span>] - patch_size[<span class="hljs-number">1</span>])<br>            <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, locations[<span class="hljs-number">2</span>]):<br>                ys = <span class="hljs-built_in">min</span>(patch_stride[<span class="hljs-number">2</span>] * y, image_shape[<span class="hljs-number">2</span>] - patch_size[<span class="hljs-number">2</span>])<br><br>                patch = ct_array_nor[zs:zs + patch_size[<span class="hljs-number">0</span>],<br>                        xs:xs + patch_size[<span class="hljs-number">1</span>],<br>                        ys:ys + patch_size[<span class="hljs-number">2</span>]]<br>                <span class="hljs-comment"># print(&#x27;patch&#x27;,patch)</span><br>                patch = np.expand_dims(np.expand_dims(patch, axis=<span class="hljs-number">0</span>), axis=<span class="hljs-number">0</span>).astype(np.float32)<br><br>                <span class="hljs-comment"># 适用于深度学习预测</span><br>                <span class="hljs-comment"># patch_tensor = torch.from_numpy(patch).cuda()</span><br>                <span class="hljs-comment"># output = model(patch_tensor)</span><br>                <span class="hljs-comment"># output = output.cpu().data.numpy()</span><br><br>                <span class="hljs-comment"># 适用于正常拼接</span><br>                patch_tensor = torch.from_numpy(patch).cuda()<br>                output = patch_tensor.cpu().data.numpy()<br><br>                image[:, zs:zs + patch_size[<span class="hljs-number">0</span>], xs:xs + patch_size[<span class="hljs-number">1</span>], ys:ys + patch_size[<span class="hljs-number">2</span>]] \<br>                    = image[:, zs:zs + patch_size[<span class="hljs-number">0</span>], xs:xs + patch_size[<span class="hljs-number">1</span>], ys:ys + patch_size[<span class="hljs-number">2</span>]] + output[<span class="hljs-number">0</span>, <span class="hljs-number">0</span>,<br>                                                                                                          :, :, :]<br><br>                seg[zs:zs + patch_size[<span class="hljs-number">0</span>], xs:xs + patch_size[<span class="hljs-number">1</span>], ys:ys + patch_size[<span class="hljs-number">2</span>]] \<br>                    = seg[zs:zs + patch_size[<span class="hljs-number">0</span>], xs:xs + patch_size[<span class="hljs-number">1</span>], ys:ys + patch_size[<span class="hljs-number">2</span>]] + <span class="hljs-number">1</span><br><br><br>    image = image / np.expand_dims(seg, axis=<span class="hljs-number">0</span>)<br><br><br>    image = np.squeeze(image)<br>    <br>    <span class="hljs-comment"># 可以对图像进行窗宽窗位调整</span><br>    image[image&lt;<span class="hljs-number">50</span>] = <span class="hljs-number">0</span><br>    image[image&gt;<span class="hljs-number">400</span>] =<span class="hljs-number">400</span><br>    mask_pred_containers = image<br><br>    <span class="hljs-comment"># 弄回pad前大小</span><br>    <span class="hljs-keyword">return</span> mask_pred_containers<br></code></pre></td></tr></table></figure><p>因为我做了图像强度变化，所以前后存在一些不一致，但是不影响拼接结果。</p><p>图像拼接前：</p><p><img src="/2023/image/1218402-20220304170330988-1916118888.png" alt="" /></p><p>拼接后：</p><p><img src="/2023/image/1218402-20220304170359156-1519632988.png" alt="" /></p><p>具体代码，请看我的：<a href="https://gist.github.com/DreamOneYou/e00ccfd8cde07a048b20e628f4da0b8a" target="_blank">github</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>三维医学图像</tag>
      
      <tag>窗宽窗位</tag>
      
      <tag>图像拼接</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>npy转换为png和nii文件</title>
    <link href="/2022/npy%E8%BD%AC%E6%8D%A2%E4%B8%BApng%E5%92%8Cnii%E6%96%87%E4%BB%B6/"/>
    <url>/2022/npy%E8%BD%AC%E6%8D%A2%E4%B8%BApng%E5%92%8Cnii%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment">#coding:utf-8</span><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> skimage.transform <span class="hljs-keyword">import</span> resize<br><span class="hljs-keyword">from</span> glob <span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> SimpleITK <span class="hljs-keyword">as</span> sitk<br>file_dir = <span class="hljs-string">r&quot;D:\MyData\3Dircadb1_fusion_date\npy\train_image\*&quot;</span>  <span class="hljs-comment"># npy文件路径</span><br>dest_dir = <span class="hljs-string">r&quot;D:\MyData\3Dircadb1_fusion_date\png&quot;</span>  <span class="hljs-comment"># 文件存储的路径</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">npy_png</span>(<span class="hljs-params">file_dir, dest_dir</span>):<br>    <span class="hljs-comment"># 如果不存在对应文件，则创建对应文件</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(dest_dir):<br>        os.makedirs(dest_dir)<br>    path = glob(file_dir)<br>    k=<span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> path:<br>        arr = np.load(file)<br>        z = arr.shape[<span class="hljs-number">0</span>] <span class="hljs-comment"># 获取Z轴大小</span><br>        k += <span class="hljs-number">1</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span>  <span class="hljs-built_in">range</span>(z-<span class="hljs-number">1</span>):  <span class="hljs-comment"># 因为是npy是三维的，但是png二维显示，所以我按照Z轴切片进行保存展示</span><br>            arr1 = arr[i:i+<span class="hljs-number">1</span>,...] <span class="hljs-comment">#每次增长1 slice</span><br>            arr2 = arr1[<span class="hljs-number">0</span>, ...] <span class="hljs-comment"># 将其转换为两维，因为Z轴当前为1，可以省略。</span><br>            disp_to_img = resize(arr2, [<span class="hljs-number">128</span>, <span class="hljs-number">128</span>])<br>            plt.imsave(os.path.join(dest_dir, <span class="hljs-string">&quot;&#123;&#125;_&#123;&#125;_disp.png&quot;</span>.<span class="hljs-built_in">format</span>(k,i)), disp_to_img, cmap=<span class="hljs-string">&#x27;plasma&#x27;</span>)  <span class="hljs-comment"># 定义命名规则，保存图片为彩色模式</span><br>        <span class="hljs-comment">## npy文件转换为nii文件</span><br>        <span class="hljs-comment"># sitk_img = sitk.GetImageFromArray(arr, isVector=False)</span><br>        <span class="hljs-comment"># sitk.WriteImage(sitk_img, os.path.join(dest_dir, str(i) + &quot;.nii&quot;))</span><br>        <span class="hljs-comment"># print(&#x27;file_name:&#123;&#125;&#x27;.format(file))</span><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    npy_png(file_dir, dest_dir)<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>npy2png</tag>
      
      <tag>npy2nii</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>批量读取nii文件的shape</title>
    <link href="/2022/%E6%89%B9%E9%87%8F%E8%AF%BB%E5%8F%96nii%E6%96%87%E4%BB%B6%E7%9A%84shape/"/>
    <url>/2022/%E6%89%B9%E9%87%8F%E8%AF%BB%E5%8F%96nii%E6%96%87%E4%BB%B6%E7%9A%84shape/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> SimpleITK as sitk</span><span style="color: #0000ff;">from</span> glob <span style="color: #0000ff;">import</span><span style="color: #000000;"> glob</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> ospath </span>= glob(r<span style="color: #800000;">"</span><span style="color: #800000;">D:\MyData\date\*</span><span style="color: #800000;">"</span><span style="color: #000000;">)n </span>=<span style="color: #000000;"> len(path)res </span>=<span style="color: #000000;"> []</span><span style="color: #0000ff;">for</span> file <span style="color: #0000ff;">in</span><span style="color: #000000;"> path:    </span><span style="color: #008000;">#</span><span style="color: #008000;"> print(file)</span>    file_name = os.path.join(os.path.join(file, <span style="color: #800000;">"</span><span style="color: #800000;">image</span><span style="color: #800000;">"</span>), <span style="color: #800000;">"</span><span style="color: #800000;">sample.nii</span><span style="color: #800000;">"</span><span style="color: #000000;">)    im </span>=<span style="color: #000000;"> sitk.ReadImage(file_name)    image </span>=<span style="color: #000000;"> sitk.GetArrayFromImage(im)    res.append(image.shape[0])    </span><span style="color: #0000ff;">print</span><span style="color: #000000;">(image.shape)</span><span style="color: #0000ff;">print</span>(sorted(res))</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>批量读取nii</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>批量读取dicom数据 to Array类型（多标签融合）</title>
    <link href="/2022/%E6%89%B9%E9%87%8F%E8%AF%BB%E5%8F%96dicom%E6%95%B0%E6%8D%AE%20to%20array%E7%B1%BB%E5%9E%8B%EF%BC%88%EF%BC%88%E5%A4%9A%E6%A0%87%E7%AD%BE%E8%9E%8D%E5%90%88%EF%BC%89%EF%BC%89%EF%BC%89/"/>
    <url>/2022/%E6%89%B9%E9%87%8F%E8%AF%BB%E5%8F%96dicom%E6%95%B0%E6%8D%AE%20to%20array%E7%B1%BB%E5%9E%8B%EF%BC%88%EF%BC%88%E5%A4%9A%E6%A0%87%E7%AD%BE%E8%9E%8D%E5%90%88%EF%BC%89%EF%BC%89%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python">file_name = [<span class="hljs-string">&quot;portalvein&quot;</span>, <span class="hljs-string">&quot;venoussystem&quot;</span>, <span class="hljs-string">&quot;venacava&quot;</span>]<br><span class="hljs-keyword">def</span> <span class="hljs-title function_">read_dicom</span>(<span class="hljs-params">path</span>):<br>    lstFileDCM = []<br>    <span class="hljs-keyword">for</span> dirName, subdirList, fileList <span class="hljs-keyword">in</span> os.walk(path):<br>        n = <span class="hljs-built_in">len</span>(fileList)<br>        <span class="hljs-comment"># print(&quot;n:&quot;, n)</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(n):<br>            filename = fileList[i]<br><br>            idx = filename.split(<span class="hljs-string">&quot;_&quot;</span>)[-<span class="hljs-number">1</span>]<br>            filename = filename.replace(<span class="hljs-built_in">str</span>(idx), <span class="hljs-built_in">str</span>(i))<br><br>            lstFileDCM.append(os.path.join(dirName, filename))<br><br>    <span class="hljs-comment"># 读取第一张dicom图片</span><br>    RefDs = pydicom.read_file(lstFileDCM[<span class="hljs-number">0</span>])<br>    <span class="hljs-comment"># 得到dicom图片所组成3D图片的维度</span><br>    ConstPixelDims = (<span class="hljs-built_in">int</span>(RefDs.Rows), <span class="hljs-built_in">int</span>(RefDs.Columns), <span class="hljs-built_in">len</span>(lstFileDCM))<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;ConstPixelDims:&quot;</span>, ConstPixelDims)<br>    <span class="hljs-comment"># (512,512,74)【这是我的一张示例图片输出的结果】</span><br><br>    <span class="hljs-comment"># 得到x方向和y方向的Spacing并得到z方向的层厚</span><br>    ConstPixelSpacing = (<span class="hljs-built_in">float</span>(RefDs.PixelSpacing[<span class="hljs-number">0</span>]), <span class="hljs-built_in">float</span>(RefDs.PixelSpacing[<span class="hljs-number">1</span>]), <span class="hljs-built_in">float</span>(RefDs.SliceThickness))<br>    <span class="hljs-comment"># (0.742187976837158, 0.742187976837158, 2.5)【这是我的一张示例图片输出的结果】</span><br><br>    <span class="hljs-comment"># 得到图像的原点</span><br>    Origin = RefDs.ImagePositionPatient<br>    <span class="hljs-comment"># [0, 0, 0]【这是我的一张示例图片输出的结果】</span><br><br>    <span class="hljs-comment"># 根据维度创建一个numpy的三维数组，并将元素类型设为：pixel_array.dtype</span><br>    ArrayDicom = np.zeros(ConstPixelDims, dtype=RefDs.pixel_array.dtype)<br><br>    <span class="hljs-comment"># 遍历所有的dicom文件，读取图像数据，存放在numpy数组中</span><br>    i = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> filenameDCM <span class="hljs-keyword">in</span> lstFileDCM:<br>        ds = pydicom.read_file(filenameDCM)<br>        ArrayDicom[:, :, lstFileDCM.index(filenameDCM)] = ds.pixel_array<br>        <span class="hljs-comment"># 将文件按照png的格式写进当前目录</span><br>        <span class="hljs-comment"># cv2.imwrite(os.path.join(png_path, &quot;out_&quot; + str(i) + &#x27;.png&#x27;), ArrayDicom[:, :, lstFileDCM.index(filenameDCM)])</span><br>        i += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 对numpy数组进行转置，即把坐标轴(x,y,z)变换为(z,y,x)，这样是dicom存储文件的格式，即第一个维度为z轴便于图片堆叠</span><br>    ArrayDicom = np.transpose(ArrayDicom, (<span class="hljs-number">2</span>, <span class="hljs-number">0</span>, <span class="hljs-number">1</span>))<br>    <span class="hljs-keyword">return</span> ArrayDicom,ConstPixelSpacing,Origin<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>批量读取dicom</tag>
      
      <tag>dicon2array</tag>
      
      <tag>多标签融合</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>批量解压zip文件到指定位置</title>
    <link href="/2022/%E6%89%B9%E9%87%8F%E8%A7%A3%E5%8E%8Bzip%E6%96%87%E4%BB%B6%E5%88%B0%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%BD%AE/"/>
    <url>/2022/%E6%89%B9%E9%87%8F%E8%A7%A3%E5%8E%8Bzip%E6%96%87%E4%BB%B6%E5%88%B0%E6%8C%87%E5%AE%9A%E4%BD%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<p>话不多说，直接上代码。</p><div class="cnblogs_code"><pre><span style="color: #008000;">#</span><span style="color: #008000;"> coding:utf-8</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> zipfile</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> utils_filen </span>= 21  <span style="color: #008000;">#</span><span style="color: #008000;"> 我事先知道我有多少个文件，所以确定为21</span><span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span> range(1<span style="color: #000000;">, n):    path </span>= r<span style="color: #800000;">"</span><span style="color: #800000;">D:\MyData\3Dircadb1\3Dircadb1.</span><span style="color: #800000;">"</span>+str(i)+<span style="color: #800000;">"</span><span style="color: #800000;">\MASKS_DICOM.zip</span><span style="color: #800000;">"</span>  <span style="color: #008000;">#</span><span style="color: #008000;"> 需要解码的指定zip文件目录地址</span>    save_path = r<span style="color: #800000;">"</span><span style="color: #800000;">D:\MyData\3Dircadb1_date\3Dircadb1.</span><span style="color: #800000;">"</span>+str(i)  <span style="color: #008000;">#</span><span style="color: #008000;"> 指定保存位置</span>    utils_file.mkdir(save_path)  <span style="color: #008000;">#</span><span style="color: #008000;"> 是否创建指定保存位置 ，创建文件夹具体操作看我的github地址。</span>    azip = zipfile.ZipFile(path)  <span style="color: #008000;">#</span><span style="color: #008000;"> 开始解压</span>    <span style="color: #0000ff;">print</span>(azip.namelist())  <span style="color: #008000;">#</span><span style="color: #008000;"> 查看zip文件下的文件夹和文件</span>    <span style="color: #0000ff;">for</span> file <span style="color: #0000ff;">in</span><span style="color: #000000;"> azip.namelist():        azip.extract(file,save_path) </span><span style="color: #008000;">#</span><span style="color: #008000;">将zip文件解压到指定位置</span></pre></div><p>github地址:<a href="https://gist.github.com/DreamOneYou/ee946c14d52dbc3f14b324037ff4408b" target="_blank">https://gist.github.com/DreamOneYou/ee946c14d52dbc3f14b324037ff4408b</a></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>批量解压zip</tag>
      
      <tag>zip解压指定位置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>flops,params=profile(model,inputs=(x,))计算</title>
    <link href="/2021/flops,%20params%20=%20profile(model,%20inputs=(x,))%E8%AE%A1%E7%AE%97/"/>
    <url>/2021/flops,%20params%20=%20profile(model,%20inputs=(x,))%E8%AE%A1%E7%AE%97/</url>
    
    <content type="html"><![CDATA[<p>&nbsp;</p><p>计算量：<br />FLOPs，FLOP时指浮点运算次数，s是指秒，即每秒浮点运算次数的意思，考量一个网络模型的计算量的标准。<br />参数量：<br />Params，是指网络模型中需要训练的参数总数。</p><p>&nbsp;</p><p>flops(G) =&nbsp;flops / 1000**3</p><p>params(M) =&nbsp;params /1000**2</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>模型复杂度计算</tag>
      
      <tag>FLOPs</tag>
      
      <tag>Params</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>对3D图像进行裁剪</title>
    <link href="/2021/%E5%AF%B93D%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2/"/>
    <url>/2021/%E5%AF%B93D%E5%9B%BE%E5%83%8F%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2/</url>
    
    <content type="html"><![CDATA[<p>在对医学图像进行深度学习的过程中，我们会遇到图片过大，导致train的过程中网络会瘫痪，所以我们会考虑到对图像进行分割。比如一张155x240x240的图像，我们可以将他分割成一系列128x128x128大小的小图像。代码如下：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">from</span> crop <span style="color: #0000ff;">import</span> *<span style="color: #0000ff;">import</span><span style="color: #000000;"> torch</span><span style="color: #0000ff;">def</span> split_image(img, crop_size=(128,128,128<span style="color: #000000;">)):    patient_image </span>= img  <span style="color: #008000;">#</span><span style="color: #008000;"> (1, 240, 240, 155, 4)</span>    patient_image = patient_image[0, ...]  <span style="color: #008000;">#</span><span style="color: #008000;"> (240, 240, 155, 4)</span>    patient_image = patient_image.permute(3, 0, 1, 2)  <span style="color: #008000;">#</span><span style="color: #008000;"> (1, 4, 155, 240, 240)</span>    patient_image =<span style="color: #000000;"> patient_image.cpu().numpy()    pasient_image </span>=<span style="color: #000000;"> crop_pad(patient_image, crop_size)    patient_image </span>= torch.from_numpy(pasient_image).permute(1, 0, 2, 3, 4)  <span style="color: #008000;">#</span><span style="color: #008000;"> (C, S, T, Y, W)</span>    patient_image =<span style="color: #000000;"> patient_image.unsqueeze(0).numpy()    </span><span style="color: #008000;">#</span><span style="color: #008000;"> print("patient_image", patient_image.shape)</span>    <span style="color: #0000ff;">return</span><span style="color: #000000;"> patient_image</span><span style="color: #0000ff;">if</span> <span style="color: #800080;">__name__</span> ==<span style="color: #800000;">"</span><span style="color: #800000;">__main__</span><span style="color: #800000;">"</span><span style="color: #000000;">:    device </span>= torch.device(<span style="color: #800000;">'</span><span style="color: #800000;">cuda</span><span style="color: #800000;">'</span><span style="color: #000000;">)    image_size </span>= 128<span style="color: #000000;">    image </span>= torch.rand((1, 155, 240, 240, 4), device=<span style="color: #000000;">device)    x </span>= split_image(image, (128,128,128<span style="color: #000000;">))    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">before Pinjie</span><span style="color: #800000;">"</span><span style="color: #000000;">,image.shape)    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">after Pinjie</span><span style="color: #800000;">"</span>,x.shape)</pre></div><p>结果显示：</p><p><img src="/2023/image/1218402-20210716223721753-1239349668.jpg" alt="" loading="lazy" /></p><p>我们可以看到，我们将图像分割成8个128x128x128大小的图像。</p><p>详细代码，请看我的<a href="https://gist.github.com/DreamOneYou/e2892f7ccf282a0c73f070a2832495d9" target="_blank">github</a></p><div id="translate-man-app" class="content-3WfBL_0" style="background-color: #ffffff; left: -1468px; top: 99px;"><div class="outputBox-qe9A4_0" data-v-2868eb04=""><div class="outputBox-3oESn_0" data-v-2868eb04=""><span class="outputBox-13Ovx_0" data-v-2868eb04="">github</span></div><div class="outputBox-1GLb__0" data-v-2868eb04=""><div class="icon-tprjJ_0 outputBox-onVZH_0" data-v-2868eb04=""><img src="chrome-extension://fapgabkkfcaejckbfmfcdgnfefbmlion/static/sound.svg" class="icon-tprjJ_0" /></div></div><div class="outputBox-2sJgr_0" data-v-2868eb04=""><div class="outputBox-GomOI_0" data-v-2868eb04=""><span class="outputBox-2liU7_0" data-v-2868eb04="">GitHub.</span></div></div><div class="outputBox-17RAm_0" style="display: none;" data-v-2868eb04="">&nbsp;</div></div></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>3D图像进行裁剪</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CNN归纳偏好</title>
    <link href="/2021/CNN%E5%BD%92%E7%BA%B3%E5%81%8F%E5%A5%BD/"/>
    <url>/2021/CNN%E5%BD%92%E7%BA%B3%E5%81%8F%E5%A5%BD/</url>
    
    <content type="html"><![CDATA[<p>出处：<a href="https://mp.weixin.qq.com/s/eSOabk8eVE5j6bOXUGkrgQ" target="_blank">Transformer为何能闯入CV界秒杀CNN？</a></p><p>CNN 中的卷积运算由于使用了两个重要的空间约束，从而有助于视觉特征的学习和提取：</p><p>&nbsp;</p><ul class="list-paddingleft-2"><li>由于 CNN 权重共享机制，卷积层所提取的特征便具有平移不变性，它们对特征的全局位置不感冒，而只在乎这些决定性的特征是否存在。</li><li>由于卷积算子的性质，所以卷积的特征图具有局部敏感性,也就是每次卷积操作只会考虑原始数据的一小部分的局部信息。</li></ul><p>&nbsp;</p><p>正是由于此，CNN 的归纳偏差缺乏对输入数据本身的整体把握。它很擅长提取局部的有效信息，但是没能提取全局数据之间的长距离特征。比如，当我们使用 CNN 去训练一个人脸识别模型时，卷积层可以有效的提取出眼睛大小、鼻子翘不翘、嘴巴颜色等小器官的特征，但是无法将他们联系起来，无法形成"眼镜在鼻子上"、"嘴巴在眼睛下面"的这种长距离的特征。因为每个卷积核都很局部，没办法同时处理这么多个特征。为了提取和跟踪这些原始数据中的长相关特征，模型需要扩大自己的感受野，这就需要使用一些更大的卷积核，以及更深的卷积。但是由此会带来计算效率的大幅下降，会让模型的复杂度剧烈上升，甚至会让模型产生维度灾难从而无法收敛训练。</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CNN</tag>
      
      <tag>CNN局部归纳性</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>window和Linux下安装nvidia的apex</title>
    <link href="/2021/window%E5%92%8CLinux%E4%B8%8B%E5%AE%89%E8%A3%85nvidia%E7%9A%84apex/"/>
    <url>/2021/window%E5%92%8CLinux%E4%B8%8B%E5%AE%89%E8%A3%85nvidia%E7%9A%84apex/</url>
    
    <content type="html"><![CDATA[<p>两种方法：</p><p>1、去github下下载<a href="https://github.com/NVIDIA/apex" target="_blank">apex&nbsp;</a>，之后安装到你的python环境下，我的安装路径：E:\Anaconda\anaconda\envs\pytorch\Lib\site-packages</p><p>注：建议用git下载</p><div class="cnblogs_code"><pre>1、git clone git@github.com:NVIDIA/apex.git<br />2、开cmd命令窗口，切换到apex所在的文件夹<br /><br />3、python setup.py install</pre></div><p>如果出现：ModuleNotFoundError错误，建议使用以下代码：</p><div class="cnblogs_code"><pre>pip install --upgrade setuptools</pre></div><p>2、需要你有anaconda环境，因为需要用到conda命令，我是通过这个方法安装好的。</p><div class="cnblogs_code"><pre>conda install -c conda-forge nvidia-apex</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Windows</tag>
      
      <tag>安装apex</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用GrabCut做分割</title>
    <link href="/2021/%E4%BD%BF%E7%94%A8GrabCut%E5%81%9A%E5%88%86%E5%89%B2/"/>
    <url>/2021/%E4%BD%BF%E7%94%A8GrabCut%E5%81%9A%E5%88%86%E5%89%B2/</url>
    
    <content type="html"><![CDATA[<p>主要完成了界面化设计，代码如下</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> cv2 <span class="hljs-keyword">as</span> cv<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> sys<br><span class="hljs-keyword">from</span> PyQt5.Qt <span class="hljs-keyword">import</span> *<br><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyWediget</span>(<span class="hljs-title class_ inherited__">QWidget</span>):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.setWindowTitle(<span class="hljs-string">&quot;分割烟草&quot;</span>)<br>        self.setWindowIcon(QIcon(<span class="hljs-string">&quot;2.jpg&quot;</span>))<br>        self.setFixedSize(<span class="hljs-number">800</span>, <span class="hljs-number">430</span>)<br>        self.setup_ui()<br>        self.arg = <span class="hljs-string">&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">setup_ui</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">test</span>():<br>            fd = QFileDialog(window, <span class="hljs-string">&quot;选择一个文件&quot;</span>, <span class="hljs-string">&quot;../&quot;</span>, <span class="hljs-string">&quot;All(*.*);;Images(*.png *.jpg);;Python文件(*.py)&quot;</span>)<br>            fd.move(<span class="hljs-number">200</span>,<span class="hljs-number">0</span>)<br>            fd.setLabelText(QFileDialog.FileName, <span class="hljs-string">&quot;我的文件&quot;</span>)<br>            fd.setLabelText(QFileDialog.Accept, <span class="hljs-string">&quot;接受&quot;</span>)<br><br>            fd.setLabelText(QFileDialog.Reject, <span class="hljs-string">&quot;拒绝&quot;</span>)<br>            fd.setFileMode(QFileDialog.ExistingFiles)<br>            <span class="hljs-keyword">def</span> <span class="hljs-title function_">path</span>(<span class="hljs-params">val</span>):<br>                inputPath.setText(val)<br>                self.segmentation(val)<br>            fd.fileSelected.connect(path)<br>            fd.<span class="hljs-built_in">open</span>()<br>        inputPath = QLineEdit(self)<br>        inputPath.resize(<span class="hljs-number">300</span>,<span class="hljs-number">30</span>)<br>        btn = QPushButton(self)<br>        btn.setText(<span class="hljs-string">&quot;选择文件&quot;</span>)<br>        <span class="hljs-keyword">def</span> <span class="hljs-title function_">click</span>():<br>            btn.isDefault()<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(inputPath.text()) &amp;gt; <span class="hljs-number">0</span>:<br>            evt = QKeyEvent()<br>            <span class="hljs-keyword">if</span> evt.modifiers() == Qt.EnterKeyGo:<br>                btn.pressed.connect(click)<br>        btn.move(<span class="hljs-number">300</span>,<span class="hljs-number">0</span>)<br>        btn.clicked.connect(test)<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">segmentation</span>(<span class="hljs-params">self,val</span>):<br>        windows = QWidget(self)<br>        windows.resize(<span class="hljs-number">400</span>,<span class="hljs-number">400</span>)<br>        windows.move(<span class="hljs-number">0</span>,<span class="hljs-number">30</span>)<br><br>        w2 = QWidget(self)<br>        w2.move(<span class="hljs-number">400</span>,<span class="hljs-number">30</span>)<br>        w2.resize(<span class="hljs-number">400</span>,<span class="hljs-number">400</span>)<br><br>        self.arg = val<br>        inputPath = QLineEdit(self)<br>        inputPath.setText(self.arg)<br><br>        src = cv.imread(self.arg)<br>        <span class="hljs-built_in">print</span>(src.shape)<br>        w = <span class="hljs-built_in">int</span>(src.shape[<span class="hljs-number">1</span>])<br>        h = <span class="hljs-built_in">int</span>(src.shape[<span class="hljs-number">0</span>])<br><br>        <span class="hljs-keyword">if</span> w&amp;gt;<span class="hljs-number">1000</span> <span class="hljs-keyword">or</span> h&amp;gt;<span class="hljs-number">800</span>:<br>            w = <span class="hljs-built_in">int</span>(w/<span class="hljs-number">2</span>)<br>            h = <span class="hljs-built_in">int</span>(h/<span class="hljs-number">2</span>)<br>        <span class="hljs-comment"># print(w+&quot;  &quot;+h)</span><br>        src = cv.resize(src, (w, h), interpolation=cv.INTER_CUBIC)<br>        r = cv.selectROI(<span class="hljs-string">&#x27;Draw a rectangle&#x27;</span>, src, <span class="hljs-literal">False</span>)  <span class="hljs-comment"># 返回 (x_min, y_min, w, h)\</span><br><br>        roi = src[<span class="hljs-built_in">int</span>(r[<span class="hljs-number">1</span>]):<span class="hljs-built_in">int</span>(r[<span class="hljs-number">1</span>] + r[<span class="hljs-number">3</span>]), <span class="hljs-built_in">int</span>(r[<span class="hljs-number">0</span>]):<span class="hljs-built_in">int</span>(r[<span class="hljs-number">0</span>] + r[<span class="hljs-number">2</span>])]<br><br>        <span class="hljs-comment"># 原图mask</span><br>        mask = np.zeros(src.shape[:<span class="hljs-number">2</span>], dtype=np.uint8)<br><br>        <span class="hljs-comment"># 矩形roi</span><br>        rect = (<span class="hljs-built_in">int</span>(r[<span class="hljs-number">0</span>]), <span class="hljs-built_in">int</span>(r[<span class="hljs-number">1</span>]), <span class="hljs-built_in">int</span>(r[<span class="hljs-number">2</span>]), <span class="hljs-built_in">int</span>(r[<span class="hljs-number">3</span>]))  <span class="hljs-comment"># 包括前景的矩形，格式为(x,y,w,h)</span><br><br>        bgdmodel = np.zeros((<span class="hljs-number">1</span>, <span class="hljs-number">65</span>), np.float64)  <span class="hljs-comment"># bg模型的临时数组</span><br>        fgdmodel = np.zeros((<span class="hljs-number">1</span>, <span class="hljs-number">65</span>), np.float64)  <span class="hljs-comment"># fg模型的临时数组</span><br><br>        cv.grabCut(src, mask, rect, bgdmodel, fgdmodel, <span class="hljs-number">11</span>, mode=cv.GC_INIT_WITH_RECT)<br><br>        <span class="hljs-comment"># 提取前景和可能的前景区域</span><br>        mask2 = np.where((mask == <span class="hljs-number">1</span>) + (mask == <span class="hljs-number">3</span>), <span class="hljs-number">255</span>, <span class="hljs-number">0</span>).astype(<span class="hljs-string">&#x27;uint8&#x27;</span>)<br><br>        <span class="hljs-built_in">print</span>(mask2.shape)<br><br>        result = cv.bitwise_and(src, src, mask=mask2)<br>        cv.imwrite(<span class="hljs-string">&#x27;result.jpg&#x27;</span>, result)<br>        cv.imwrite(<span class="hljs-string">&#x27;roi.jpg&#x27;</span>, roi)<br><br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;over&quot;</span>)<br>        w2.setStyleSheet(<span class="hljs-string">&quot;border-image:url(roi.jpg)&quot;</span>)<br>        windows.setStyleSheet(<span class="hljs-string">&quot;border-image:url(result.jpg)&quot;</span>)<br><br>        w2.show()<br>        windows.show()<br><br><br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    app = QApplication(sys.argv)<br>    window = MyWediget()<br>    window.show()<br>    sys.exit(app.exec_())<br></code></pre></td></tr></table></figure><p>第一、选择图像文件</p><p><img src="/2023/image/1218402-20210304105159932-1478558264.png" alt="" loading="lazy" /></p><p>第二、画出矩形框</p><p><img src="/2023/image/1218402-20210304105238931-661512430.png" alt="" loading="lazy" /></p><p>第三、回车得到分割结果</p><p><img src="/2023/image/1218402-20210304105306020-90110381.png" alt="" loading="lazy" /></p><p>如果想要生成exe文件，就需要配置.spec文件。请访问我的<a href="https://github.com/DreamOneYou/GrabCut" target="_blank">github</a>。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GrabCut</tag>
      
      <tag>图像分割</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>将python文件编译成exe文件</title>
    <link href="/2021/%E5%B0%86python%E6%96%87%E4%BB%B6%E7%BC%96%E8%AF%91%E6%88%90exe%E6%96%87%E4%BB%B6/"/>
    <url>/2021/%E5%B0%86python%E6%96%87%E4%BB%B6%E7%BC%96%E8%AF%91%E6%88%90exe%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<p><strong>第一种方法：我们只会生成一个exe文件，因为所有的库文件他都会包含在这个exe文件中</strong></p><p>1、安装：pyinstaller</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">pip install pyinstaller</pre></div><p>2、使用如下命令编译</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">pyinstaller -F -w GraphCut.py</pre></div><p>3、会在项目下生成文件：NewCutUI.spec。之后我们需要在文件里添加导入的包。</p><p><strong>原始生成文件：</strong></p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;"># -*- mode: python ; coding: utf-8 -*-<p>block_cipher &#x3D; None</p><p>a &#x3D; Analysis([‘NewCutUI.py’],<br>             pathex&#x3D;[‘E:\项目\GraphCut\graph_cut’],<br>             binaries&#x3D;[],<br>             datas&#x3D;[],<br>             hiddenimports&#x3D;[],<br>             hookspath&#x3D;[],<br>             runtime_hooks&#x3D;[],<br>             excludes&#x3D;[],<br>             win_no_prefer_redirects&#x3D;False,<br>             win_private_assemblies&#x3D;False,<br>             cipher&#x3D;block_cipher,<br>             noarchive&#x3D;False)<br>pyz &#x3D; PYZ(a.pure, a.zipped_data,<br>             cipher&#x3D;block_cipher)<br>exe &#x3D; EXE(pyz,<br>          a.scripts,<br>          a.binaries,<br>          a.zipfiles,<br>          a.datas,<br>          [],<br>          name&#x3D;’NewCutUI’,<br>          debug&#x3D;False,<br>          bootloader_ignore_signals&#x3D;False,<br>          strip&#x3D;False,<br>          upx&#x3D;True,<br>          upx_exclude&#x3D;[],<br>          runtime_tmpdir&#x3D;None,<br>          console&#x3D;False )　</pre></p></div><p>&nbsp;</p><p><strong>修改后的文件：</strong></p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;"># -*- mode: python ; coding: utf-8 -*-from PyInstaller.utils.hooks import collect_submodulesblock_cipher = Nonehiddenimports_numpy = collect_submodules('numpy')hidden_imports_PyQt4 = collect_submodules('PyQt4')hiddenimports_graph_cut = collect_submodules('graph_cut')hidden_imports_maxflow = collect_submodules('maxflow')hidden_imports_argparse = collect_submodules('argparse')hidden_imports_GraphMaker = collect_submodules('GraphMaker')hidden_imports_cv2 = collect_submodules('cv2')<p>block_cipher &#x3D; None</p><p>all_hidden_imports &#x3D; hiddenimports_numpy + hidden_imports_PyQt4+hiddenimports_graph_cut + hidden_imports_maxflow + hidden_imports_argparse + hidden_imports_GraphMaker + hidden_imports_cv2</p><p>a &#x3D; Analysis([‘NewCutUI.py’],<br>             pathex&#x3D;[‘E:\项目\GraphCut\graph_cut’],<br>             binaries&#x3D;[],<br>             datas&#x3D;[],<br>             hiddenimports&#x3D;all_hidden_imports,<br>             hookspath&#x3D;[],<br>             runtime_hooks&#x3D;[],<br>             excludes&#x3D;[],<br>             win_no_prefer_redirects&#x3D;False,<br>             win_private_assemblies&#x3D;False,<br>             cipher&#x3D;block_cipher,<br>             noarchive&#x3D;False)<br>pyz &#x3D; PYZ(a.pure, a.zipped_data,<br>             cipher&#x3D;block_cipher)<br>exe &#x3D; EXE(pyz,<br>          a.scripts,<br>          a.binaries,<br>          a.zipfiles,<br>          a.datas,<br>          [],<br>          name&#x3D;’NewCutUI’,<br>          debug&#x3D;False,<br>          bootloader_ignore_signals&#x3D;False,<br>          strip&#x3D;False,<br>          upx&#x3D;True,<br>          upx_exclude&#x3D;[],<br>          runtime_tmpdir&#x3D;None,<br>          console&#x3D;False )<br></pre></p></div><p>　　</p><p>4、使用：pyinstaller.exe NewCutUI.spec 进行打包，其中你需要找到pyinstaller.exe文件位置，我的位置：D:\anaconda\Anaconda\envs\pytorch\Scripts\pyinstaller.exe</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">pyinstaller.exe E:\项目\GraphCut\graph_cut\NewCutUI.spec　</pre></div><p>最后生成的exe文件目录：D:\anaconda\Anaconda\envs\pytorch\Scripts\dist\NewCutUI.exe</p><p>我在外面导包的时候经常遇到错误，所以直接在文件里面填了导包的内容。最后exe文件可能会很大，大概都是使用import这个方法导包，虽然我使用from * import *没小多少。</p><p><strong>&nbsp;第二种方法：他会把一些库的依赖生成dll动态链接库文件，所以dist下会有很多个文件。</strong></p><p><span style="color: #ff0000;">如果上述方法出现 "failed to execute script&rdquo;这个错误，我们可以使用下面这个方法，同样可以得到exe文件：</span></p><p><span style="color: #ff0000;">只需要执行这行代码就ok了：pyinstaller.exe&nbsp; computer_S.py</span></p><p><span style="color: #ff0000;">你可以在当前目录下找到：../dist/computer_S/computer_S.exe文件</span></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>python编译exe文件</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>git设置代理和取消代理</title>
    <link href="/2021/git%20%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%92%8C%E5%8F%96%E6%B6%88%E4%BB%A3%E7%90%86/"/>
    <url>/2021/git%20%E8%AE%BE%E7%BD%AE%E4%BB%A3%E7%90%86%E5%92%8C%E5%8F%96%E6%B6%88%E4%BB%A3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p>1、设置代理</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;"> git config --global http.proxy "127.0.0.1:1080"</pre></div><p>2、取消代理</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">git config --global --unset http.proxy# 或者git config --global --unset https.proxy</pre></div><p>　　</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>git</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pip下载太慢，换源</title>
    <link href="/2021/pip%E4%B8%8B%E8%BD%BD%E5%A4%AA%E6%85%A2%EF%BC%8C%E6%8D%A2%E6%BA%90/"/>
    <url>/2021/pip%E4%B8%8B%E8%BD%BD%E5%A4%AA%E6%85%A2%EF%BC%8C%E6%8D%A2%E6%BA%90/</url>
    
    <content type="html"><![CDATA[<p>1、安装pqi</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">pip install pqi</pre></div><p>　　<img src="/2023/image/1218402-20210130193150956-1670073248.png" alt="" loading="lazy" /></p><p>2、改变pip源</p><p>比如换成清华源：</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">pqi use tuna</pre></div><p>　　3、显示当前源</p><p><img src="/2023/image/1218402-20210130193332530-1315645960.png" alt="" loading="lazy" /></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pip换源</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>UNet++: Redesigning Skip Connections to ExploitMultiscale Features in Image Segmentation中文阅读</title>
    <link href="/2020/UNet%E5%8A%A0%E5%8A%A0%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB/"/>
    <url>/2020/UNet%E5%8A%A0%E5%8A%A0%E4%B8%AD%E6%96%87%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<h2 id="阅读的第二篇论文，翻译的一般，英文好的，希望阅读原文。"><a href="#阅读的第二篇论文，翻译的一般，英文好的，希望阅读原文。" class="headerlink" title="阅读的第二篇论文，翻译的一般，英文好的，希望阅读原文。"></a>阅读的第二篇论文，翻译的一般，英文好的，希望阅读原文。</h2><h3 id="UNet-Redesigning-Skip-Connections-to-ExploitMultiscale-Features-in-Image-Segmentation"><a href="#UNet-Redesigning-Skip-Connections-to-ExploitMultiscale-Features-in-Image-Segmentation" class="headerlink" title="UNet++: Redesigning Skip Connections to ExploitMultiscale Features in Image Segmentation"></a>UNet++: Redesigning Skip Connections to ExploitMultiscale Features in Image Segmentation</h3><p>Zongwei Zhou, Member, IEEE, Md Mahfuzur Rahman Siddiquee, Member, IEEE, Nima Tajbakhsh, Member, IEEE, and Jianming Liang, Senior Member, IEEE</p><h3 id="摘要："><a href="#摘要：" class="headerlink" title="摘要："></a>摘要：</h3><p>医学图像分割的最新模型是U-Net和完全卷积网络（FCN）的变体。尽管取得了成功，但是这两个模型有两个局限性：（1）最佳深度是不知道的，需要宽的结构探索或者效率低的不同深度模型集成； （2）它们的skip connections施加了不必要的限制性融合方案，仅在编码器和解码器子网相同比例的特征图上强制聚合。为克服这两个限制，我们提出了UNet ++，这是一种新的神经网络架构，用于语义分割和实例分割。（1）有效的缓解了未知的网络深度，并且都是不同深度的U-Net的集合，这些U-Net共享一个编码器和同时使用深度监督进行合作学习； （2）重新设计skip connections以在解码器子网络上聚合不同尺度的语义特征，从而产生一个高度灵活的特征融合方案（3）设计一个剪枝方案以加快UNet ++的推理速度。我们使用六个不同的医学图像分割数据集对UNet ++进行了评估，涵盖了多种成像方式，例如计算机断层扫描（CT），磁共振成像（MRI），和电子显微镜（EM），并证明了（1）UNet ++对于交叉了不同数据集和主干架构的语义分割任务，其始终优于baseline模型，； （2）UNet ++提高了各种尺寸对象的分割质量，这是对固定深度U-Net的改进； （3）Mask RCNN ++（具有UNet ++设计的Mask R-CNN）在执行实例任务方面优于原始Mask R-CNN分割; （4）剪枝过的UNet ++模型实现了明显的加速，同时仅显示出适度的性能下降。可在<a href="https://github.com/MrGiovanni/UNetPlusPlus%E4%B8%8A%E8%8E%B7%E5%BE%97%E6%88%91%E4%BB%AC%E7%9A%84%E5%AE%9E%E6%96%BD%E5%92%8C%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E3%80%82">https://github.com/MrGiovanni/UNetPlusPlus上获得我们的实施和预训练模型。</a></p><h3 id="索引词：神经结构分割，肝脏分割，细胞分割，核分割，脑肿瘤分割，肺结节分割，医学图像分割，语义分割，实例分割，深度监督，模型修剪。"><a href="#索引词：神经结构分割，肝脏分割，细胞分割，核分割，脑肿瘤分割，肺结节分割，医学图像分割，语义分割，实例分割，深度监督，模型修剪。" class="headerlink" title="索引词：神经结构分割，肝脏分割，细胞分割，核分割，脑肿瘤分割，肺结节分割，医学图像分割，语义分割，实例分割，深度监督，模型修剪。"></a>索引词：神经结构分割，肝脏分割，细胞分割，核分割，脑肿瘤分割，肺结节分割，医学图像分割，语义分割，实例分割，深度监督，模型修剪。</h3><h3 id="I-I-NTRODUCTION"><a href="#I-I-NTRODUCTION" class="headerlink" title="I. I NTRODUCTION"></a>I. I NTRODUCTION</h3><p>编码器-解码器网络广泛用于现代语义分割和实例分割模型[1]，[2]，[3]，[4]，[5]，[6]。 它们的成功很大程度上归功于其skip connections，skip connections 将解码器子网中的深度，语义，粗粒度特征图与编码器子网中的浅，低层次，细粒度特征图结合在一起，并被证明在恢复目标对象[7]，[8]，[9]细粒度细节是有效的， 即使在复杂的情况下[10]，[11]。 skip connections在实例级分割模型（例如[12]，[13]）的成功中也发挥了关键的作用，其中的想法是对所需对象的每个实例进行分割和区分。</p><p>然而，这些用于图像分割的编码器-解码器架构具有两个限制。首先，编码器&#x2F;解码器网络的最佳深度可能因一个应用程序而异，取决于任务难度和可用于训练的标记数据量。一种简单的方法是分别训练不同深度的模型，然后在推理时间期间[14]，[15]，[16]将结果模型合在一起。但是，从部署的角度来看，这种简单的方法效率低下，因为这些网络并不共享公共的编码器。此外，由于独立训练，这些网络无法享受来自多任务学习的优势[17]，[18]。其次，在编码器-解码器网络中使用的skip connections的设计受到不必要的限制，要求融合相同比例的编码器和解码器特征图。尽管是自然设计，但来自解码器和编码器网络相同比例的特征图在语义上是不同的，没有可靠的理论可以保证它们是特征融合的最佳匹配。</p><p>在本文中，我们介绍了UNet ++，这是一种旨在克服以上限制的新型通用图像分割体系结构。如图1（g）所示，UNet ++由不同深度的U-Net组成，其解码器通过重新设计的skip connections以相同的分辨率密集连接。 UNet ++中引入的体系结构具有以下改进优点。首先，UNet ++不容易选择网络深度，因为它在其体系结构中嵌入了不同深度的U-Net。所有这些U-Net都部分共享一个编码器，而它们的解码器则交织在一起。通过在深度监督下训练UNet ++，所有组成的U-Net都将同时接受训练，同时受益于共享的图像表示。这种设计不仅可以提高整体分割性能，而且可以在推理期间剪枝模型。其次，UNet ++不会受到不必要的限制性skip connections的限制，在这种限制就是只能融合来自编码器和解码器的相同比例的特征图。 UNet ++中重新设计了skip connections，那就是在解码器节点处提供了不同比例的特征图，从而使聚合层可以决定如何将skip connections中携带的各种特征图与解码器特征图融合在一起。通过以相同的分辨率密集连接部分U-Net的解码器，可以在UNet ++中实现重新设计的skip connections。我们已经在六个细分数据集和不同深度的多个主干中对UNet ++进行了广泛的评估。我们的结果强有力的表明，通过重新设计的skip connections和深度监督，为UNet ++在语义和实例分割提供了更高的性能。与传统的U-Net架构相比，UNet ++的显着改进归因于重新设计的skip connections和扩展的解码器所提供的优势，这些优势共同使水平和垂直网络上的图像特征逐渐聚合。</p><p><img src="/2023/image/1218402-20201006205617438-694540373111.png" alt="image"><br>总而言之，我们做出了以下五点贡献：</p><p>1）我们在UNet ++中引入了一个内置的深度可变的U-Net集合，从而提高了对各种尺寸对象的分割性能，这是对固定深度U-Net的改进（请参阅第II-B节），</p><p>2）我们重新设计了UNet ++中的skip connections，从而在解码器中实现了灵活的特征融合，这是对U-Net中仅需要融合相同比例特征图的限制性skip connections的一种改进（请参阅第II-B节）。</p><p>3）我们设计了一种方案来剪枝经过训练的UNet ++，在保持其性能的同时加快推理速度（请参阅第IV-C节）。</p><p>4）我们发现，同时训练嵌入在UNet ++结构中的多深度U-Net，可以激发在U-Nets结构中协作学习，这与单独训练具有相同体系结构的隔离U-Net相比，可带来更好的性能（请参阅第IV-D节和VC节。</p><p>5）我们证明了UNet ++在多个主干编码器上的可扩展性，并进一步适用于包括CT，MRI和电子显微镜在内的各种医学成像模式（请参阅第IV-A节和第IV-B节）。</p><h3 id="II-P-ROPOSED-N-ETWORK-A-RCHITECTURE-UN-ET"><a href="#II-P-ROPOSED-N-ETWORK-A-RCHITECTURE-UN-ET" class="headerlink" title="II. P ROPOSED N ETWORK A RCHITECTURE : UN ET ++"></a>II. P ROPOSED N ETWORK A RCHITECTURE : UN ET ++</h3><p>图1显示了UNet ++是如何从原始U-Net演变而来的。 在下文中，我们首先跟踪这种演变，激发对UNet ++的需求，然后解释其技术和实现细节。</p><h4 id="A-Motivation-behind-the-new-architecture"><a href="#A-Motivation-behind-the-new-architecture" class="headerlink" title="A. Motivation behind the new architecture"></a>A. Motivation behind the new architecture</h4><p>我们已经进行了全面的消融研究，以研究不同深度的U-Nets的性能（图1（a-d））。为了这个目的，我们使用了三个相对较小的数据集，即细胞，EM和脑肿瘤（在III-A节中详细介绍）。表I总结了结果。对于细胞和脑肿瘤的分割，较浅的网络（U-Net L 3）胜过较深的U-Net。另一方面，对于EM数据集，较深的U-Net始终优于较浅的U-Net，但性能提升仅是微不足道的。我们的实验结果提出了两个关键发现：1）更深的U-Net不一定总是更好，2）最佳架构深度取决于手头上数据集的难度和大小。尽管这些发现可能会鼓励进行自动化的神经体系结构搜索，但是这种方法由于有限的计算资源而受到阻碍[19]，[20]，[21]，[22]，[23]。另外，我们提出了一个集成架构，该架构将不同深度的U-Net合并为一个统一的结构。我们将此架构称为U-Net e（图1（e））。我们通过为集合中的每个U-Net定义一个单独的损失函数来训练U-Net e，即X 0，j，j∈{1,2,3,4}。我们的深度监控方案不同于深度图像分类和图像分割网络中常用的深度监控；在[24]，[25]，[26]，[27]中，辅助损失函数被添加到沿着解码器网络的节点上，即X 4-j，j，j∈{0,1,2,3,4}，而我们将它们应用于X 0，j，j∈{1,2,3,4}。在推理时，对集合中每个U-Net的输出求平均值。<br><img src="/2023/image/1218402-20201006205642505-430406382112.png" alt="iamge1"><br><img src="/2023/image/1218402-20201006205704748-7005017113.png" alt="iamge2"><br>上面概述的集成体系结构（U-Net e）受益于知识共享，因为集成中的所有U-Net尽管他们拥有自己的解码器但也部分共享相同编码器。 然而，该架构仍然遭受两个缺点。 首先，在集成环境下，当解码器已断开连接，较深的U-Net并不会向较浅的U-Net的解码器提供监控信号。 其次，U-Net e中使用的跳过连接的通用设计受到了不必要的限制，要求网络将解码器特征图与仅来自的相同比例的特征图进行组合编码器。 虽然是自然设计，但不能保证相同比例的特征图是特征融合的最佳匹配。</p><p>为了克服上述限制，我们从U-Net e中删除了原始的跳跃连接，并连接了集合中的每两个相邻节点，从而形成了一种新的架构，我们称之为UNet +（图1（f））。由于采用了新的连接方案，UNet +连接了不相交的解码器，从而实现了从较深的解码器到较浅的解码器的梯度反向传播。 UNet +展现了在每一个解码器中的每个节点，这些节点都是浅层流中计算的所有特征图的聚合，进一步释放了跳跃连接不必要的限制性行为。尽管在解码器节点上使用聚合的特征图比仅从编码器得到相同比例的特征图的约束要少得多，但仍有改进的空间。我们进一步建议在UNet +中使用密集连接，从而形成最终的架构提案，我们称为UNet ++（图1（g））。通过密集的连接，不仅为解码器中的每个节点提供了最终的聚合特征图，而且还提供了中间的聚合特征图和来自编码器的原始等比例特征图。这样，在解码器节点中的聚合层或许可以学习仅仅去使用相同比例的编码器特征图或者在入口使用收集的所有可用特征图。与U-Net e不同，UNet +和UNet ++对深度监督并不是必须要求的，但是，正如我们稍后将描述的那样，深度监督可以在推理期间剪枝模型，从而导致明显的speedup，而在performance仅适度下降。</p><h4 id="B-Technical-details"><a href="#B-Technical-details" class="headerlink" title="B. Technical  details"></a>B. Technical  details</h4><p>   1）网络连通：令x i，j表示节点X i，j的输出，其中i沿编码器索引下采样层，j沿着跳跃连接密集块的卷积层。 由x i，j表示的特征图的堆栈计算如下：<br><img src="/2023/image/1218402-20201006205736421-1138081347114.png" alt="iamge4"></p><p>函数H（·）是一个卷积运算，后跟激活函数，D（·）和U（·）表示下采样层和上采样层，[]表示串联层。基本上，如图1（g）所示，级别j &#x3D; 0的节点仅接收来上一个自编码器层的一个输入；级别j &#x3D; 1的节点从编码器子网接收两个输入，但在两个连续级别上；并且级别j&gt; 1的节点接收j + 1输入，其中j输入是同一跳跃连接中前j个节点之前的输出，第j + 1输入是来自较低跳跃连接的上采样输出。所有先前的特征图都会累积并到达当前节点的原因，是因为我们沿着每个跳跃连接都使用了密集卷积块。<br><img src="/2023/image/1218402-20201006205755136-1029085322115.png" alt="iamge5"><br>2）深度监督：我们在UNet ++中引入了深度监督。为此，我们将带有C核的1×1卷积和Sigmoid激活函数附加到节点X 0,1，X 0,2，X 0,3和X 0,4的输出中，其中C是给定数据集中观察到的类的数量。然后，我们定义了一种混合分割损失，包括对于每个语义尺度的像素交叉熵（cross-entropy）损失和 soft dice系数损失。混合损失可以利用两种损失函数必须提供的优势：平滑的梯度和类不平衡的处理[28]，[29]。在数学上，混合损失定义为：<br><img src="/2023/image/1218402-20201006205816335-2062825095116.png" alt="iamge6"><br>其中 y n，c∈Y 和 p n，c∈P 表示批次中c类和第n个像素的目标标签和预测概率，N表示一个批次中的像素数。然后，对于UNet ++的所有损失函数之后定义为每个独自解码器的混合损失的权重总和：![image7](&#x2F;2023&#x2F;image&#x2F;1218402-20201006205832264-947916901 (1).png)，其中d表示解码器的索引。在实验中，我们对每个损失赋予相同的平衡权重ηi，即ηi≡1，并且不针对不同输出监督的真实标签，如高斯模糊。</p><p>3）模型剪枝：深度监督可实现模型剪枝。 由于深度监督，UNet ++可以以两种操作模型进行部署：1）集成模型，其中收集所有分割分支的分割结果，然后取其平均值； 2）剪枝模型，其中仅从分割分支之一中选择分割输出 ，其选择决定了模型剪枝的大小和速度增益。 图2显示了如何选择分割分支，以及在不同的剪枝结构中的结果。 具体来说，从X 0,4不会剪枝，然而从X 0,1取得的分割结果则会导致网络的最大剪枝。</p><h3 id="III-E-XPERIMENTS"><a href="#III-E-XPERIMENTS" class="headerlink" title="III. E XPERIMENTS"></a>III. E XPERIMENTS</h3><h4 id="A-Datasets"><a href="#A-Datasets" class="headerlink" title="A. Datasets"></a>A. Datasets</h4><p>表II总结了本研究中使用的六个生物医学图像分割数据集，涵盖了来自最常用的医学成像模式（包括显微镜检查，计算机断层扫描（CT）和磁共振成像（MRI））的病变&#x2F;器官。<br><img src="/2023/image/1218402-20201006205854680-1081544965117.png" alt="iamge8"></p><pre><code class="hljs">   1）电子显微镜（EM）：数据集由EM分割挑战[30]作为ISBI 2012的一部分提供。该数据集由果蝇初生幼虫的连续切片透射电子显微镜得到的30张图像（512×512像素）组成 幼虫腹神经索（VNC）。 参考图3中的示例，每个图像都带有对应的完全注释的地面真相分割图，用于细胞（白色）和膜（黑色）。 标记的图像分为训练（24个图像），验证（3个图像）和测试（3个图像）数据集。 训练和推理都是基于96×96 patches进行的，这些patches通过滑动窗口被选择为重叠大小一半。 具体来说，在推论过程中，我们通过在重叠区域进行投票来聚集跨patches的预测。</code></pre><p>438&#x2F;5000</p><p>2）细胞：使用Cell-CT成像系统获取数据集[31]。 两名训练有素的专家手动分割了收集的图像，因此数据集中的每个图像都带有两个二进制单元格蒙版。 对于我们的实验，我们选择了354个图像的子集，这些图像在两个专家注释者之间的一致性最高。 然后将选定的图像分为训练（212个图像），验证（70个图像）和测试（72个图像）子集。</p><p>3）核：数据集由Data Science Bowl 2018分割挑战赛提供，由670个来自不同模态（明场与荧光）的分割核图像组成。 这是在此工作中使用的带有实例级注释的唯一数据集，其中每个核仁均以不同的颜色标记。 将图像随机分配到训练集（50％），验证集（20％）和测试集（30％）中。 然后，我们使用滑动窗口机制从图像中提取96×96色块，其中32像素的stride用于训练和验证模型，而1像素的stride用于测试。</p><p>4）脑瘤：该数据集由BraTS 2013 [32]，[34]提供。 为了简化与其他方法的比较，这个模型通过使用来自所有患者的MR扫描图像来训练模型，这些图像是带有Flair（液体衰减反转恢复）的20份高级别（HG）和十份低级别（LG），T1，T1c，和T2。 66,348片 我们通过将切片重新缩放为256×256进一步预处理数据集。 最后，数据集中的30位患者随机分为五张，每张都有六位患者的图像。 然后，我们将这五个折叠随机分配到一个训练集（3个折叠），一个验证集（1个折叠）和一个测试集（1个折叠）中。 真实标签分割具有四个不同的标记：坏死，水肿，非增强性肿瘤和增强性肿瘤。 在BraTS 2013之后，通过将所有四个标签都视为肯定类别，将其标签视为负面类别来完成“完整”评估。</p><p>5）肝脏：该数据集由MICCAI 2017 LiTS挑战赛提供，包括331个CT扫描，我们将其分为训练（100例患者），验证（15例患者）和测试（15例患者）子集。ground truth分割提供两个不同的标签：肝脏和病变。 对于我们的实验，我们仅将肝脏视为阳性，将其他肝脏视为阴性。</p><p>6）肺结节：该数据集由肺图像数据库协会图像收集（LIDC-IDRI）提供[33]，由七个学术中心和八个医学影像公司收集的1018例病例组成。 查明并删除了六起涉及事实真相的案件。 其余案例分为训练（510），验证（100）和测试（408）集。 每种情况都是3D CT扫描，并且结节已被标记为体积二进制掩码。<br>我们将这个体积重新采样为1-1-1间距，然后在每个结节周围进行了64×64×64的裁剪。 这些3D组用于模型训练和评估。</p><h4 id="B-Baselines-and-implementation"><a href="#B-Baselines-and-implementation" class="headerlink" title="B. Baselines and implementation"></a>B. Baselines and implementation</h4><p>为了进行比较，我们使用原始的U-Net [35]和用于2D分割任务的自定义宽幅U-Net体系结构，以及V-Net [28]和用于3D分割任务的自定义宽幅V-Net体系结构。 我们选择U-Net（或用于3D的V-Net），因为它是图像分割的常见性能基准。 我们还设计了具有与我们类似数量的参数的宽U-Net（或用于3D的宽V-Net）建议的架构。 这是为了确保我们的架构所获得的性能提升不仅仅是因为参数数量的增加。 表III详细列出了U-Net和广泛的U-Net体系结构。 我们进一步比较了UNet ++和UNet +的性能，这是我们的中间体系结构建议。 表III中给出了中间节点中的内核数。<br><img src="/2023/image/1218402-20201006205916097-873312702118.png" alt="iamge9"><br>我们的实验是在带有Tensorflow环境下的Keras中实现的。 我们在验证集上使用早期停止机制，以避免过度拟合，并使用Dice系数和Intersection over Union（IoU）评估结果。 可以在附录A中找到替代的度量指标，例如像素灵敏度，特异性，F1和F2分数以及统计分析。Adam被用作优化器，学习率为3e-4。 UNet +和UNet ++都是从原始U-Net体系结构构建的。 所有实验均使用三个NVIDIA TITAN X（Pascal）GPU（每个GPU具有12 GB内存）执行。</p><h3 id="IV-R-ESULTS"><a href="#IV-R-ESULTS" class="headerlink" title="IV. R ESULTS"></a>IV. R ESULTS</h3><h4 id="A-Semantic-segmentation-results"><a href="#A-Semantic-segmentation-results" class="headerlink" title="A. Semantic segmentation results"></a>A. Semantic segmentation results</h4><p>表IV比较了U-Net，宽U-Net，UNet +和UNet ++的数量参数和分割结果对基于六个分割任务的研究我们采用了IoU（ (mean±s.d)）来衡量。如图所示，宽的U-Net始终优于U-Net。这种改进归因于宽U-Net中的大量参数。在所有六个任务，没有深层监督的UNet ++在U-Net和宽U-Net上均实现了显着的IoU增益，如如在神经元结构（↑0.62±0.10，↑0.55±0.01），（↑0.62±0.10，↑0.55±0.01），细胞（↑2.30±0.30，↑2.12±0.09），没有深层监督的UNet ++在U-Net和宽U-Net上均获得了显着的IoU增益），细胞核（↑1.87±0.06，↑1.71±0.06），脑瘤（↑2.00±0.87，↑1.86±0.81），肝脏（↑2.62±0.09，↑2.26±0.02）和肺结节（↑5.06±1.42） ，↑3.12±0.88）分割。使用深度监督和平均投票可以更进一步改善UNet ++，将IoU提升多达0.8点。特别是，神经元结构和肺结节分割在深度监督中受益最大，因为它们在EM和CT切片中以不同的比例出现。但是，深度监督最多只能对其他数据集有效。图3描述了U-Net，宽U-Net和UNet ++的结果之间的定性比较。<br><img src="/2023/image/1218402-20201006205942502-249176643119.png" alt="iamge10"><br><img src="/2023/image/1218402-20201006210003479-9692075411110.png" alt="iamge11"></p><p>我们更进一步研究了UNet++在语义分割中的扩展性，通过将重新设计的跳跃连接应用于现代CNN架构数组中：vgg-19 [36]，resnet-152 [8]和densitynet-201 [9]，。具体来说，我们通过添加解码器子网将上述每个体系结构转变为U-Net模型，然后用重新设计UNet++的连接替换了U-Net的普通跳过连接。为了进行比较，我们还使用上述骨干架构训练了U-Net和UNet +。为了进行全面比较，我们使用了EM，细胞，细胞核，脑肿瘤和肝脏分割数据集。如图4所示，在所研究的所有主干架构和应用程序中，UNet ++始终优于U-Net和UNet +。通过20个试验，我们进一步基于U-Net，UNet +和UNet ++中每对的独立两样本t检验提供了统计分析。我们的结果表明，UNet ++是对U-Net的有效，与主干无关的扩展。为了促进可重复性和模型重用，我们针对各种传统和现代骨干架构发布了U-Net，UNet +和UNet ++的实现1。</p><h4 id="B-Instance-segmentation-results"><a href="#B-Instance-segmentation-results" class="headerlink" title="B. Instance segmentation results"></a>B. Instance segmentation results</h4><p>实例分割包括对所有对象实例进行分割和区分。 因此，比语义分割更具挑战性。 我们使用Mask R-CNN [12]作为实例分割的基线模型。 Mask R-CNN以特征金字塔网络（FPN）为骨干，去生成一个多尺度对象提案，然后通过专用的分割分支为收集的提案输出分割Mask。 我们修改了Mask R-CNN，通过用重新设计的UNet ++跳跃连接来取代FPN的普通跳过连接。 我们将此模型称为Mask RCNN ++。 我们在我们的实验中，使用resnet101作为Mask R-CNN的主干。<br><img src="/2023/image/1218402-20201006210019231-18724729881111.png" alt="iamge12"><br>表V比较了Mask R-CNN和Mask RCNN ++在核分割方面的性能。我们之所以选择Nuclei数据集，是因为图像中可以存在多个核仁实例，在这种情况下，每个实例都以不同的颜色进行注释，因此被标记为不同的对象。因此，该数据集既适合于将所有核实例都视为前景类的语义分割，也适合于将每个单独的核分别去分割的实例分割。如表V所示，Mask RCNN ++的表现优于其同类产品，IoU提高了1.82分（从93.28％提高到95.10％），Dice系数提高了3.45分（从87.91％提高到91.36％），排行榜得分提高了0.013分（0.401到0.414）。为了更好地了解这种性能，我们还训练了一个U-Net和UNet ++模型，用于使用resnet101主干进行语义分割。如表V所示，Mask R-CNN模型比语义分割模型具有更高的分割性能。此外，正如预期的那样，UNet ++在语义分割方面优于U-Net。</p><h4 id="C-Model-pruning"><a href="#C-Model-pruning" class="headerlink" title="C. Model pruning"></a>C. Model pruning</h4><p>一旦对UNet ++进行了训练，则在推理时深度d的解码器路径就与深度d + 1的解码器路径完全独立。因此，我们可以完全删除深度d + 1的解码器，从而获得训练后的较浅版本。由于引入了深度监督，因此深度为d的UNet ++。这种剪枝可以显着减少推理时间，但是分割性能可能会下降。因此，剪枝级别应通过在验证集中评估模型的性能来确定。我们在图5中对UNet ++的IoU推理速度进行了权衡研究。我们使用UNet ++ Ld表示在深度d处修剪的UNet ++（有关更多详细信息，请参见图2）。可以看出，UNet ++ L3的平均推理时间减少了32.2％，内存占用减少了75.6％，而IoU仅降低了0.6点。更积极的修剪进一步减少了推理时间，但代价是IoU明显下降。更重要的是，由于现有的深度卷积神经网络模型的存在，这种观察有可能对移动设备上的计算机辅助诊断（CAD）产生重要影响。计算量大且占用大量内存。<br><img src="/2023/image/1218402-20201006210032907-1966381351112.png" alt="iamge13"></p><h4 id="D-Embedded-vs-isolated-training-of-pruned-models"><a href="#D-Embedded-vs-isolated-training-of-pruned-models" class="headerlink" title="D. Embedded vs. isolated training of pruned models"></a>D. Embedded vs. isolated training of pruned models</h4><p>从理论上讲，可以通过两种方式训练UNet ++ Ld：1）嵌入式训练，其中训练完整的UNet ++模型，然后在深度d上剪枝以得到UNet ++ L d，2）孤立训练，其中UNet ++ L d在没有任何深度编码和解码器的节点上交互而单独训练。 参见图2，在深度监督的情况下子网的嵌入式训练包括训练所有图节点（黄色和灰色），但是在推理期间，我们仅使用黄色子网。 相反，孤立的训练包括从图形中删除灰色节点，仅基于黄色子网络进行训练和测试。<br><img src="/2023/image/1218402-20201006210046009-6405657391113.png" alt="image"><br>我们比较了图6中两个数据集上在孤立训练和嵌入式训练这两个方案中，不同级别的UNet ++剪枝。我们发现，与孤立训练相同的结构相比，UNet ++ L d的嵌入式训练产生了更高的性能模型。 当将完整的UNet ++剪枝为UNet ++ L 1时，在主动剪枝下观察到的优势更为明显。 特别是针对肝脏分割的UNet ++ L 1嵌入式培训与孤立的培训计划相比，IoU达到5分增加。 这一发现表明，来自下游深处的监督信号可以训练性能更好的浅层模型。 这一发现还与知识提炼有关，在知识提炼中，由较深的教师网络学习的知识由较浅的学生网络学习。</p><h3 id="V-D-ISCUSSIONS"><a href="#V-D-ISCUSSIONS" class="headerlink" title="V. D ISCUSSIONS"></a>V. D ISCUSSIONS</h3><h4 id="A-Performance-analysis-on-stratified-lesion-sizes"><a href="#A-Performance-analysis-on-stratified-lesion-sizes" class="headerlink" title="A. Performance analysis on stratified lesion sizes"></a>A. Performance analysis on stratified lesion sizes</h4><p>图7比较了U-Net和UNet ++用于分割不同大小的脑肿瘤。 为避免图中混乱，我们将肿瘤按大小分为七个桶。 如图所示，UNet ++在所有存储桶中始终优于U-Net。 我们还基于20个不同的试验对每个存储桶进行t检验，以衡量改进的重要性，结论是7个比较中有5个具有统计学意义（p ＜0.05）。 UNet ++分割不同大小的肿瘤的能力归因于其内置的U-Net集成，它可以基于多感受野网络进行图像分割。<br><img src="/2023/image/1218402-20201006210101598-7332997401114.png" alt="iamge16"></p><h4 id="B-Feature-maps-visualization"><a href="#B-Feature-maps-visualization" class="headerlink" title="B. Feature maps visualization"></a>B. Feature maps visualization</h4><p>在第II-A节中，我们解释了重新设计的跳跃连接可以将语义丰富的解码器特征图与来自体系结构中间层的语义级别不同的特征图进行融合。 在本节中，我们通过可视化中间特征图来说明重新设计的跳跃连接的优势。<br><img src="/2023/image/1218402-20201006210116851-18021815061115.png" alt="image"><br>图8示出了沿着脑肿瘤图像的最顶部跳过连接（即，X 0，i）的来自早期，中间和晚期层的代表性特征图。对于某一层的代表特征图是通过平均所有特征图获得的。还应注意，仅使用附加深度解码器层（X 0,4）的损失函数来训练图8左侧的体系结构，而图8右侧的体系结构是在深度监督下进行的。请注意，这些功能图不是最终的输出。我们在每个解码器分支的顶部附加了一个额外的1×1卷积层，以形成最终的分割。我们发现，U-Net中间层的输出在语义上是不同的而对于UNet +和UNet ++，输出是逐渐形成的。 U-Net中的节点X 0,0的输出经过轻微的变换（仅很少的卷积运算），而X 1,3的输出（X 0,4的输入）几乎经历了每个变换（四个下采样和三个上采样）。因此，X 0,0和X 1,3的表示能力之间存在很大的差距。因此，简单地将X 0,4和X 1,3的输出串联起来并不是最佳解决方案。相反，在UNet +和UNet ++中重新设计的跳跃连接有助于逐步完善分段结果。我们在附录B部分中进一步介绍了所有六个医疗应用程序的学习曲线，揭示了在UNet ++中添加密集连接鼓励了更好的优化并降低了验证损失。</p><h4 id="C-Collaborative-learning-in-UNet"><a href="#C-Collaborative-learning-in-UNet" class="headerlink" title="C. Collaborative learning in UNet++"></a>C. Collaborative learning in UNet++</h4><p>协作学习称为在同一训练数据上同时训练同一网络的多个分类器。人们发现它可以提高深度神经网络的泛化能力[37]。 UNet ++通常体现协作学习是通过聚合多深度网络并监督每个组成网络的分割。此外，分割头（例如，图2中的X 0,2）从强（来自真实标签的损失）和软（从邻近的较深节点传播的损失）监管接收梯度。结果，较浅的网络改善了其分割（图6）并提供了向更深入的同行提供更多信息。基本上，更深层的网络和浅层网络通过UNet ++中的协作学习使彼此正规化。与单独训练作为隔离网络的单独训练相比，一起训练多深度的嵌入式网络可以提高分割效果，这在IV-D节中很明显。 UNet ++的嵌入式设计使其可用于辅助培训，多任务学习和知识提炼[17]，[38]，[37]。</p><h3 id="VI-R-ELATED-W-ORKS"><a href="#VI-R-ELATED-W-ORKS" class="headerlink" title="VI. R ELATED W ORKS"></a>VI. R ELATED W ORKS</h3><p>下面，我们回顾与重新设计的跳跃连接，特征聚合和深度监督有关的工作，这些是我们新体系结构的主要组成部分。</p><h4 id="A-Skip-connections"><a href="#A-Skip-connections" class="headerlink" title="A. Skip connections"></a>A. Skip connections</h4><p>跳跃连接最早是在Long等人的开创性工作中引入的。 [39]他们提出了用于语义分割的全卷积网络（FCN）。不久之后，Ronneberger等人建立了跳跃连接。 [35]提出了用于医学图像语义分割的U-Net架构。但是，FCN和U-Net架构在上采样解码器特征图的处理方式上有所不同与来自编码器网络的相同比例的特征图相融合。当FCN [39]使用求和运算进行特征融合时，U-Net [35]将特征串联起来，然后再应用卷积和非线性。跳跃连接已显示出有助于恢复完整的空间分辨率的能力，从而使完全卷积的方法适用于语义分割[40]，[41]，[42]，[43]。跳跃连接已进一步用于现代神经体系结构中，例如残差网络[8]，[44]和密集网络[9]，梯度流和改善分类网络的整体性能。</p><h4 id="B-Feature-aggregation"><a href="#B-Feature-aggregation" class="headerlink" title="B. Feature aggregation"></a>B. Feature aggregation</h4><p>聚合分层特征的探索最近已经成为研究的主题。 Fourure等。 [45]提出了GridNet，它是一种编码器-解码器体系结构，其中特征图以网格方式进行布线，概括了几种经典的分割体系结构。尽管GridNet包含多个具有不同分辨率的流，但是它缺少跳跃连接之间的上采样层。因此，它不代表UNet ++。全分辨率残差网络（FRRN）[46]采用两流框架，其中全分辨率信息承载在一个流中，上下文信息承载在另一个池流中。在[47]中，提出了两种改进的FRRN版本，即具有28.6M参数的增量MRRN和具有25.5M参数的密集MRRN。但是，这些2D架构的参数数量与我们的3D VNet ++相似，并且参数是2D UNet ++的三倍；因此，仅将这些体系结构升级为3D方式可能不适用于常见的3D体积医学成像应用。我们想指出的是，我们重新设计的密集跳跃连接与MRRN中使用的连接是完全不同的，MRRN由一个公共的剩余流组成。另外，将MRRN的设计应用于其他骨干编码器和元框架（例如Mask R-CNN [12]）也不灵活。 DLA 2 [48]，在拓扑上等效于我们的中间体系结构UNet +（图1（f）），按顺序连接相同分辨率的特征图，而无需使用U-Net中的长时间跳过连接。我们的实验结果表明，通过紧密地连接各层，UNet ++可以实现比UNet + &#x2F; DLA更高的分段性能（请参见表IV）。</p><h4 id="C-Deep-supervision"><a href="#C-Deep-supervision" class="headerlink" title="C. Deep supervision"></a>C. Deep supervision</h4><p>他等。 [8]建议网络深度d可以充当正则化器。 Lee等。文献[27]证明了深度监督层可以提高隐藏层的学习能力，并强制中间层学习判别特征，从而实现网络的快速收敛和规范化[26]。 DenseNet [9]以隐式方式执行类似的深度监控。深度监督也可以在类似U-Net的体系结构中使用。 Dou等。 [49]通过结合来自特征图的不同分辨率的预测来引入深度监督，这表明它可以克服潜在的优化难题，从而达到更快的收敛速度和更强大的判别能力。朱等。 [50]在他们提出的体系结构中使用了八个额外的深度监督层。但是，我们的嵌套网络更适合在深度监督下进行训练：1）多个解码器自动生成全分辨率分割图； 2）网络被嵌入到各种不同深度的U-Net中，从而掌握了多分辨率特征； 3）紧密相连的特征图有助于平滑梯度流并提供相对一致的预测蒙版； 4）高维特征会通过反向传播对每个输出产生影响，使我们能够在推理阶段修剪网络。</p><h4 id="D-Our-previous-work"><a href="#D-Our-previous-work" class="headerlink" title="D. Our previous work"></a>D. Our previous work</h4><p>我们首先在DLMIA 2018论文[51]中介绍了UNet ++。此后，UNet ++被研究界迅速采用，可以作为比较的可靠基准[52]，[53]，[54]，[55]，也可以作为比较的基础。开发新语义分割体系结构的灵感来源[56]，[57]，[58]，[59]，[60]，[61]；它也已用于多种应用，例如在生物医学图像[62]，[63]，自然图像[64]和卫星图像[65]，[66]中分割对象。最近，Shenoy [67]针对“接触预测模型PconsC4”的任务独立而系统地研究了UNet ++，证明了在广泛使用的U-Net上的重大改进。尽管如此，为了进一步增强我们自己的UNet ++，当前的工作对我们以前的工作进行了一些扩展：（1）我们对网络深度进行了全面的研究，从而激发了对所提议的体系结构的需求（第II-A节）； （2）我们将修剪的UNet ++各个级别的嵌入式训练方案与孤立的训练方案进行了比较，发现与单独进行单独训练相比，训练多深度的嵌入式U-Net可以提高性能（第IV-D节）； （3）通过增加用于脑肿瘤分割的新的磁共振成像（MRI）数据集来加强我们的实验（第四节）； （4）我们证明了UNet ++在Mask R-CNN中的有效性，从而产生了一个更强大的模型，即Mask RCNN ++（第IV-B节）； （5）我们研究了UNet ++对多个高级编码器主干进行语义分割的可扩展性（第IV-A节）； （6）我们研究了UNet ++在分割大小不同的病变方面的有效性（第V-A节）；和（7）可视化沿退位跳过的特征传播连接以说明性能（第V-B节）。</p><h3 id="VII-C-ONCLUSION"><a href="#VII-C-ONCLUSION" class="headerlink" title="VII. C ONCLUSION"></a>VII. C ONCLUSION</h3><p>我们提出了一种名为UNet ++的新颖体系结构，用于更精确的图像分割。 我们的UNet ++改进的性能归因于其嵌套结构和重新设计的跳过连接，旨在解决U-Net的两个关键挑战：1）最佳架构的深度未知； 2）跳跃连接的不必要的限制性设计。 我们已经使用六个不同的生物医学成像应用程序对UNet ++进行了评估，并证明了针对语义分割和元框架（例如实例分割）的各种最新骨干网的性能持续改进。</p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>UNet++</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu16.04安装SSH服务</title>
    <link href="/2020/ubuntu16.04%E5%AE%89%E8%A3%85SSH%E6%9C%8D%E5%8A%A1/"/>
    <url>/2020/ubuntu16.04%E5%AE%89%E8%A3%85SSH%E6%9C%8D%E5%8A%A1/</url>
    
    <content type="html"><![CDATA[<p>第一步：查看SSH服务是不是安装</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">sudo ps -e |grep ssh</pre></div><p>　　如果啥都没看到，恭喜你，你没装ssh。那就开始下面的步骤。</p><p>第二步：安装SSH</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">sudo apt-get install openssh-server</pre></div><p>　第三步：查看端口号</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">more /etc/ssh/sshd_config</pre></div><p>　　你会看到一个：#Port 22</p><p>我的端口是22，分情况讨论。</p><ul><li><p>启动ssh命令：service sshd start</p></li><li><p>停止ssh命令：service sshd stop</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
      <tag>SSH</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>windows下配置pytorch环境</title>
    <link href="/2020/windows%E4%B8%8B%E9%85%8D%E7%BD%AEpytorch%E7%8E%AF%E5%A2%83/"/>
    <url>/2020/windows%E4%B8%8B%E9%85%8D%E7%BD%AEpytorch%E7%8E%AF%E5%A2%83/</url>
    
    <content type="html"><![CDATA[<p>借鉴了<a href="https://www.bilibili.com/video/BV1nE411b7Vx?from=search&amp;seid=941344988983295783" target="_blank">B站大佬</a>的视频，自己总结安装如下。</p><p>首先安装<a href="https://www.anaconda.com/products/individual" target="_blank">anaconda</a></p><p>按照操作顺序，依次安装，按照我个人习惯，不喜欢讲文件安装在C盘，你们自己决定。</p><p><img src="/2023/image/1218402-20200927202343364-88566838.png" alt="" loading="lazy" /></p><p>安装完毕之后。</p><p>之后打开Anaconda Prompt，如下图：</p><p><img src="/2023/image/1218402-20201026202408709-1422907397.png" alt="" loading="lazy" /></p><p>换源：</p><p>输入红线命令到Anaconda Prompt中，不过我建议换清华源，因为用conda安装软件时，比如安装pytroch就会很容易中断，因为太大了。换源命令如下：</p><div class="cnblogs_Highlighter"><pre>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/<br />conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/<br /><br />conda config --add channels https:<span style="color: rgba(0, 128, 0, 1);">//<span style="color: rgba(0, 128, 0, 1);">mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ </span></span></pre><pre class="brush:python;gutter:true;">conda config --set show_channel_urls yes</pre></div><p>　　</p><p>&nbsp;之后创建新的pytorch账户，名字随便起。我写的是pytorch</p><p><img src="/2023/image/1218402-20200927202926422-352649569.png" alt="" loading="lazy" /></p><p>&nbsp;</p><p>表示创建一个pytorch账户，-n表示名字，python=3.6表示这个环境所用的包。</p><p>按回车输入y，表示移除当前账户，因为我的pytorch账户之前存在。</p><p><img src="/2023/image/1218402-20200927203302176-2041590521.png" alt="" loading="lazy" /></p><p>之后需要安装一些包，输入Y，执行下一步。</p><p>之后就可以输入箭头所指的命令，激活环境：</p><p><img src="/2023/image/1218402-20200927203514327-1693982892.png" alt="" loading="lazy" /></p><p>就可以看到前面的base变为pytorch</p><p><img src="/2023/image/1218402-20200927203609390-693747482.png" alt="" loading="lazy" /></p><p>之后我们要考虑怎么安装pytorch。因为在接下来的步骤中会安装cuda toolkit，所以不用单独装。</p><p>我们需要进入pytorch首页：http://www.pytorch.org/</p><p>一般window使用conda，linux系统使用pip，我自己装的10.1，你们根据自己电脑的显卡，安装合适的版本。</p><p>下图是pytorch和显卡驱动型号的适配图：</p><p><img src="/2023/image/1218402-20201026202623141-1763597205.png" alt="" loading="lazy" /></p><p>前提要查看你的显卡驱动是否安装完成，如果可以看到下图信息，表明你的显卡驱动安装好了。只要出现一个就ok。</p><p><img src="/2023/image/1218402-20200927210846078-596702238.png" alt="" loading="lazy" /></p><p><img src="/2023/image/1218402-20200927203958534-242434794.png" alt="" loading="lazy" /></p><p>&nbsp;</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">conda install pytorch torchvision cudatoolkit=10.1</pre></div><p>　　记住要把最后&nbsp;-c pytorch去掉，不然还是在原来的源下载，依旧很慢。</p><p>如果出现<strong>PackagesNotFoundError: The following packages are not available from current channels</strong> 这个错误，试试添加以下语句</p><div class="cnblogs_Highlighter"><pre class="brush:python;gutter:true;">conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/# for legacy win-64conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/peterjc123/</pre></div><p><img src="/2023/image/1218402-20200927204955066-1198372176.png" alt="" loading="lazy" /></p><p>这些就是需要下载的包，输入y继续。</p><p>如果依次输入以下命令，输出是True，那pytorch配置成功。</p><p><img src="/2023/image/1218402-20200927205224052-1751253818.png" alt="" loading="lazy" /></p><p><strong>&nbsp;现在你的pytorch环境就在你的anaconda文件下的envs文件内，envs里的文件的名字就是你命名的pytorch名字。在bin下可以找到python3.6。估计在配置pycharm项目环境是会用到。</strong></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Windows</tag>
      
      <tag>pytorch环境配置</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HDC-Net: Hierarchical Decoupled Convolution Network for Brain Tumor Segmentation</title>
    <link href="/2020/HDC-Net%E9%98%85%E8%AF%BB/"/>
    <url>/2020/HDC-Net%E9%98%85%E8%AF%BB/</url>
    
    <content type="html"><![CDATA[<p>认真读的第一篇论文，翻译可能有很多问题，请见谅，建议去读原文。<br>论文地址：<br>HDC-Net: Hierarchical Decoupled Convolution Network for Brain Tumor Segmentation<br>Zhengrong Luo† , Zhongdao Jia† , Zhimin Yuan, and Jialin Peng∗<br>摘要：—从磁共振图像（MRI）准确分割脑肿瘤对于临床治疗决策和手术计划至关重要。由于肿瘤的多样性和子区域之间复杂的边界相互作用，这是一个巨大的挑战。除了准确性之外，资源约束也是另一个重要考虑因素。最近，通过使用深度卷积网络，针对此任务已实现了令人印象深刻的改进。但是，大多数最新模型都依赖昂贵的3D卷积以及模型级联&#x2F;集成策略，这会导致高计算开销和不期望的系统复杂性。对于临床使用而言，挑战在于如何在非常有限的计算预算内追求最佳准确性。在这项研究中，我们使用分层的解耦卷积网络（HDCNet）一次性分割3D立体图像，这是一种轻巧但有效的伪3D模型。具体来说，我们将3D卷积替换为新颖的分层解耦卷积（HDC）模块，该模块可以高效地探索多尺度多视图空间上下文。在BraTS 2018和2017挑战数据集上进行的大量实验表明，我们的方法在精度方面优于最新技术，但计算复杂度大大降低。</p><p>索引词-脑瘤，磁共振图像，图像分割，解耦卷积，轻量级网络</p><p>I. INTRODUCTION<br><img src="/2023/image/1218402-20200927114400193-1227259706111.png" alt="1"><br>GLioma是最常见的脑肿瘤类型之一，通常使用多个MRI序列成像，例如T1加权（T1），对比增强的T1加权（T1ce），T2加权（T2）和液体衰减反转恢复序列（FLAIR）。多模式MRI具有突出神经胶质瘤子区域的多种能力，从而为肿瘤分析提供了补充信息。例如，在T1ce中可以观察到增强的肿瘤（ET）；肿瘤核心（TC）由坏死，不增强的肿瘤组成，ET在T2中可见。 T2和FLAIR突出显示了包括水肿和TC在内的整个肿瘤（WT）。准确的肿瘤分割，尤其是分离子区域，即WT，TC和ET，是诊断和治疗计划的先决条件。但是，手动描绘在大多数临床工作流程中效率低下，因为它既费时又主观精确注释的含糊之处。因此，自动分割方法不仅可以提高诊断效率，而且可以提供可重复的结果。这项任务的主要挑战在于：1）脑胶质瘤及其子区域在患者的外观，位置和形状方面的变异性； 2）边界模糊不清； 3）子区域之间复杂的边界相互作用。</p><p>最近，通过使用全卷积网络（FCN）进行端到端学习，医学图像分割已取得了显着进步[1] – [3]。对于脑肿瘤分割，最先进的模型[4] – [11]是具有跳过连接的编码器-解码器体系结构的变体，它最初作为U-Net [2]引入，并已被证明可有效地用于恢复细粒度的细分。给定大量的大脑图像，已经探索了同时使用3D卷积和2D卷积的网络。 2D网络[9]，[12]，[13]逐片处理卷，通常是内存高效，但不可避免地忽略了连续的切片间一致性。 3D网络[14]，[15]可以通过直接将整个体积作为输入来一次性分割整个体积。因此，它可以利用3D内核在所有三个空间维度上充分利用完整的空间上下文，并已显示出优异的结果，但以显着增加GPU内存消耗和参数数量为代价。对于2D网络，一种简单而有效的补救措施是在3D体的不同角度（即轴向，冠状和矢状视图）上集合独立的分割，被许多研究[7]，[9]，[12]，[13]，[16]采用。对于2D和3D模型，另一个广泛使用的技巧是采用模型级联迭代地细分分割[12]，[17]或利用肿瘤子区域的分层结构[7]，[18]。尽管采用集成和级联策略可以提高性能，但主要缺点是不需要的系统和计算复杂性。除了分割精度外，计算和存储效率是模型设计的另一个重要考虑因素。因此，有利的是为3D体积分割开发一个轻量但有效的模型，该模型可以本质上包含仅具有低维卷积的完整空间信息。</p><p>为了在具有挑战性的分割任务中实现更高的性能，构建更深，更宽的FCN（这还允许对较大的空间输入和远程上下文进行编码）是有益的。但是，对于3D体积图像处理，当前的深度架构，尤其是那些使用昂贵的3D卷积的深度架构，经常受到对大量内存和计算能力的需求的限制。尽管使用2D卷积可以大大减少参数数量，但它们固有的局限性在于无法捕获丰富的空间上下文。在严格的内存和计算预算约束下，通过分解标准卷积（例如深度方向可分离卷积[19]，组卷积[20] – [22]和常规的多分支结构[23]）来设计具有低冗余的有效内核。 ]，已被视为解决此问题的有效方法。在本文中，我们以分层方式将跨通道域和空间域的标准卷积解耦同时减少冗余并利用多视图和多尺度空间上下文</p><p>在这项工作中，我们介绍了一个分层的解耦卷积网络（HDC-Net）（图1（a）），它是一个轻量级的伪3D网络，旨在作为脑肿瘤分割的简单而强大的基线。我们采用减少通道数的3D U-Net架构作为我们的骨干网络，并使用新颖的轻量级块来替代昂贵的3D卷积。具体来说，为了以较低的计算成本对多视图和多尺度空间上下文进行编码，我们引入了一种新颖的分层解耦卷积（HDC）（图2（b））。而不是像3D一样在空间和通道维度上同时进行计算</p><p>如图2（b）所示，HDC在空间和通道维度上将标准卷积解耦。更具体地说，a）在空间域中，我们通过将3D空间卷积分解为工作在不同视图（轴向，冠状和矢状视图）上的两个互补2D卷积来引入视图解卷积，这可以在最小化感知的情况下降低计算复杂性空间环境； b）在通道域中，我们不是通过简单地堆叠2D卷积来近似3D卷积，而是对轴视图的2D卷积应用了一种新颖的分层组解耦卷积视图，即在具有分层连接的特征通道的子组上应用平行轴向视图卷积。这样，我们不仅可以将焦点放在特定的视图上，还可以从多个领域视图对焦点视图上的线索进行编码，这对于处理医疗量是理想的。为了允许大量输入并捕获远距离空间上下文，我们在第一层进一步插入了额外的下采样[24]。这项工作是对我们的初步工作的广泛扩展[25]，具有改进的网络体系结构以及更广泛的性能分析和比较实验。</p><p>II. RELATED WORK<br>大多数现有的用于多类脑肿瘤分割的方法都使用具有2D或&#x2F;和3D卷积的FCN或U-Net变体来设计有效的方法。 与2D网络相比，即使是单个3D网络也可以获得更好的性能，但以高计算开销为代价。 而且，通常采用集成和级联策略来进一步提高2D和3D网络的性能。</p><p>为了提高2D网络用于肿瘤分割的性能，在许多研究中已采用多个2D网络的多视图集成[9]，[13]，[16]，[26]。 例如，在[16]和[13]中集成了在三个视图上的独立2D分割。 除了多视图集成之外，在[27]中还使用了几个具有丢包的随机采样网络的集成。 Pereira等。 [28]开发了一种改进的U-Net，具有新颖的特征重组和重新校准模块，并且可以级联地分割脑肿瘤的子区域以利用其层次结构。</p><p>3D FCN，包括3D U-Net [29]，V-Net [30]及其使用多尺度输出[7]，[31]，残差连接[7]，[31]，[32]的变体，空洞卷积 [4]，[7]，[32]，CRF改进[12]等已广泛用于脑肿瘤分割。 通过改进的体系结构，Nuechterlein等人。 [14]将ESP-Net [33]的3D变体与金字塔形细化相结合。 Chen等。 [4]用3D扩张的多纤维网络（3D DMFNet）解决了脑肿瘤分割问题。Mlynarski等。 [34]介绍了一种2D-3D模型，在该模型中，多视图2D网络学习的功能被用作3D U-Net的附加输入，以捕获较大的空间环境。 模型集成进一步提高了性能。</p><p>模型级联策略已被许多著作[7]，[14]，[17]，[32]，[35]采用，以提高3D模型的性能。华等。 [17]介绍了级联的V-网络首先提取整个肿瘤，然后将其划分为子区域。在[4]中开发了一个由3D SE-Inception网络组成的级联，以依次分割脑肿瘤的亚结构。 Wang等。 [7]设计了一个级联的各向异性卷积网络（Cascaded-Anisotropic-Net），在该网络中，他们不仅使用多视图集成，而且还通过模型级联来提高最终的分割性能。徐等人，而不是简单地使用连续模型。 [5]引入了3D深度级联注意力网络（Cascaded-Attention-Net），该网络可以探索分区之间的潜在关联作为指导。由于使用级联方法的系统复杂度很高，Zhou等人。 [8]用单个多任务网络（MultiTask-Net）解决了多标签分割问题，该网络有多个输出用于单次分割。并非同时训练多个任务，而是使用课程学习来逐渐集中精力处理更困难的任务。在此研究中，我们没有使用集成，级联或课程学习，而是仅使用具有4类输出的单个网络来同时分割所有子区域。</p><p>临床任务通常需要在有限的计算预算下实现最佳准确性。标准3D（空间）卷积涉及昂贵的4D操作，包括空间和通道信息。通过分离标准卷积的不同维度，可分离卷积已被证明是一种针对轻量级网络的有效策略。这种流行的深度卷积[19]将标准卷积分解为Depth-wise Convolution与Point-wise Convolution的组合。群卷积[20] – [22]，对预定义的通道组执行并行卷积。在多分支架构中，著名的Inception V3 [21]进行了空间分解。卷积变成非对称卷积，例如，将n×n卷积替换为n×1卷积，然后是1×n卷积。对于肿瘤分割，DMFNet [4]建立在多纤维单元[36]上，该单元使用有效的群卷积，并取得了良好的性能。在Cascaded-各向异性网络[7]中，Wang等。将3×3×3的空间3D卷积分解为2D堆栈3×3×1的卷积和1×1×3的1D卷积。但是，仅在一个空间视图上使用交叉切片1D卷积和切片内部2D卷积具有有限的利用完整3D空间上下文的能力，并且通过多种技巧进行了补偿，其中包括多尺度输出，多视图集成和模型级联。 Chen等人在S3D-UNet中[37]。使用S3D卷积[38]，并将其扩展为使用将不同类型的2级卷积和1D卷积结合起来，这与我们的方法密切相关。但是，我们专注于通过焦点视图将3D空间卷积分层解耦为2D卷积，在该视图上MR体积图像最初具有最高的片内分辨率，并且信息最可靠。</p><p>III. METHOD<br>A. Architecture of the HDC-Net<br>HDC-Net的概述如图1（a）所示。 我们默认进行端到端的多标签学习，并执行体积密集分割。 将来自多种模态的图像连接起来，形成模型的4通道输入。 用于3D分割的HDC-Net的主体主要由一个新颖的HDC模块（图2）组成，该模块实质上依赖于更有效的2D卷积，并将在以下各节中详细介绍。</p><p>HDC-Net的骨干架构是3D U-Net的轻量级变体，具有：a）每层减少的通道数（仅32个通道），b）额外的下采样&#x2F;上采样操作以允许相对较大的输入量。 具体来说，骨干网由一个具有4个下采样级的编码器和一个具有4个上采样级的解码器组成，如图1（a）所示。 定期的下移（PDS）操作[24]在第一阶段用作下采样，因为该下采样策略没有参数，并且可以保留完整的图像信息。 这里的PDS操作旨在将大小为Cin×H×W×D的高分辨率输入张量Tin重新排列为大小为Cout×H &#x2F; 2×W &#x2F; 2×D &#x2F; 2的低分辨率张量Tout，其中H×W×D 是Tin的空间大小，而Cin是通道号。 Tout的空间大小是输入空间大小的1&#x2F;2倍，而输出通道Cout的数量是8×Cin。 数学上PDS的操作描述如下，<br><img src="/2023/image/1218402-20200927114442550-1788825326.png" alt="2"></p><p>c,x,y,z是Tout的坐标。</p><p>在我们的初步研究中[25]引入了HDC-Net的简化版本HDC-Net0，如图1（b）所示。与HDC-Net相比，HDC-Net0不使用附加的下&#x2F;上采样层，因此在严格的内存约束下仅允许相对较小的输入大小。为了弥补这一限制，HDC-Net0同时利用了多视图集成和模型级联策略来提高性能。基于这种观察，在临床使用中，医师通常会沿着所有轴向，冠状和矢状平面查看体积图像，以捕获互补信息，并一一识别肿瘤的子区域。更具体地说，1）为了减轻脑肿瘤组织之间的干扰，HDC-Net0将多标签分割任务分解为三个二进制分割子任务，每个子任务从背景中分割目标； 2）还使用了多视图合奏。请注意，由于我们模型中的各向异性分解，通常仅在2D模型中使用的多视图合奏在此处适用。然而，由于重复的模型训练和测试，模型级联和集成策略将大大增加模型的复杂性。相比之下，这项研究中提出的HDC-Net能够使用单个网络一次性通过分割所有肿瘤亚区域，从而提高了计算效率。</p><p>B. The HDC module<br><img src="/2023/image/1218402-20200927114456646-2116617853.png" alt="3"></p><p>近来，已广泛使用通过几个低维内核的乘积来逼近满秩滤波器以减少存储器开销。 但是，挑战在于如何仅使用低维内核和非常小的网络在非常有限的计算预算内追求最佳精度。 为此，我们将进一步努力，以利用多尺度的视野和丰富的空间背景（仅需较低的分辨率）来提高分割精度尺寸内核。 为了解决这些挑战，我们提出了在空间和通道域上进行去耦卷积的层次化集成，以减少可学习参数的大小并提高判别能力。</p><p>提出的HDC模块如图2（b）所示，该模块具有相互连接的多分支结构，并采用一次和二次卷积。 具体而言，一次卷积应用于并行分支的主卷积（例如3×3×1）用于在3D体积的焦点视图上分层提取多尺度特征，而二次卷积（例如1×3×3） 遵循多分支模块的作用是通过一次卷积来混合多尺度输出，以及在互补视图上提取空间上下文特征。 本质上，HDC模块仅基于2D卷积。 在详细介绍HDC模块之前，我们首先介VDC（HDC的简化版本）作为基准。 然后，我们使用一种新颖的分层组卷积（HGC）块对其进行改进，并获得HDC模块。</p><p>视图解耦卷积（VDC）如图2（a）所示。为了在减少参数数量的同时更有效地使用3D空间上下文信息，我们将3×3×3的3D卷积核在空间上分解为两个互补的2D卷积，即3×3×1卷积和1× 3×3卷积，适用于3D空间上的不同2D视图。为了近似计算两个3×3×3空间3D卷积的堆栈，我们使用四个2D卷积的堆栈，包括三个3×3×1卷积和一个1×3×3卷积，如图2（a）所示。假设3×3×1卷积对应于轴向视图切片上的运算。然后，使用VDC中的前三个2D卷积捕获轴向视图上的内部切片特征，随后的1×3×3 2D卷积将融合互补视图上的空间一致性和上下文。通过不对称分解和连续卷积的特殊布置，VDC能够强调通常具有最高空间分辨率的轴向视图。</p><p>作为VDC的改进，HDC使用了一种改进的称为HGC的组卷积组件，该组卷积组件在图2（b）的实心框中突出显示，作为增强的一次卷积。多尺度上下文特征捕获是至关重要的，重要在对于神经网络模型的表示强度以及最终的分割精度。除了在HGC中将空间解耦的卷积简单地堆叠为VDC之外，我们还进一步在通道域上解耦卷积运算，并且在特征通道不同子组上并行进行2D卷积（3×3×1）。更具体地说，在进行1×1×1卷积之后，HGC块首先将特征通道分组为s个（&#x3D; 4个）大小相等的子组（在我们的设置中每组8个通道）。然后，对s-1个子组执行3×3×1卷积；快捷连接应用于第一个子组以将HGC重新配置为残差学习[39]。为了提升特征组和在主视图上捕获的多尺度特征的信息流动，我们进一步使用了内部组之间的连接，如图2（b）所示。类似的组间联系已在诸如[22]的数项研究中使用。连接所有输出的特征图后，执行一次1×3×3卷积以在另一视图上编码提示。通过在HDC模块中集成组解耦卷积，层次连接和视图解耦卷积，可以：1）从多个视图区域中提取语义特征，以及多尺度信息可以被发现； 2）焦点视图的3D空间上下文感知能力相比于2D方法可以得到提升3）模型在视图上是不对称的，因此有促使去使用集成方法来获得更好且鲁棒的预测性能。</p><p>C. Variants of the HDC module<br><img src="/2023/image/1218402-20200927114507339-2141993524.png" alt="4"></p><p>提出的HDC模块可以灵活地使用其他空间解耦的卷积。 例如，代替恒定使用1×3×3卷积，我们可以从1×3×3卷积和3×1×3卷积在不同层中随机选择卷积。 我们将这种类型的HDC模块命名为HDC +。 另一个变体是将1×3×3替换为1×1×3卷积，即我们首先执行切片内卷积，然后执行像素级切片间卷积。 我们命名为HDC-的变体，如图3（a）所示。</p><p>在本节中，我们进一步介绍HDC模块的另一个变体HDC ++，它涉及在3D体积的三个视图上进行2D卷积。 HDC ++也是多分支结构，如图3（b）所示。 但是，对于不同的分支，我们应用不同的等级-2（2D）卷积从不同的视图提取特征。 对于最后三个分支中的每个分支，我们堆叠相同的两个卷积。 为了去进一步提升特征复用和信息传递分支，我们引入了一个与[36]中的多路复用器相似的特征融合模块。 具体来说，在第一次卷积后，四个分支通过1×1×1卷积融合在一起，然后将其输出与各个分支连接起来。 这样，多视图信息被组合在单个块中。</p><p>D. Complexity of the proposed model<br>通常通过网络参数和FLOPs的数量来衡量模型的复杂性[20]，[21]。 内核大小为Kx×Ky×Kz的卷积层中的参数数为Cin×Kh×Kw×Kd×Cout，其中Cin和Cout分别是输入通道数和输出通道数。 总体而言，我们的HDC-Net具有0.29M参数。 假设卷积层的输入是Cin×H×W×D的4维张量，输出是Cout×H×W×D， FLOPs是Cin×Kh×Kw×Kd×Cout×H×W×D。输入尺寸为128×128×128时，HDC-Net需要24个GFLOP，而3D U-Net需要1900个以上GFLOPs。</p><p>由于HDC模块被两个连续3D卷积的替换，因此我们将模块的参数大小与两个具有压缩率的3D卷积的级联进行比较。 假设每层中的通道为Cin &#x3D; Cout &#x3D; 32，两个3D卷积的参数数目为55296，对于HDC 12992，对于VDC为36864，对于HGC为3776，对于HDC-为6848，对于HDC +为12992，对于HDC ++为6528。 HDC &#x2F; HDC +的压缩率为0.23，VDC为0.67，使用HGC时为0.07，使用HDC-时为0.12，使用HDC ++时为0.12。 表I中显示了总的模型大小比较。</p><p>IV. EXPERIMENTAL RESULTS<br>A. Dataset<br>我们使用脑肿瘤的基准评估我们的方法分段挑战（BraTS）， BraTS 2018和BraTS2017。具体来说，1）BraTS 2018具有两个公开可用的数据集：带注释的训练集（285个受试者），包括210个高级别神经胶质瘤（HGG）和75个低级别神经胶质瘤（LGG） ）案例，验证集（排行榜）（66个主题），这些验证集的评估是通过网上隐藏的标注来完成，2）BraTS 2017包含带注释的285个主题作为训练集，包含46个主题作为在线评估的验证集。 对于这两个基准，每个主题具有四种模式的MRI数据，即T1 T1ce，T2和FLAIR（液体衰减反转恢复序列）。 将所有图像剥离，对齐并且内插至1 mm各向同性分辨率。按照挑战指南，使用骰子和Hausdorff距离的第95个百分位 （Hausdorff95）来评估性能。</p><p>B. Implementation details<br>这些网络在Pytorch中实现。 使用ReLU激活功能和批量归一化。 我们的模型使用Adam优化器进行了优化，初始学习率设置为10−3。 我们以L2正则的10−5权重衰减来规范化模型。 1）对于HDC-Net，我们使用多类soft Dice 子函数作为损失函数。 我们在两个并行的Nvidia Tesla K40 GPU上使用随机裁剪的128×128×128大小和10个batch size的体积训练网络，历时800个epoch。 使用包括随机旋转和随机强度偏移的数据增强。 总训练时间为12.8小时，每卷的平均预测时间为2.3秒。 2）对于HDC-Net0，我们使用soft Dice函数作为损失函数。 我们训练的模型使用随机裁剪尺寸为144×144×24和batch size为2，模型在单个Nvidia Tesla K40 GPU上并且epoch 800次。 该代码可从<a href="https://github.com/luozhengrong/HDC-Net%E8%8E%B7%E5%BE%97%E3%80%82">https://github.com/luozhengrong/HDC-Net获得。</a></p><p>C. Results on BraTS 2018 dataset<br><img src="/2023/image/1218402-20200927114520299-159119888.png" alt="image"></p><p>1）在BraTS 2018验证数据集上的细分结果：在BraTS 2018验证数据集上，我们的HDC-Net的ET，WT和TC骰子的平均准确度分别达到80.9％，89.7％，84.7％。 图4显示了具有我们分割分数分布特征的组级别箱线图。在图4中，绘制了患者之间Dice分数和Hausdorff95距离的平滑分布以及ET，WT和TC组中各个患者的值。 图4.中可以看到，除了少数失败的案例，HDC-Net对于所有这三个组中的大多数对象都表现良好<br><img src="/2023/image/1218402-20200927114733497-1436887840.png" alt="image1"><br>2）HDC-Net及其变体的视觉比较：我们首先在BraTS 2018训练集上进行视觉比较。 具体来说，我们随机选择BraTS 2018培训集中的80％进行培训，其余20％进行测试。 视觉比较结果显示在图5中，其中显示了来自两个主题的示例。 从图5中可以看出，所有方法在WT区域均表现出很好的性能，而HDC-Net在更具挑战性的ET和TC区域上在视觉上显示出与标注的更好一致性，该区域用红色箭头高亮显示出来。</p><p>3）HDC-Net的消融研究：默认情况下，HDCNet使用HDC模块作为基本构件。 在此实验中，我们研究了建议的HDC模块及其变体对BraTS 2018验证集上的分割性能的影响。 更具体地说，比较的变体包括：1）2（a）中的VDC，即不带HGC的HDC模块； 2）HDC中的HGC子模块，如图2（b）所示； 3）图3中的HDC-； 4）HDC +，随机使用从不同层 1×3×3卷积和3×1×3卷积中选择卷积; 5）图3中的HDC ++</p><p>比较的结果显示在表I中。与HDC-Net相比，HDC-Net（VDC）在三个区域的Dice中的性能下降分别为1.7％，1.3％，1.3％。在不使用complementary view的情况下，HDCNet（HGC）在这三个区域的性能分别下降了1.2％，0.9％和1.7％。通过在complementary view上使用1×1×3卷积，HDC-Net（HDC-）在平面外方向上的接收场要小得多，并且显示出这三个地区的性能下降分别为1.5％，1.2％和0.7％。相比之下，使用HDC的HDC-Net能够通过分层组的集成和视图解耦的卷积来捕获更丰富的空间上下文，从而可以比使用VDC和HDC-的HDC-Net更好。使用HDC +，我们在ET区域获得了最高的81.5％的性能，但是该模型显示出在其他两个区域上的性能下降很小。 HDC-Net（HDC ++）也显示 在ET区域的性能比HDC-Net（HDC）更高。与强大的3D基线（即V-Net和3D U-Net）相比，HDC-Net在具有挑战性的ET和TC区域分割方面获得了巨大的性能提升，但模型尺寸却大大减小了。与其他变体相比，使用HDC的HDC-Net展现了模型大小和分割精确度之间达到了良好平衡。在图5中的视觉比较也表明，HDC-Net的结果与三个子任务的标注更加一致。<br><img src="/2023/image/1218402-20200927114543292-1857077422.png" alt="image2"><br>4）HDC-Net0的消融研究：在表I中，我们还研究了HDC-Net0中关键组件的影响。 与HDC Net相比，HDC-Net0仅允许较小的输入大小。 为了提高性能，它使用多视图集成和模型级联。 多视图集成表示为Ens。 请参见表I。在HDC-Net0中使用VDC和HDC-的效果与在HDC-Net中使用的效果相似。 借助多视图集成和模型级联，HDC-Net0获得了显着的性能提升。 但是，单HDC-Net效率更高，性能更高。 特别是，在具有挑战性的ET和TC细分方面，HDC-Net分别比HDC-Net0高出1.6％和2.2％。</p><p>5）与现有技术的比较：多视图集成和模型级联已被证明有效地提高了分割性能，并被广泛用于肿瘤分割。 因此，我们在六个类别中将我们的方法与最新方法进行了比较：1）多视图2D网络的集成； 2）单一3D网络 3）级联3D网络； 4）多个3D网络的集合； 5）同时使用多视图集成和模型级联的伪3D网络； 6）单伪3D网络。 提出的HDC-Net是单个伪3D网络，HDC-Net0是同时使用多视图集成和模型级联的伪3D网络，这将不可避免地增加计算和系统复杂性。<br><img src="/2023/image/1218402-20200927114820758-2063928957.png" alt="6"><br>表II总结了BraTS 2018验证数据集的比较结果。 可以观察到，ET和TC子区域的分割比整个肿瘤分割更具挑战性。 结果，所有方法对于WT分割均显示出更好的分割精度，而对于其他两个在临床上更重要的任务则表现出急剧的性能下降。 总体而言，即使采用多视图集成策略的2D方法也没有足够的竞争力。 相比之下，单个3D模型（例如3D U-Net和V-Net）已经可以实现令人鼓舞的结果。 与强大的基线模型（例如V-Net [12]，V-Net + CRF [12]，3D UNet，残差3D-UNet以及级联V-Net [17]）相比，我们的HDC-Net表现得更好 具有挑战性的ET和TC细分的细分精度。 尤其是，我们使用HDC +模块的HDCNet在Dice中对ET区域分割显示出最高的81.5％的性能。</p><p>如表II所示，级联的3D模型显示出明显改善的结果，但是通常以高系统复杂性为代价。 尽管Multitask-Net [8]通过共同学习所有具有多个输出的二元任务解决了这个问题，但是模型训练需要在 curriculum training下进行连续训练。 与Multitask-Net [8]相比，我们的单通道HDC-Net在ET和TC的Dice中获得了1.6％和1.2％的大性能提升，但参数却减少了47倍。 为了增强多任务模型[8]，在[5]（CascadedAttention-Net）中引入了级联注意机制，以利用子区域之间的相关性作为指导。 Cascaded-Attention-Net分别在ET，WT和TC获得80.8％，90.7％，85.1％的最先进执行效果，其中比我们HDC-Net中ET分别降低0.1％，WT高1.0％和TC高0.4％ 。</p><p>Kao等人探索了多种最先进方法的集合。 [40]。 但是，在ET，WT和TC的Dice中，其性能分别比我们的HDC-Net低2.1％，0.2％和3.4％。 此外，异构模型的集成不可避免地导致非常复杂的系统，这个系统需要大量的计算资源，而最终模型无论在训练还是测试阶段均缺乏效率。 相比之下，最新技术NoNewNet [6]使用训练交叉验证和集成在不同子集上的五个训练网络的结果。 当我们的HDC-Net进行多类预测时，NoNewNet（ 多类）的执行性能在WT方面比HDC-Net高1.1％，在ET和TC方面比HDC-Net低1.2％和0.4％。 此外，我们HDC-Net的参数和FLOPs的数量分别仅为NoNewNet（51.8M和202 GFLOPs）的0.6％和12％。 通过将多类预测分为三个二进制分段，NoNewNet（多任务）可以分别在WT和TC高HDC-Net的 1.2％和0.5％，但显示出ET的性能较差。 尽管具有出色的性能，但NoNewNet依赖于几个独立训练的模型的集合，因此具有训练和预测复杂度高的局限性。 相反，我们的单次one-pass模型非常轻便，高效，但性能却相当。</p><p>在表II中，我们还与其他伪3D模型进行了比较，这些伪3D模型通常使用跨空间域或通道域的解耦卷积。这些模型是轻量级，模型尺寸小的模型，也适合在有限的硬件资源下工作。与性能最佳的CascadedAnisotropicNet [7]，[35]相比，我们分别获得了ET和TC 1.8％和1.5％的性能提升。此外，CascadedAnisotropicNet依赖于多尺度输出，多视图集成和模型级联策略，并且涉及使用九种独立训练模型进行预测，这些模型的总大小是我们HDC-Net的6倍以上。因此，此类方法的代价是系统复杂度高。相比之下，使用单个轻量模型执行一次通过分割的方法，例如3D ESPNet [14]，S3D-UNet [37]，3D DMFNet [4]和HDCNet，则更为有利。 S3D-UNet [37]与我们的方法密切相关，并使用基于1D 1×1×3和2D 3×3×1卷积的多分支S3D块。但是，这种方法无法产生最先进的性能，特别是对于ET区域。通过将2D 1×3×3和2D 3×3×1卷积与多分支体系结构进行分层集成，我们提出的HDC-Net的性能优于S3DUNet，分别在ET高出6.0%，WT高出0.3%和TC高出1.6%。尽管HDC模块也是基于与S3D-UNet相同的1D和2D卷积，但是对于ET，WT，和TC，在带有HDC-的HDC-Net中，Dice仍然比S3D-UNet分别高出4.5％，0.9％和0.9％。</p><p>[1]  这个数据是从哪儿获得的？<br>另一种高效的先进方法是3D DMFNet [4]，它集成了扩张卷积以捕获多尺度上下文信息，并集成了多光纤单元以减少参数。除了通道分组策略之外，多光纤单元还利用1×1×1作为多路复用器，以促进消息在通道组之间的流动。与3D DMFNet相比，我们的HDC-Net在ET和TC分割方面获得了0.8％和0.2％的性能提升，而WT却有0.9%的下降。但是，3D DMFNet （3.88M）的参数大小是我们HDC-Net（0.29M）的13倍以上，这表明所提出的轻量级模型具有强大的学习能力。</p><p>D. Results on BraTS 2017 validation set<br>为了完整起见，我们还报告了初步研究中提出的关于BraTS 2017的HDC-Net0的结果[25]。 由于BraTS 2017的在线评估已经结束，因此我们无法在此验证集中报告HDC-Net的结果。<br><img src="/2023/image/1218402-20200927114556990-1140269729.png" alt="image7"></p><p>1）在BraTS 2017验证集上对HDC-Net0的消融研究：在表III中，我们测试了HDC模块的两个简化版本（即VDC和HDC-）的效果以及多视图集成的影响（ Ens）。 如表III所示，HDC-Net0（HDC）在ET，WT和TC方面分别优于HDCNet0（VDC）3.2％，1.7％和2.3％，并且优于HDC-Net0 （HDC-）分别为ET，WT和TC的1.3％，1.0％和2.1％。 而且，通过小尺寸输入（144×144×24）到HDC-Net0，多视图集成策略可以显着提高性能</p><p>2）BraTS 2017验证集的比较：结果列于表IV。我们将HDC-Net0与（1）Li等进行了比较。 [26]融合了多视图分割； （2）赵等。 [41]，其中集成了多视图集成和CRF改进； （3）Isensee等。 [31]，它使用U-Net的3D版本，并在定位路径和最终输出中集成了不同级别的分割层； （4）Pereira 等。 [28]，它使用了两个新颖的FCN网络的级联； （5）Jungo等。 [27]集合了几个随机采样的网络进行预测； （6）Kamnitsas等。 [42]，它使用了多个最新模型的集合； （7）混合2D-3D [34]中的模型； （8）陈等。 [43]，它使用了一个新型的双重训练方案多级DeepMedic； （9）在[8]中的多任务网络;（10）在[7]中的CascadedAnisotropicNet。相比之下，我们的方法优于大多数方法，包括[42]中的最新集成方法。由于其较小的模型尺寸，HDC-Net0的优势在于可以在有限的硬件资源预算下工作，而且可以产生令人满意的结果。但是，它具有较高的局限性 HDC-Net的模型冗余。</p><p><img src="/2023/image/1218402-20200927114610889-549987943.png" alt="9"></p><p>V. DISCUSSION AND CONCLUSION<br>我们使用新型轻量级HDC-Net解决了脑肿瘤分割问题。 为了减少计算开销，我们使用一种新颖的HDC模型探索了视图和组解耦卷积，它可以通过在3D图像中编码多尺度多视图上下文，并减少参数数量的同时提高执行性能。 在BraTS 2018和2017基准测试上的实验表明，我们的方法仅需0.29M参数即可达到竞争性能，参数数量比最新3D模型NoNewNet [6]低了170倍，比最新的轻量模型3D DMFNet [4]模型的参数低了13倍。 。</p><p>尽管我们所提出的方法总体执行性能优异，但在一些具有挑战性的情况下，其在ET &#x2F; TC上的准确性仍然很低。 图6演示了两种代表性情况，其中TC和ET显示了不可见的边界。 为了解决这些问题，将来我们将利用多模式数据的更好融合而不是简单的级联。<br><img src="/2023/image/1218402-20200927114631709-982409666.png" alt="image0"></p>]]></content>
    
    
    <categories>
      
      <category>论文阅读</category>
      
    </categories>
    
    
    <tags>
      
      <tag>HDC-Net</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用VNC连接ubuntu16.4错误AuthenticationFailure问题</title>
    <link href="/2020/%E4%BD%BF%E7%94%A8VNC%E8%BF%9E%E6%8E%A5ubuntu16.4%E9%94%99%E8%AF%AFAuthentication%20Failure%E9%97%AE%E9%A2%98/"/>
    <url>/2020/%E4%BD%BF%E7%94%A8VNC%E8%BF%9E%E6%8E%A5ubuntu16.4%E9%94%99%E8%AF%AFAuthentication%20Failure%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<p>解决办法：<br />是因为vnc用一套自己的密码系统，不要去输入ssh登录时的密码，所以只需要进入远程服务器中，设置一哈vnc的密码即可！</p><p><span class="hljs-variable">在终端输入命令：vncpasswd</span></p><p><span class="hljs-variable"><img src="/2023/image/1218402-20200926213946395-297999655.png" alt="" loading="lazy" /></span></p><p>&nbsp;</p><p>&nbsp;到此可以试试远程</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
      <tag>VNC远程</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ubuntu16.04安装nvidia显卡驱动</title>
    <link href="/2020/ubuntu16.04%E5%AE%89%E8%A3%85nvidia%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8/"/>
    <url>/2020/ubuntu16.04%E5%AE%89%E8%A3%85nvidia%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8/</url>
    
    <content type="html"><![CDATA[<p>本篇博客来自：<a href="https://blog.csdn.net/weixin_42546496/article/details/88640174" target="_blank">ubuntu16.04安装nvidia显卡驱动</a></p><p>1、打开blacklist.conf<br />sudo vim /etc/modprobe.d/blacklist.conf<br />若未安装vim可通过sudo apt-get install vim安装或使用vi<br />（vim界面配置及相应状态切换及使用教程自行百度）<br />2、在blacklist.conf文件最后部分插入以下两行内容<br />blacklist nouveau<br />options nouveau modeset=0<br />3、更新系统<br />sudo update-initramfs -u<br />4、重启系统（一定要重启）<br />sudo reboot<br />5、验证nouveau是否已禁用<br />lsmod | grep nouveau</p><p>没有信息显示，说明nouveau已被禁用，接下来可以安装nvidia的显卡驱动。</p><p><strong>注明，以上步骤我个人没用。</strong></p><p><strong>以下开始操作。</strong></p><h2><a name="t1"></a><a name="t1"></a><a id="_19"></a>下载英伟达显卡驱动</h2><p>1、在英伟达的官网上查找你自己电脑的显卡型号然后下载相应的驱动。网址：<a href="http://www.nvidia.cn/page/home.html/">http://www.nvidia.cn/page/home.html/</a><br />要根据自己的电脑系统、显卡型号进行下载。<br />我下载的版本：NVIDIA-Linux-x86_64-450.57.run（注意不同的版本最后安装执行的具体选项不同）<br />下载后的run文件拷贝至home目录下，用于以后安装。</p><h2>显卡驱动安装</h2><p>1、在ubuntu下按ctrl+alt+f1进入命令行界面，然后输入用户名和密码。<br />接着在命令行界面下输入：<br />sudo service lightdm stop //这个是关闭图形界面，不执行会出错。<br />然后卸载掉原有驱动：<br />sudo apt-get remove nvidia-* （若安装过其他版本或其他方式安装过驱动执行此项）</p><p>2、给驱动run文件赋予执行权限：<br />cd ./<br />sudo chmod a+x NVIDIA-Linux-x86_64-396.18.run</p><p>3、安装：<br />cd ./<br />sudo sh ./NVIDIA-Linux-x86_64-410.78.run -no-x-check -no-nouveau-check -no-opengl-files<br />//只有禁用opengl这样安装才不会出现循环登陆的问题<br />-no-x-check：安装驱动时关闭X服务<br />-no-nouveau-check：安装驱动时禁用nouveau<br />-no-opengl-files：只安装驱动文件，不安装OpenGL文件<br />安装过程中的选项：<br />The distribution-provided pre-install script failed! Are you sure you want to continue?<br />选择 yes 继续。<br />Would you like to register the kernel module souces with DKMS? This will allow DKMS to automatically build a new module, if you install a different kernel later?<br />选择 No 继续。<br />问题没记住，选项是：install without signing<br />问题大概是：Nvidia&rsquo;s 32-bit compatibility libraries? 选择 No 继续。<br />Would you like to run the nvidia-xconfigutility to automatically update your x configuration so that the NVIDIA x driver will be used when you restart x? Any pre-existing x confile will be backed up.<br />选择 Yes 继续</p><p>这些选项如果选择错误可能会导致安装失败，没关系，只要前面不出错，多尝试几次就好。</p><h2>挂载Nvidia驱动：</h2><p>modprobe nvidia<br />检查驱动是否安装成功：<br />nvidia-smi<br />如果出现如下提示，则说明安装成功：</p><p>&nbsp;<img src="/2023/image/1218402-20200924172602923-451169979.jpg" alt="" loading="lazy" /></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
      <tag>nvidia显卡驱动安装</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python批量读取并显示图片，处理异常</title>
    <link href="/2020/python%E6%89%B9%E9%87%8F%E8%AF%BB%E5%8F%96%E5%B9%B6%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%EF%BC%8C%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%E3%80%82/"/>
    <url>/2020/python%E6%89%B9%E9%87%8F%E8%AF%BB%E5%8F%96%E5%B9%B6%E6%98%BE%E7%A4%BA%E5%9B%BE%E7%89%87%EF%BC%8C%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8%E3%80%82/</url>
    
    <content type="html"><![CDATA[<p>今天写了一个批量读取并显示图片的代码，当做练习，方便以后拿来使用。</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> imageio</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> os</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> matplotlib.pyplot as pltfilepath </span>=<span style="color: #800000;">"</span><span style="color: #800000;">F:/相册/自己/</span><span style="color: #800000;">"</span><span style="color: #000000;">filename </span>=<span style="color: #000000;"> os.listdir(filepath)</span><span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> filename:    image </span>= i.strip().split(<span style="color: #800000;">"</span><span style="color: #800000;">.</span><span style="color: #800000;">"</span><span style="color: #000000;">)  #这条语句完全是为了练习split方法。    </span><span style="color: #0000ff;">try</span><span style="color: #000000;">:        img </span>= image[0]+<span style="color: #800000;">"</span><span style="color: #800000;">.jpg</span><span style="color: #800000;">"</span><span style="color: #000000;">        imag </span>=<span style="color: #000000;"> os.path.join(filepath,img)        im </span>=<span style="color: #000000;"> imageio.imread(imag)    </span><span style="color: #0000ff;">except</span><span style="color: #000000;"> FileNotFoundError:        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">出现一个文件读错误</span><span style="color: #800000;">"</span><span style="color: #000000;">)        img </span>= image[0]+<span style="color: #800000;">"</span><span style="color: #800000;">.PNG</span><span style="color: #800000;">"</span><span style="color: #000000;">        imag </span>=<span style="color: #000000;"> os.path.join(filepath,img)        im </span>=<span style="color: #000000;"> imageio.imread(imag)    </span><span style="color: #0000ff;">else</span><span style="color: #000000;">:        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">没有异常</span><span style="color: #800000;">"</span><span style="color: #000000;">)    plt.imshow(im)    plt.show()</span></pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>批量读取图片并显示</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>将nii文件CT图像更改窗宽窗位之后保存成nii文件</title>
    <link href="/2020/%E5%B0%86nii%E6%96%87%E4%BB%B6CT%E5%9B%BE%E5%83%8F%E6%9B%B4%E6%94%B9%E7%AA%97%E5%AE%BD%E7%AA%97%E4%BD%8D%E4%B9%8B%E5%90%8E%E4%BF%9D%E5%AD%98%E6%88%90nii%E6%96%87%E4%BB%B6/"/>
    <url>/2020/%E5%B0%86nii%E6%96%87%E4%BB%B6CT%E5%9B%BE%E5%83%8F%E6%9B%B4%E6%94%B9%E7%AA%97%E5%AE%BD%E7%AA%97%E4%BD%8D%E4%B9%8B%E5%90%8E%E4%BF%9D%E5%AD%98%E6%88%90nii%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<p>因为项目需要把CT图像中骨头更加明确的显示出来，且还需要保存nii文件，所以查了一些资料，在这里做一下笔记，方便以后使用。代码如下：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> nibabel as nib</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as np</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> SimpleITK as sitkcenter </span>= 350  <span style="color: #008000;">#</span><span style="color: #008000;"> 窗位</span>width = 1200  <span style="color: #008000;">#</span><span style="color: #008000;"> 窗宽</span><span style="color: #000000;">filename </span>= <span style="color: #800000;">'</span><span style="color: #800000;">E:/个人/骨折检测/分割项目/HDC-Net-master/mydata/RibFrac1-image.nii.gz</span><span style="color: #800000;">'</span><span style="color: #000000;">img </span>=<span style="color: #000000;"> nib.load(filename)img_fdata </span>=<span style="color: #000000;"> img.get_fdata()<p>min </span>&#x3D; (2 * center - width) &#x2F; 2.0 + 0.5<span style="color: #000000;"><br>max </span>&#x3D; (2 * center + width) &#x2F; 2.0 + 0.5<span style="color: #000000;"></p><p>dFactor </span>&#x3D; 255.0 &#x2F; (max -<span style="color: #000000;"> min)</p><p>img_fdata[img_fdata</span>&lt;min] &#x3D;<span style="color: #000000;"> min<br>img_fdata[img_fdata</span>&gt;max] &#x3D;<span style="color: #000000;"> max<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 进行转置，因为需要按照原来的方向进行保存</span><br>data &#x3D; np.transpose(img_fdata, [2, 1<span style="color: #000000;">, 0])<br>(z, y, x) </span>&#x3D;<span style="color: #000000;"> data.shape<br></span><span style="color: #0000ff;">print</span>(z,<span style="color: #800000;">“</span> <span style="color: #800000;">“</span>,y,<span style="color: #800000;">“</span> <span style="color: #800000;">“</span><span style="color: #000000;">,x)<br></span><span style="color: #0000ff;">for</span> i <span style="color: #0000ff;">in</span><span style="color: #000000;"> range(z):<br>    </span><span style="color: #0000ff;">for</span> j <span style="color: #0000ff;">in</span><span style="color: #000000;"> range(x):<br>        </span><span style="color: #0000ff;">for</span> k <span style="color: #0000ff;">in</span><span style="color: #000000;"> range(y):<br>            value </span>&#x3D;<span style="color: #000000;"> data[i,j,k]<br>            </span><span style="color: #0000ff;">if</span> value &lt;&#x3D;<span style="color: #000000;"> min:<br>                value </span>&#x3D;<span style="color: #000000;"> 0<br>            </span><span style="color: #0000ff;">elif</span> value &lt;<span style="color: #000000;"> max:<br>                value </span>&#x3D; (value - min) &#x2F; width * 255<br>            <span style="color: #0000ff;">elif</span> value &gt;&#x3D;<span style="color: #000000;"> max:<br>                value </span>&#x3D; 255<br>            <span style="color: #0000ff;">else</span><span style="color: #000000;">:<br>                data[i,j,k] </span>&#x3D;<span style="color: #000000;"> value<br></span><span style="color: #008000;">#</span><span style="color: #008000;">进行保存</span><br><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">—————–</span><span style="color: #800000;">“</span><span style="color: #000000;">)<br>filesname </span>&#x3D; <span style="color: #800000;">“</span><span style="color: #800000;">RibFrac1.nii.gz</span><span style="color: #800000;">“</span><span style="color: #000000;"><br>img </span>&#x3D;<span style="color: #000000;"> sitk.GetImageFromArray(data)<br>sitk.WriteImage(img, filesname)<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">+++++++++++++++++</span><span style="color: #800000;">“</span>)</pre></p></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>nii</tag>
      
      <tag>窗宽窗位</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>yaml.load与yaml.dump的用法</title>
    <link href="/2020/yaml.load%E4%B8%8Eyaml.dump%E7%9A%84%E7%94%A8%E6%B3%95/"/>
    <url>/2020/yaml.load%E4%B8%8Eyaml.dump%E7%9A%84%E7%94%A8%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> yaml<p></span><span style="color: #008000;">#</span><span style="color: #008000;">向yaml文件中写</span><br>with open(<span style="color: #800000;">“</span><span style="color: #800000;">E:\个人\ rename.yaml</span><span style="color: #800000;">“</span>, <span style="color: #800000;">‘</span><span style="color: #800000;">w</span><span style="color: #800000;">‘</span><span style="color: #000000;">) as f:<br>    project </span>&#x3D; {<span style="color: #800000;">‘</span><span style="color: #800000;">在远方</span><span style="color: #800000;">‘</span>:<span style="color: #800000;">“</span><span style="color: #800000;">1214</span><span style="color: #800000;">“</span>, <span style="color: #800000;">“</span><span style="color: #800000;">宁夏</span><span style="color: #800000;">“</span>:<span style="color: #800000;">“</span><span style="color: #800000;">银川</span><span style="color: #800000;">“</span>,<span style="color: #800000;">“</span><span style="color: #800000;">test</span><span style="color: #800000;">“</span>:<span style="color: #800000;">‘</span><span style="color: #800000;">txt</span><span style="color: #800000;">‘</span><span style="color: #000000;">}<br>    yaml.dump(project,f)<br></span><span style="color: #008000;">#</span><span style="color: #008000;">读取yaml文件中的内容</span><br>with open(<span style="color: #800000;">“</span><span style="color: #800000;">E:\个人\ rename.yaml</span><span style="color: #800000;">“</span><span style="color: #000000;">) as ff:<br>    temp </span>&#x3D; yaml.load(ff.read(),Loader&#x3D;<span style="color: #000000;">yaml.FullLoader)<br></span><span style="color: #0000ff;">for</span> key,values <span style="color: #0000ff;">in</span><span style="color: #000000;"> temp.items():<br>    </span><span style="color: #0000ff;">print</span>(key,<span style="color: #800000;">“</span> <span style="color: #800000;">“</span>,values)</pre></p></div><p>output：</p><div class="cnblogs_code"><pre><span style="color: #000000;">test   txt在远方   </span>1214<span style="color: #000000;">宁夏   银川</span></pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>yaml</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>【PyTorch】state_dict详解</title>
    <link href="/2020/%E3%80%90PyTorch%E3%80%91state_dict%E8%AF%A6%E8%A7%A3/"/>
    <url>/2020/%E3%80%90PyTorch%E3%80%91state_dict%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<h1><em>这篇博客来自<span style="font-size: 18pt;"><strong><a href="https://blog.csdn.net/bigFatCat_Tom/article/details/90722261" target="_blank">csdn</a></strong></span>，完全用于学习。</em></h1><h1><em>Introduce</em></h1><p>在pytorch中，torch.nn.Module模块中的state_dict变量存放训练过程中需要学习的权重和偏执系数，state_dict作为python的字典对象将每一层的参数映射成tensor张量，需要注意的是torch.nn.Module模块中的state_dict只包含卷积层和全连接层的参数，当网络中存在batchnorm时，例如vgg网络结构，torch.nn.Module模块中的state_dict也会存放batchnorm's running_mean，关于batchnorm详解可见<a href="https://blog.csdn.net/wzy_zju/article/details/81262453">https://blog.csdn.net/wzy_zju/article/details/81262453</a></p><p>torch.optim模块中的Optimizer优化器对象也存在一个state_dict对象，此处的state_dict字典对象包含state和param_groups的字典对象，而param_groups key对应的value也是一个由学习率，动量等参数组成的一个字典对象。</p><p>因为state_dict本质上Python字典对象，所以可以很好地进行保存、更新、修改和恢复操作（python字典结构的特性），从而为PyTorch模型和优化器增加了大量的模块化。</p><h1><a name="t1"></a><a name="t1"></a><em>Sample</em></h1><p>通过一个简单的案例来输出state_dict字典对象中存放的变量</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs pyhton">#encoding:utf-8<br> <br>import torch<br>import torch.nn as nn<br>import torch.optim as optim<br>import torchvision<br>import numpy as mp<br>import matplotlib.pyplot as plt<br>import torch.nn.functional as F<br> <br>#define model<br>class TheModelClass(nn.Module):<br>    def __init__(self):<br>        super(TheModelClass,self).__init__()<br>        self.conv1=nn.Conv2d(3,6,5)<br>        self.pool=nn.MaxPool2d(2,2)<br>        self.conv2=nn.Conv2d(6,16,5)<br>        self.fc1=nn.Linear(16*5*5,120)<br>        self.fc2=nn.Linear(120,84)<br>        self.fc3=nn.Linear(84,10)<br> <br>    def forward(self,x):<br>        x=self.pool(F.relu(self.conv1(x)))<br>        x=self.pool(F.relu(self.conv2(x)))<br>        x=x.view(-1,16*5*5)<br>        x=F.relu(self.fc1(x))<br>        x=F.relu(self.fc2(x))<br>        x=self.fc3(x)<br>        return x<br> <br>def main():<br>    # Initialize model<br>    model = TheModelClass()<br> <br>    #Initialize optimizer<br>    optimizer=optim.SGD(model.parameters(),lr=0.001,momentum=0.9)<br> <br>    #print model&#x27;s state_dict<br>    print(&#x27;Model.state_dict:&#x27;)<br>    for param_tensor in model.state_dict():<br>        #打印 key value字典<br>        print(param_tensor,&#x27;\t&#x27;,model.state_dict()[param_tensor].size())<br> <br>    #print optimizer&#x27;s state_dict<br>    print(&#x27;Optimizer,s state_dict:&#x27;)<br>    for var_name in optimizer.state_dict():<br>        print(var_name,&#x27;\t&#x27;,optimizer.state_dict()[var_name])<br> <br> <br> <br>if __name__==&#x27;__main__&#x27;:<br>    main()<br></code></pre></td></tr></table></figure><p>output：</p><div class="cnblogs_code"><pre><span style="color: #000000;">Model.state_dict:conv1.weight      torch.Size([</span>6, 3, 5, 5<span style="color: #000000;">])conv1.bias      torch.Size([</span>6<span style="color: #000000;">])conv2.weight      torch.Size([</span>16, 6, 5, 5<span style="color: #000000;">])conv2.bias      torch.Size([</span>16<span style="color: #000000;">])fc1.weight      torch.Size([</span>120, 400<span style="color: #000000;">])fc1.bias      torch.Size([</span>120<span style="color: #000000;">])fc2.weight      torch.Size([</span>84, 120<span style="color: #000000;">])fc2.bias      torch.Size([</span>84<span style="color: #000000;">])fc3.weight      torch.Size([</span>10, 84<span style="color: #000000;">])fc3.bias      torch.Size([</span>10<span style="color: #000000;">])Optimizer,s state_dict:state      {}param_groups      [{</span><span style="color: #800000;">'</span><span style="color: #800000;">lr</span><span style="color: #800000;">'</span>: 0.001, <span style="color: #800000;">'</span><span style="color: #800000;">momentum</span><span style="color: #800000;">'</span>: 0.9, <span style="color: #800000;">'</span><span style="color: #800000;">dampening</span><span style="color: #800000;">'</span>: 0, <span style="color: #800000;">'</span><span style="color: #800000;">weight_decay</span><span style="color: #800000;">'</span>: 0, <span style="color: #800000;">'</span><span style="color: #800000;">nesterov</span><span style="color: #800000;">'</span>: False, <span style="color: #800000;">'</span><span style="color: #800000;">params</span><span style="color: #800000;">'</span>: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]}]</pre></div><p>&nbsp;</p><div id="translate-man-app" class="content-3WfBL_0" style="background-color: #f4f5df; left: -895px; top: 27px;"><div class="outputBox-qe9A4_0" data-v-2868eb04=""><div class="outputBox-3oESn_0" data-v-2868eb04=""><span class="outputBox-13Ovx_0" data-v-2868eb04="">csdn</span></div><div class="outputBox-1GLb__0" data-v-2868eb04=""><div class="icon-tprjJ_0 outputBox-onVZH_0" data-v-2868eb04=""><img src="chrome-extension://fapgabkkfcaejckbfmfcdgnfefbmlion/static/sound.svg" class="icon-tprjJ_0" /></div></div><div class="outputBox-2sJgr_0" data-v-2868eb04=""><div class="outputBox-GomOI_0" data-v-2868eb04=""><span class="outputBox-2liU7_0" data-v-2868eb04="">CSDN</span></div></div><div class="outputBox-17RAm_0" style="display: none;" data-v-2868eb04="">&nbsp;</div></div></div><div id="translate-man-app" class="content-3WfBL_0" style="background-color: #f4f5df; left: -724px; top: 934px;"><div class="outputBox-qe9A4_0" data-v-2868eb04=""><div class="outputBox-3oESn_0" data-v-2868eb04=""><span class="outputBox-13Ovx_0" data-v-2868eb04="">csdn</span></div><div class="outputBox-1GLb__0" data-v-2868eb04=""><div class="icon-tprjJ_0 outputBox-onVZH_0" data-v-2868eb04=""><img src="chrome-extension://fapgabkkfcaejckbfmfcdgnfefbmlion/static/sound.svg" class="icon-tprjJ_0" /></div></div><div class="outputBox-2sJgr_0" data-v-2868eb04=""><div class="outputBox-GomOI_0" data-v-2868eb04=""><span class="outputBox-2liU7_0" data-v-2868eb04="">CSDN</span></div></div><div class="outputBox-17RAm_0" style="display: none;" data-v-2868eb04="">&nbsp;</div></div></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pytorch</tag>
      
      <tag>state_dict</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>np.ascontiguousarray()详解</title>
    <link href="/2020/np.ascontiguousarray()%E8%AF%A6%E8%A7%A3/"/>
    <url>/2020/np.ascontiguousarray()%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>从知乎上借鉴而来，用于学习：<a href="https://zhuanlan.zhihu.com/p/59767914" target="_blank">链接</a></p><p>1、<code>ascontiguousarray</code>函数将一个内存不连续存储的数组转换为内存连续存储的数组，使得运行速度更快。</p><p>比如我们生成一个二维数组，Numpy可以通过<code>.flags</code>熟悉查看一个数组是C连续还是Fortran连续的</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as nparr </span>= np.arange(12).reshape(3,4<span style="color: #000000;">)flags </span>=<span style="color: #000000;"> arr.flags</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">""</span><span style="color: #000000;">,arr)</span><span style="color: #0000ff;">print</span>(flags)</pre></div><p>output:</p><div class="cnblogs_code"><pre> [[ 0  1  2  3<span style="color: #000000;">] [ </span>4  5  6  7<span style="color: #000000;">] [ </span>8  9 10 11<span style="color: #000000;">]]  C_CONTIGUOUS : True  F_CONTIGUOUS : False  OWNDATA : False  WRITEABLE : True  ALIGNED : True  WRITEBACKIFCOPY : False  UPDATEIFCOPY : False</span></pre></div><p>我们可以看到 <strong>C_CONTIGUOUS : True</strong>，就说明是行连续，<strong>F_CONTIGUOUS : False</strong>则代表列不连续。同理如果我们进行<strong>arr.T&nbsp; </strong>或者<strong>arr.transpose(1,0)</strong>则是列连续，行不连续。</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as nparr </span>= np.arange(12).reshape(3,4<span style="color: #000000;">)arr1 </span>= arr.transpose(1<span style="color: #000000;">,0)flags </span>=<span style="color: #000000;"> arr1.flags</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">""</span><span style="color: #000000;">,arr1)</span><span style="color: #0000ff;">print</span>(flags)</pre></div><p>output:</p><div class="cnblogs_code"><pre> [[ 0  4  8<span style="color: #000000;">] [ </span>1  5  9<span style="color: #000000;">] [ </span>2  6 10<span style="color: #000000;">] [ </span>3  7 11<span style="color: #000000;">]]  C_CONTIGUOUS : False  F_CONTIGUOUS : True  OWNDATA : False  WRITEABLE : True  ALIGNED : True  WRITEBACKIFCOPY : False  UPDATEIFCOPY : False</span></pre></div><p>如果进行在<strong>行</strong>上的<code>slice即进行切割</code>，则会改变连续性，成为既不C连续，也不Fortran连续的：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as nparr </span>= np.arange(12).reshape(3,4<span style="color: #000000;">)arr1 </span>= arr[:,0:2<span style="color: #000000;">]flags </span>=<span style="color: #000000;"> arr1.flags</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">""</span><span style="color: #000000;">,arr1)</span><span style="color: #0000ff;">print</span>(flags)</pre></div><p>output:</p><div class="cnblogs_code"><pre> [[0 1<span style="color: #000000;">] [</span>4 5<span style="color: #000000;">] [</span>8 9<span style="color: #000000;">]]  C_CONTIGUOUS : False  F_CONTIGUOUS : False  OWNDATA : False  WRITEABLE : True  ALIGNED : True  WRITEBACKIFCOPY : False  UPDATEIFCOPY : False</span></pre></div><p>此时利用<strong><code>ascontiguousarray</code></strong>函数，可以将其变为连续的：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as nparr </span>= np.arange(12).reshape(3,4<span style="color: #000000;">)arr1 </span>= arr[:,0:2<span style="color: #000000;">]arr2 </span>=<span style="color: #000000;"> np.ascontiguousarray(arr1)flags </span>=<span style="color: #000000;"> arr2.flags</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">""</span><span style="color: #000000;">,arr2)</span><span style="color: #0000ff;">print</span>(flags)</pre></div><p>output:</p><div class="cnblogs_code"><pre>[[0 1<span style="color: #000000;">] [</span>4 5<span style="color: #000000;">] [</span>8 9<span style="color: #000000;">]]  C_CONTIGUOUS : True  F_CONTIGUOUS : False  OWNDATA : True  WRITEABLE : True  ALIGNED : True  WRITEBACKIFCOPY : False  UPDATEIFCOPY : False</span></pre></div><div id="translate-man-app" class="content-3WfBL_0" style="background-color: #f4f5df; left: -943px; top: 328px;"><div class="outputBox-qe9A4_0" data-v-2868eb04=""><div class="outputBox-3oESn_0" data-v-2868eb04=""><span class="outputBox-13Ovx_0" data-v-2868eb04="">C_CONTIGUOUS : True</span></div><div class="outputBox-1GLb__0" data-v-2868eb04=""><div class="icon-tprjJ_0 outputBox-onVZH_0" data-v-2868eb04=""><img src="chrome-extension://fapgabkkfcaejckbfmfcdgnfefbmlion/static/sound.svg" class="icon-tprjJ_0" /></div></div><div class="outputBox-2sJgr_0" data-v-2868eb04=""><div class="outputBox-GomOI_0" data-v-2868eb04=""><span class="outputBox-2liU7_0" data-v-2868eb04="">C_CONTIGUOUS：真</span></div></div><div class="outputBox-17RAm_0" style="display: none;" data-v-2868eb04="">&nbsp;</div></div></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>numpy库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>os.path.basename()和os.path.splitext()</title>
    <link href="/2020/os.path.basename()%E5%92%8Cos.path.splitext()/"/>
    <url>/2020/os.path.basename()%E5%92%8Cos.path.splitext()/</url>
    
    <content type="html"><![CDATA[<p>1、os.path.splitext()是用来分离文件名与扩展名；</p><p>2、os.path.basename()他返回的是一个base name，我认为就是路径最后一个文件名。</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> osfname </span>= <span style="color: #800000;">"</span><span style="color: #800000;">D:\\Python\\fig\\data.txt</span><span style="color: #800000;">"</span><span style="color: #000000;">files </span>= <span style="color: #800000;">"</span><span style="color: #800000;">D:/file/cat/dog.jpg</span><span style="color: #800000;">"</span><span style="color: #000000;">basename </span>=<span style="color: #000000;"> os.path.basename(fname)splittesxt </span>=<span style="color: #000000;"> os.path.splitext(fname)cfg </span>=<span style="color: #000000;"> os.path.splitext(os.path.basename(fname))[0]<p>basename1 </span>&#x3D;<span style="color: #000000;"> os.path.basename(files)<br>splittesxt1 </span>&#x3D;<span style="color: #000000;"> os.path.splitext(files)<br>cfg1 </span>&#x3D;<span style="color: #000000;"> os.path.splitext(os.path.basename(files))[0]<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">basename:</span><span style="color: #800000;">“</span><span style="color: #000000;">,basename)<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">splittext:</span><span style="color: #800000;">“</span><span style="color: #000000;">,splittesxt)<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">cfg:</span><span style="color: #800000;">“</span><span style="color: #000000;">,cfg)</p><p></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">basename1:</span><span style="color: #800000;">“</span><span style="color: #000000;">,basename1)<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">splittext1:</span><span style="color: #800000;">“</span><span style="color: #000000;">,splittesxt1)<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">cfg1:</span><span style="color: #800000;">“</span>,cfg1)</pre></p></div><p>output：</p><div class="cnblogs_code"><pre><span style="color: #000000;">basename: D:\Python\fig\data.txtsplittext: (</span><span style="color: #800000;">'</span><span style="color: #800000;">D:\\Python\\fig\\data</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">.txt</span><span style="color: #800000;">'</span><span style="color: #000000;">)cfg: D:\Python\fig\databasename1: dog.jpgsplittext1: (</span><span style="color: #800000;">'</span><span style="color: #800000;">D:/file/cat/dog</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">.jpg</span><span style="color: #800000;">'</span><span style="color: #000000;">)cfg1: dog</span></pre></div><p>从上面代码看出，貌似只有路径名写成：</p><pre>files = "D:/file/cat/dog.jpg"</pre><p>os.path.basename()才会和我们想象的结果一样。也可能是我的python版本是：Python 3.6.9的原因。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>os库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>np.mean()和np.std()函数</title>
    <link href="/2020/np.mean()%E5%92%8Cnp.std()%E5%87%BD%E6%95%B0/"/>
    <url>/2020/np.mean()%E5%92%8Cnp.std()%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p>一、mean() 函数定义：<br />numpy.mean(a, axis, dtype, out，keepdims )</p><p>mean()函数功能：求取均值<br />经常操作的参数为axis，以m * n矩阵举例：</p><ul><li>axis 不设置值，对 m*n 个数求均值，返回一个实数</li><li>axis = 0：压缩行，对各列求均值，返回 1* n 矩阵</li><li>axis =1 ：压缩列，对各行求均值，返回 m *1 矩</li></ul><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as npa </span>= np.array([[1, 2], [3, 4<span style="color: #000000;">]])</span><span style="color: #0000ff;">print</span><span style="color: #000000;">(a)</span><span style="color: #0000ff;">print</span><span style="color: #000000;">(type(a))</span><span style="color: #0000ff;">print</span><span style="color: #000000;">(np.mean(a))</span><span style="color: #0000ff;">print</span>(np.mean(a, axis=0)) <span style="color: #008000;">#</span><span style="color: #008000;"> axis=0，计算每一列的均值</span><span style="color: #0000ff;">print</span>(np.mean(a, axis=1)) <span style="color: #008000;">#</span><span style="color: #008000;"> axis = 1计算每一行的均值</span></pre></div><p>output:</p><div class="cnblogs_code"><pre>[[1 2<span style="color: #000000;">] [</span>3 4<span style="color: #000000;">]]</span>&lt;<span style="color: #0000ff;">class</span> <span style="color: #800000;">'</span><span style="color: #800000;">numpy.ndarray</span><span style="color: #800000;">'</span>&gt;2.5<span style="color: #000000;">[</span>2. 3<span style="color: #000000;">.][</span>1.5 3.5]</pre></div><p>二、<code class="sig-prename descclassname">numpy.</code><code class="sig-name descname">std</code><span class="sig-paren">(<em class="sig-param">a</em>,&nbsp;<em class="sig-param">axis=None</em>,&nbsp;<em class="sig-param">dtype=None</em>,&nbsp;<em class="sig-param">out=None</em>,&nbsp;<em class="sig-param">ddof=0</em>,&nbsp;<em class="sig-param">keepdims=&lt;no value&gt;</em><span class="sig-paren">)</span></span></p><p>这个函数是用来求标准差的。axis=0时，表示求每一列标准差，axis=1时，表示求每一行标准差，当axis=None时，表示求全局标准差。</p><p>其次numpy计算的为总体标准偏差，即当ddof=0时，计算有偏样本标准差；一般在拥有所有数据的情况下，计算所有数据的标准差时使用，即最终除以n。</p><p>当ddo = 1时，表示计算无偏样本标准差，最终除以n-1</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as npa </span>= np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9<span style="color: #000000;">])pian </span>= np.std(a, ddof = 0) <span style="color: #008000;">#</span><span style="color: #008000;"> 有偏</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">std有偏计算结果：</span><span style="color: #800000;">"</span><span style="color: #000000;">,pian)orig </span>= np.sqrt(((a - np.mean(a)) ** 2).sum() /<span style="color: #000000;"> a.size)</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">有偏公式计算结果：</span><span style="color: #800000;">"</span><span style="color: #000000;">,orig)no_pian </span>= np.std(a, ddof = 1) <span style="color: #008000;">#</span><span style="color: #008000;"> 无偏</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">std无偏计算结果：</span><span style="color: #800000;">"</span><span style="color: #000000;">,no_pian)orig1 </span>= np.sqrt(((a - np.mean(a)) ** 2).sum() / (a.size - 1<span style="color: #000000;">))</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">无偏公式计算结果：</span><span style="color: #800000;">"</span>,orig1)</pre></div><p>output：</p><div class="cnblogs_code"><pre>std有偏计算结果： 2.8722813232690143<span style="color: #000000;">有偏公式计算结果： </span>2.8722813232690143<span style="color: #000000;">std无偏计算结果： </span>3.0276503540974917<span style="color: #000000;">无偏公式计算结果： </span>3.0276503540974917</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>numpy库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Canny算子</title>
    <link href="/2020/Canny%E7%AE%97%E5%AD%90/"/>
    <url>/2020/Canny%E7%AE%97%E5%AD%90/</url>
    
    <content type="html"><![CDATA[<p>这篇文章是从<span style="font-size: 16px;"><a href="https://zh.wikipedia.org/wiki/Canny%E7%AE%97%E5%AD%90" target="_blank">wiki</a></span>中摘抄下来，需要阅读英文的，可以去看看。</p><p><strong>Canny边缘检测算子</strong>是澳洲计算机科学家<a class="new" title="约翰&middot;坎尼（页面不存在）" href="https://zh.wikipedia.org/w/index.php?title=%E7%B4%84%E7%BF%B0%C2%B7%E5%9D%8E%E5%B0%BC&amp;action=edit&amp;redlink=1">约翰&middot;坎尼</a>（<span lang="en">John F. Canny）于1986年开发出来的一个多级<a title="边缘检测" href="https://zh.wikipedia.org/wiki/%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B">边缘检测</a><a title="" href="https://zh.wikipedia.org/wiki/%E7%AE%97%E6%B3%95">算法</a>。更为重要的是Canny创立了&ldquo;边缘检测计算理论&rdquo;（computational theory of edge detection）解释这项技术如何工作。</span></p><h2><span id="Canny算法的发展" class="mw-headline">Canny算法的发展</span></h2><p>Canny的目标是找到一个最优的边缘检测算法，最优边缘检测的含义是：</p><ul><li><em>好的检测</em>&nbsp;- 算法能够尽可能多地标识出图像中的实际边缘。</li><li><em>好的定位</em>&nbsp;- 标识出的边缘要与实际图像中的实际边缘尽可能接近。</li><li><em>最小响应</em>&nbsp;- 图像中的边缘只能标识一次，并且可能存在的图像噪声不应标识为边缘。</li></ul><p>为了满足这些要求Canny使用了<a title="变分法" href="https://zh.wikipedia.org/wiki/%E5%8F%98%E5%88%86%E6%B3%95">变分法</a>，这是一种寻找满足特定功能的<a title="函数" href="https://zh.wikipedia.org/wiki/%E5%87%BD%E6%95%B0">函数</a>的方法。最优检测使用四个<a title="指数函数" href="https://zh.wikipedia.org/wiki/%E6%8C%87%E6%95%B0%E5%87%BD%E6%95%B0">指数函数</a>项的和表示，但是它非常近似于<a title="高斯函数" href="https://zh.wikipedia.org/wiki/%E9%AB%98%E6%96%AF%E5%87%BD%E6%95%B0">高斯函数</a>的一阶<a title="导数" href="https://zh.wikipedia.org/wiki/%E5%AF%BC%E6%95%B0">导数</a>。</p><h2><span id="Canny算法的步骤" class="mw-headline">Canny算法的步骤</span></h2><h3><span id="降噪" class="mw-headline"><a class="mw-redirect" title="降噪" href="https://zh.wikipedia.org/wiki/%E9%99%8D%E5%99%AA">降噪</a><span class="mw-editsection"><span class="mw-editsection-bracket"><span class="mw-editsection-bracket"><br /></span></span></span></span></h3><p>　　任何边缘检测算法都不可能在未经处理的原始数据上很好地处理，所以第一步是对原始数据与高斯平滑模板作<a title="卷积" href="https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF">卷积</a>，得到的图像与原始图像相比有些轻微的模糊（<a class="new" title="Blurring（页面不存在）" href="https://zh.wikipedia.org/w/index.php?title=Blurring&amp;action=edit&amp;redlink=1">blurred</a>）。这样，单独的一个像素噪声在经过<a class="mw-redirect" title="高斯平滑" href="https://zh.wikipedia.org/wiki/%E9%AB%98%E6%96%AF%E5%B9%B3%E6%BB%91">高斯平滑</a>的图像上变得几乎没有影响。</p><h3><span id=".E5.AF.BB.E6.89.BE.E5.9B.BE.E5.83.8F.E4.B8.AD.E7.9A.84.E4.BA.AE.E5.BA.A6.E6.A2.AF.E5.BA.A6"><span id="寻找图像中的亮度梯度" class="mw-headline">寻找图像中的亮度梯度<span class="mw-editsection"><span class="mw-editsection-bracket"><span class="mw-editsection-bracket"><br /></span></span></span></span></span></h3><p>　　图像中的边缘可能会指向不同的方向，所以Canny算法使用4个mask检测水平、垂直以及对角线方向的边缘。原始图像与每个mask所作的卷积都存储起来。对于每个点我们都标识在这个点上的最大值以及生成的边缘的方向。这样我们就从原始图像生成了图像中每个点<a class="new" title="亮度梯度（页面不存在）" href="https://zh.wikipedia.org/w/index.php?title=%E4%BA%AE%E5%BA%A6%E6%A2%AF%E5%BA%A6&amp;action=edit&amp;redlink=1">亮度梯度</a>图以及<a class="new" title="亮度梯度（页面不存在）" href="https://zh.wikipedia.org/w/index.php?title=%E4%BA%AE%E5%BA%A6%E6%A2%AF%E5%BA%A6&amp;action=edit&amp;redlink=1">亮度梯度</a>的方向。</p><h3><span id=".E5.9C.A8.E5.9B.BE.E5.83.8F.E4.B8.AD.E8.B7.9F.E8.B8.AA.E8.BE.B9.E7.BC.98"><span id="在图像中跟踪边缘" class="mw-headline">在图像中跟踪边缘<span class="mw-editsection"><span class="mw-editsection-bracket"><span class="mw-editsection-bracket"><br /></span></span></span></span></span></h3><p>　　较高的亮度梯度比较有可能是边缘，但是没有一个确切的值来限定多大的亮度梯度是边缘多大又不是，所以Canny使用了<a class="mw-redirect" title="滞后" href="https://zh.wikipedia.org/wiki/%E6%BB%9E%E5%90%8E">滞后</a>阈值。</p><p>滞后阈值需要两个阈值&mdash;&mdash;高阈值与低阈值。假设图像中的重要边缘都是连续的曲线，这样我们就可以跟踪给定曲线中模糊的部分，并且避免将没有组成曲线的噪声像素当成边缘。所以我们从一个较大的阈值开始，这将标识出我们比较确信的真实边缘，使用前面导出的方向信息，我们从这些真正的边缘开始在图像中跟踪整个的边缘。在跟踪的时候，我们使用一个较小的阈值，这样就可以跟踪曲线的模糊部分直到我们回到起点。</p><p>一旦这个过程完成，我们就得到了一个二值图像，每点表示是否是一个边缘点。</p><p>一个获得亚像素精度边缘的改进实现是在梯度方向检测二阶方向导数的过零点</p><p><span class="mwe-math-element"><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/985195d6c106e9f77aa99d1ac9c169c1a2da28df" alt="L_{x}^{2}\,L_+2\,L_{x}\,L_{y}\,L_+L_{y}^{2}\,L_=0," class="mwe-math-fallback-image-inline" style="display: block; margin-left: auto; margin-right: auto;" /></span></p><p>它在梯度方向的三阶方向导数满足符号条件</p><p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/476e832af46d5ae268c12d323ae2bf3b64453815" alt="L_{x}^{3}\,L_+3\,L_{x}^{2}\,L_{y}\,L_+3\,L_{x}\,L_{y}^{2}\,L_+L_{y}^{3}\,L_&lt;0" class="mwe-math-fallback-image-inline" style="display: block; margin-left: auto; margin-right: auto;" /><span class="mwe-math-element"><img src="/2023/image/1218402-20200709104323307-1068986561.png" alt="" loading="lazy" /></span></p><p><strong><span class="mwe-math-element">&nbsp;</span><span style="font-size: 1.5em;">参数</span></strong></p><p>&nbsp;</p><p>Canny算法包含许多可以调整的参数，它们将影响到算法的计算时间与实效。</p><p>&nbsp;</p><ul><li><a class="new" title="高斯滤波器（页面不存在）" href="https://zh.wikipedia.org/w/index.php?title=%E9%AB%98%E6%96%AF%E6%BB%A4%E6%B3%A2%E5%99%A8&amp;action=edit&amp;redlink=1">高斯滤波器</a>的大小：第一步所用的平滑滤波器将会直接影响Canny算法的结果。较小的滤波器产生的模糊效果也较少，这样就可以检测较小、变化明显的细线。较大的滤波器产生的模糊效果也较多，将较大的一块图像区域涂成一个特定点的颜色值。这样带来的结果就是对于检测较大、平滑的边缘更加有用，例如彩虹的边缘。</li><li><a class="mw-redirect mw-disambig" title="阈值" href="https://zh.wikipedia.org/wiki/%E9%98%88%E5%80%BC">阈值</a>：使用两个阈值比使用一个阈值更加灵活，但是它还是有阈值存在的共性问题。设置的阈值过高，可能会漏掉重要信息；阈值过低，将会把枝节信息看得很重要。很难给出一个适用于所有图像的通用阈值。目前还没有一个经过验证的实现方法。</li></ul><p>&nbsp;</p><p>如果想要试验Canny算法中的参数，<a class="external free" href="https://web.archive.org/web/20090615224334/http://matlabserver.cs.rug.nl/" rel="nofollow">https://web.archive.org/web/20090615224334/http://matlabserver.cs.rug.nl/</a>&nbsp;的在线Canny程序会很有帮助。</p><p><strong><span id="评价" class="mw-headline" style="font-size: 18pt;">评价</span></strong></p><p><strong><span id="评价" class="mw-headline" style="font-size: 18pt;">　　</span></strong><span class="mw-headline">Canny算法适用于不同的场合。它的参数允许根据不同实现的特定要求进行调整以识别不同的边缘特性。对于<a class="mw-disambig" title="PC" href="https://zh.wikipedia.org/wiki/PC">PC</a>上的实时图像处理来说可能慢得无法使用，尤其是在使用大的高斯滤波器的情况下。但是，我们讨论计算能力的时候，也要考虑到随着处理器速度不断提升，有望在未来几年使得这不再成为一个问题。</span></p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>canny算子</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>医学影像中常见名词解释</title>
    <link href="/2020/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/"/>
    <url>/2020/%E5%8C%BB%E5%AD%A6%E5%BD%B1%E5%83%8F%E4%B8%AD%E5%B8%B8%E8%A7%81%E5%90%8D%E8%AF%8D%E8%A7%A3%E9%87%8A/</url>
    
    <content type="html"><![CDATA[<p><span style="font-size: 18px;"><strong>后续会慢慢补充</strong></span><br /><strong>1、Faster R-CNN</strong>：他会花费更多的时间在检测方面，但是在小的项目中可以得到更为精确的结果。<br /><strong>2、False Positive</strong>&rdquo;通常指假阳性，就是把一个健康人诊断为病人。<br /><strong>3、敏感度（sensitivity）</strong>：又称真阳性率，即患者被诊断为阳性的概率，计算公式是：真阳性／（真阳性＋假阴性）&times;100％，此值越大，说明诊断试验越灵敏。<br /><strong>4、特异度（specificity）</strong>：又称真阴性率，即实际上未患病的人被诊断为阴性的概率，计算公式是：真阴性／（真阴性＋假阳性）&times;100％，此值越大，说明诊断试验越精确。<br /><strong>5、Skull-RCNN:</strong>是将头骨形态和深度卷积网络融合在一起进行精确的头骨骨折检测。<br /><strong>6、ROI Align</strong>很好地解决了ROI Pooling操作中两次量化造成的区域不匹配(mis-alignment)的问题。ROI Align的思路很简单：取消量化操作，使用双线性内插的方法获得坐标为浮点数的像素点上的图像数值,从而将整个特征聚集过程转化为一个连续的操作。<br /><strong>7、FPN（Feature Pyramid Networks）</strong>解决什么问题？<br />答：答： 在以往的faster rcnn进行目标检测时，无论是rpn还是fast rcnn，roi 都作用在最后一层，这在大目标的检测没有问题，但是对于小目标的检测就有些问题。因为对于小目标来说，当进行卷积池化到最后一层，实际上语义信息已经没有了，因为我们都知道对于一个roi映射到某个feature map的方法就是将底层坐标直接除以stride,显然越后，映射过去后就越小，甚至可能就没有了。 所以为了解决多尺度检测的问题，引入了特征金字塔网络。<br /><strong>8、特征金字塔/<strong>是多尺度目标检测系统中的一个基本组成部分</p><p><strong>9、SURF (Speeded Up Robust Features, 加速稳健特征)</strong> 是一个稳健的图像识别和描述算法，首先于2006年发表在ECCV大会上。这个算法可被用于计算机视觉任务，如物件识别和3D重构。<br /><strong>10、SURF</strong>使用海森矩阵的行列式值作特征点侦测并用积分图加速运算；SURF 的描述子基于 2D 离散小波变换 响应并且有效地利用了积分图。</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>医学图像</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sigmod、tanh、ReLU激活函数的实现</title>
    <link href="/2020/sigmod%E3%80%81tanh%E3%80%81ReLU%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <url>/2020/sigmod%E3%80%81tanh%E3%80%81ReLU%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9A%84%E5%AE%9E%E7%8E%B0/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch.nn.functional as F</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> matplotlib.pyplot as plt</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as npx </span>= torch.linspace(-10,10,60<span style="color: #000000;">)fig </span>= plt.figure(figsize=(14,4<span style="color: #000000;">))ae </span>= fig.add_subplot(131)  <span style="color: #008000;">#</span><span style="color: #008000;">sigmod激活函数</span>ax =<span style="color: #000000;"> plt.gca()ax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">top</span><span style="color: #800000;">'</span>].set_color(<span style="color: #800000;">'</span><span style="color: #800000;">none</span><span style="color: #800000;">'</span><span style="color: #000000;">)ax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">right</span><span style="color: #800000;">'</span>].set_color(<span style="color: #800000;">'</span><span style="color: #800000;">none</span><span style="color: #800000;">'</span><span style="color: #000000;">)ax.xaxis.set_ticks_position(</span><span style="color: #800000;">'</span><span style="color: #800000;">bottom</span><span style="color: #800000;">'</span><span style="color: #000000;">)ax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">bottom</span><span style="color: #800000;">'</span>].set_position((<span style="color: #800000;">'</span><span style="color: #800000;">data</span><span style="color: #800000;">'</span><span style="color: #000000;">,0))ax.yaxis.set_ticks_position(</span><span style="color: #800000;">'</span><span style="color: #800000;">left</span><span style="color: #800000;">'</span><span style="color: #000000;">)ax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">left</span><span style="color: #800000;">'</span>].set_position((<span style="color: #800000;">'</span><span style="color: #800000;">data</span><span style="color: #800000;">'</span><span style="color: #000000;">,0))y </span>=<span style="color: #000000;"> torch.sigmoid(x)plt.plot(x.numpy(),y.numpy())plt.ylim((0,</span>1<span style="color: #000000;">))<p>ae </span>&#x3D; fig.add_subplot(132)  <span style="color: #008000;">#</span><span style="color: #008000;">tanh激活函数</span><br>ax &#x3D;<span style="color: #000000;"> plt.gca()<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">top</span><span style="color: #800000;">‘</span>].set_color(<span style="color: #800000;">‘</span><span style="color: #800000;">none</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">right</span><span style="color: #800000;">‘</span>].set_color(<span style="color: #800000;">‘</span><span style="color: #800000;">none</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.xaxis.set_ticks_position(</span><span style="color: #800000;">‘</span><span style="color: #800000;">bottom</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">bottom</span><span style="color: #800000;">‘</span>].set_position((<span style="color: #800000;">‘</span><span style="color: #800000;">data</span><span style="color: #800000;">‘</span><span style="color: #000000;">,0))<br>ax.yaxis.set_ticks_position(</span><span style="color: #800000;">‘</span><span style="color: #800000;">left</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">left</span><span style="color: #800000;">‘</span>].set_position((<span style="color: #800000;">‘</span><span style="color: #800000;">data</span><span style="color: #800000;">‘</span><span style="color: #000000;">,0))<br>y1 </span>&#x3D;<span style="color: #000000;"> torch.tanh(x)<br>plt.plot(x.numpy(),y1.numpy())<br>plt.ylim((</span>-1,1<span style="color: #000000;">))</p><p>ae </span>&#x3D; fig.add_subplot(133)  <span style="color: #008000;">#</span><span style="color: #008000;"> ReLU激活函数</span><br>ax &#x3D;<span style="color: #000000;"> plt.gca()<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">top</span><span style="color: #800000;">‘</span>].set_color(<span style="color: #800000;">‘</span><span style="color: #800000;">none</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">right</span><span style="color: #800000;">‘</span>].set_color(<span style="color: #800000;">‘</span><span style="color: #800000;">none</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.xaxis.set_ticks_position(</span><span style="color: #800000;">‘</span><span style="color: #800000;">bottom</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">bottom</span><span style="color: #800000;">‘</span>].set_position((<span style="color: #800000;">‘</span><span style="color: #800000;">data</span><span style="color: #800000;">‘</span><span style="color: #000000;">,0))<br>ax.yaxis.set_ticks_position(</span><span style="color: #800000;">‘</span><span style="color: #800000;">left</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>ax.spines[</span><span style="color: #800000;">‘</span><span style="color: #800000;">left</span><span style="color: #800000;">‘</span>].set_position((<span style="color: #800000;">‘</span><span style="color: #800000;">data</span><span style="color: #800000;">‘</span><span style="color: #000000;">,0))<br>y2 </span>&#x3D;<span style="color: #000000;"> F.relu(x)<br>plt.plot(x.numpy(),y2.numpy())<br>plt.ylim((</span>-1,5<span style="color: #000000;">))</p><p>plt.show()</span></pre></p></div><p>输出：</p><p><img src="/2023/image/1218402-20200630100300669-122880299.png" alt="" loading="lazy" /></p><p><strong>sigmod公式：</strong></p><p><img src="/2023/image/1218402-20200630100512759-1159630929.png" alt="" loading="lazy" /></p><p>一般会造成梯度消失。</p><p><strong>tanh公式：</strong></p><p><strong><img src="/2023/image/1218402-20200630100711963-2025880595.png" alt="" loading="lazy" /></strong></p><p>&nbsp;</p><p>tanh是以0为中心点，如果使用tanh作为激活函数，能够起到归一化（均值为0）的效果。</p><p><strong>Relu（Rectified Linear Units）修正线性单元</strong></p><p><strong><img src="https://render.githubusercontent.com/render/math?math=a%3Dmax%280%2Cz%29&amp;mode=inline" alt="$a=max(0,z)$" class="math math-inline" />&nbsp;</strong>导数大于0时1，小于0时0。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>激活函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>plt.gca()坐标轴移动</title>
    <link href="/2020/plt.gca()%E5%9D%90%E6%A0%87%E8%BD%B4%E7%A7%BB%E5%8A%A8/"/>
    <url>/2020/plt.gca()%E5%9D%90%E6%A0%87%E8%BD%B4%E7%A7%BB%E5%8A%A8/</url>
    
    <content type="html"><![CDATA[<p><img src="/2023/image/1218402-20200630093259085-1995477786.png" alt="" loading="lazy" /></p><p>我们可以看到绘制出来的图有四个边框，我们通过gca()对坐标轴进行一些简单处理，代码如下。</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch.nn.functional as F</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> matplotlib.pyplot as plt</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as npx </span>= torch.linspace(-10,10,60<span style="color: #000000;">)y </span>=<span style="color: #000000;"> torch.sigmoid(x)ax </span>=<span style="color: #000000;"> plt.gca()ax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">top</span><span style="color: #800000;">'</span>].set_color(<span style="color: #800000;">'</span><span style="color: #800000;">none</span><span style="color: #800000;">'</span><span style="color: #000000;">) #将最上方的边框颜色置为noneax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">right</span><span style="color: #800000;">'</span>].set_color(<span style="color: #800000;">'</span><span style="color: #800000;">none</span><span style="color: #800000;">'</span><span style="color: #000000;">) #将右边的边框颜色置为noneax.xaxis.set_ticks_position(</span><span style="color: #800000;">'</span><span style="color: #800000;">bottom</span><span style="color: #800000;">'</span><span style="color: #000000;">) #要移动底部x轴，所以先要锁定x轴ax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">bottom</span><span style="color: #800000;">'</span>].set_position((<span style="color: #800000;">'</span><span style="color: #800000;">data</span><span style="color: #800000;">'</span><span style="color: #000000;">,0)) # 'data'表示按数值挪动，其后数字代表挪动到Y轴的刻度值ax.yaxis.set_ticks_position(</span><span style="color: #800000;">'</span><span style="color: #800000;">left</span><span style="color: #800000;">'</span><span style="color: #000000;">) #同上ax.spines[</span><span style="color: #800000;">'</span><span style="color: #800000;">left</span><span style="color: #800000;">'</span>].set_position((<span style="color: #800000;">'</span><span style="color: #800000;">data</span><span style="color: #800000;">'</span><span style="color: #000000;">,0)) #同上plt.plot(x.numpy(),y.numpy())plt.show()</span></pre></div><p><img src="/2023/image/1218402-20200630093450147-1786397410.png" alt="" loading="lazy" /></p><p>&nbsp;</p><pre><code class="language-python3" style="margin: 0px; padding: 0px; border-radius: 0px; font-family: Menlo, Monaco, Consolas, 'Andale Mono', 'lucida console', 'Courier New', monospace; font-size: inherit; background-color: inherit;"><span class="c1" style="font-style: italic; color: #999999;">#  要挪动底部的X轴，所以先目光锁定底部！</span></code></pre>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matplotlib.pyplot库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>损失函数和梯度下降解释</title>
    <link href="/2020/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E8%A7%A3%E9%87%8A/"/>
    <url>/2020/%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E8%A7%A3%E9%87%8A/</url>
    
    <content type="html"><![CDATA[<h2>本篇是摘抄<a href="https://github.com/zergtant/pytorch-handbook/blob/master/chapter2/2.2-deep-learning-basic-mathematics.ipynb" target="_blank" data-pjax="#js-repo-pjax-container">pytorch-handbook</a>里面的，有兴趣可以看看。</h2><h2>损失函数(Loss Function)</h2><p>损失函数（loss function）是用来估量模型的预测值(我们例子中的output)与真实值（例子中的y_train）的不一致程度，它是一个非负实值函数，损失函数越小，模型的鲁棒性就越好。 我们训练模型的过程，就是通过不断的迭代计算，使用梯度下降的优化算法，使得损失函数越来越小。损失函数越小就表示算法达到意义上的最优。</p><h3>nn.CrossEntropyLoss:</h3><p>多分类用的交叉熵损失函数，LogSoftMax和NLLLoss集成到一个类中，会调用nn.NLLLoss函数，我们可以理解为CrossEntropyLoss()=log_softmax() + NLLLoss()</p><p><img src="https://render.githubusercontent.com/render/math?math=%5Cbegin%7Baligned%7D%20loss%28x%2C%20class%29%20%26amp%3B%3D%20-%5Ctext%7Blog%7D%5Cfrac%7Bexp%28x%5Bclass%5D%29%7D%7B%5Csum_j%20exp%28x%5Bj%5D%29%29%7D%5C%20%26amp%3B%3D%20-x%5Bclass%5D%20%2B%20log%28%5Csum_j%20exp%28x%5Bj%5D%29%29%20%5Cend%7Baligned%7D&amp;mode=inline" alt="$ \begin{aligned} loss(x, class) &amp;amp;= -\text{log}\frac{exp(x[class])}{\sum_j exp(x[j]))}\ &amp;amp;= -x[class] + log(\sum_j exp(x[j])) \end{aligned}  $" class="math math-inline" /></p><p>因为使用了NLLLoss，所以也可以传入weight参数，这时loss的计算公式变为：</p><p><img src="https://render.githubusercontent.com/render/math?math=loss%28x%2C%20class%29%20%3D%20weights%5Bclass%5D%20%2A%20%28-x%5Bclass%5D%20%2B%20log%28%5Csum_j%20exp%28x%5Bj%5D%29%29%29&amp;mode=inline" alt="$ loss(x, class) = weights[class] * (-x[class] + log(\sum_j exp(x[j]))) $" class="math math-inline" /></p><p>所以一般多分类的情况会使用这个损失函数</p><h2>梯度下降</h2><p>在介绍损失函数的时候我们已经说了，梯度下降是一个使损失函数越来越小的优化算法，在无求解机器学习算法的模型参数，即约束优化问题时，梯度下降（Gradient Descent）是最常采用的方法之一。所以梯度下降是我们目前所说的机器学习的核心，了解了它的含义，也就了解了机器学习算法的含义。</p><h3>梯度<a class="anchor-link" href="https://render.githubusercontent.com/view/ipynb?commit=e6208865da50b2945ef8d759b1bc9ed1dfa88aa6&amp;enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f7a65726774616e742f7079746f7263682d68616e64626f6f6b2f653632303838363564613530623239343565663864373539623162633965643164666138386161362f63686170746572322f322e322d646565702d6c6561726e696e672d62617369632d6d617468656d61746963732e6970796e62&amp;nwo=zergtant%2Fpytorch-handbook&amp;path=chapter2%2F2.2-deep-learning-basic-mathematics.ipynb&amp;repository_id=160124067&amp;repository_type=Repository#%E6%A2%AF%E5%BA%A6">&para;</a></h3><p>在微积分里面，对多元函数的参数求&part;偏导数，把求得的各个参数的偏导数以向量的形式写出来，就是梯度。 例如函数f(x,y), 分别对x，y求偏导数，求得的梯度向量就是(&part;f/&part;x, &part;f/&part;y)T，简称grad f(x,y)或者▽f(x,y)。</p><p>几何上讲，梯度就是函数变化增加最快的地方，沿着梯度向量的方向，更加容易找到函数的最大值。反过来说，沿着梯度向量相反的方向梯度减少最快，也就是更加容易找到函数的最小值。</p><p>我们需要最小化损失函数，可以通过梯度下降法来一步步的迭代求解，得到最小化的损失函数，和模型参数值。</p><h3>torch.optim.SGD</h3><p>随机梯度下降算法，带有动量（momentum）的算法作为一个可选参数可以进行设置，样例如下：</p><div class="cnblogs_code"><pre><span style="color: #008000;">#</span><span style="color: #008000;">lr参数为学习率，对于SGD来说一般选择0.1 0.01.0.001，如何设置会在后面实战的章节中详细说明</span><span style="color: #008000;">#</span><span style="color: #008000;">#如果设置了momentum，就是带有动量的SGD，可以不设置</span>optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)</pre></div><h3>torch.optim.RMSprop</h3><p>除了以上的带有动量Momentum梯度下降法外，RMSprop（root mean square prop）也是一种可以加快梯度下降的算法，利用RMSprop算法，可以减小某些维度梯度更新波动较大的情况，使其梯度下降的速度变得更快</p><div class="cnblogs_code"><pre><span style="color: #008000;">#</span><span style="color: #008000;">我们的课程基本不会使用到RMSprop所以这里只给一个实例</span>optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01, alpha=0.99)</pre></div><p>&nbsp;</p><h3>torch.optim.Adam</h3><p>Adam 优化算法的基本思想就是将 Momentum 和 RMSprop 结合起来形成的一种适用于不同深度学习结构的优化算法</p><div class="cnblogs_code"><pre><span style="color: #008000;">#</span><span style="color: #008000;"> 这里的lr，betas，还有eps都是用默认值即可，所以Adam是一个使用起来最简单的优化方法</span>optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)</pre></div><p>&nbsp;</p><h2>方差/偏差</h2><ul><li>偏差度量了学习算法的期望预测与真实结果的偏离程序，即刻画了学习算法本身的拟合能力</li><li>方差度量了同样大小的训练集的变动所导致的学习性能的变化，即模型的泛化能力</li></ul>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>损失函数</tag>
      
      <tag>梯度下降</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torch和numpy的相互转换</title>
    <link href="/2020/torch%E5%92%8Cnumpy%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2/"/>
    <url>/2020/torch%E5%92%8Cnumpy%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torchx </span>= torch.rand(2,2<span style="color: #000000;">)x1 </span>= x.numpy() <span style="color: #008000;">#</span><span style="color: #008000;"> torch转换到numpy</span>x2 = torch.from_numpy(x1) <span style="color: #008000;">#</span><span style="color: #008000;">numpy转换torch</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">\n torch_x:\n</span><span style="color: #800000;">"</span><span style="color: #000000;">,x,   </span><span style="color: #800000;">"</span><span style="color: #800000;">\n numpy_x1:\n</span><span style="color: #800000;">"</span><span style="color: #000000;">,x1,   </span><span style="color: #800000;">"</span><span style="color: #800000;">\n torch_x2:\n</span><span style="color: #800000;">"</span>,x2)</pre></div><p>out:</p><div class="cnblogs_code"><pre><span style="color: #000000;"> torch_x: tensor([[</span>0.8195, 0.8927<span style="color: #000000;">],        [</span>0.7544, 0.8827<span style="color: #000000;">]])  numpy_x1: [[</span>0.8194596 0.8926985<span style="color: #000000;">] [</span>0.754393  0.882745<span style="color: #000000;"> ]]  torch_x2: tensor([[</span>0.8195, 0.8927<span style="color: #000000;">],        [</span>0.7544, 0.8827]])</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>torch2numpy</tag>
      
      <tag>numpy2torch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>lmplot绘制回归图</title>
    <link href="/2020/seaborn.lmplot%E8%AF%A6%E8%A7%A3/"/>
    <url>/2020/seaborn.lmplot%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p><a href="http://seaborn.pydata.org/generated/seaborn.lmplot.html" target="_blank">官方文档</a></p><p>首先我们要知道，lmplot是用来绘制回归图的。</p><p>让我们来看看他的API：</p><p><code class="sig-prename descclassname">seaborn.</code><code class="sig-name descname">lmplot</code><span class="sig-paren">(<em class="sig-param">x</em>,&nbsp;<em class="sig-param">y</em>,&nbsp;<em class="sig-param">data</em>,&nbsp;<em class="sig-param">hue=None</em>,&nbsp;<em class="sig-param">col=None</em>,&nbsp;<em class="sig-param">row=None</em>,&nbsp;<em class="sig-param">palette=None</em>,&nbsp;<em class="sig-param">col_wrap=None</em>,&nbsp;<em class="sig-param">height=5</em>,&nbsp;<em class="sig-param">aspect=1</em>,&nbsp;<em class="sig-param">markers='o'</em>,&nbsp;<em class="sig-param">sharex=True</em>,&nbsp;<em class="sig-param">sharey=True</em>,&nbsp;<em class="sig-param">hue_order=None</em>,&nbsp;<em class="sig-param">col_order=None</em>,&nbsp;<em class="sig-param">row_order=None</em>,&nbsp;<em class="sig-param">legend=True</em>,&nbsp;<em class="sig-param">legend_out=True</em>,&nbsp;<em class="sig-param">x_estimator=None</em>,&nbsp;<em class="sig-param">x_bins=None</em>,&nbsp;<em class="sig-param">x_ci='ci'</em>,&nbsp;<em class="sig-param">scatter=True</em>,&nbsp;<em class="sig-param">fit_reg=True</em>,&nbsp;<em class="sig-param">ci=95</em>,&nbsp;<em class="sig-param">n_boot=1000</em>,&nbsp;<em class="sig-param">units=None</em>,&nbsp;<em class="sig-param">seed=None</em>,&nbsp;<em class="sig-param">order=1</em>,&nbsp;<em class="sig-param">logistic=False</em>,&nbsp;<em class="sig-param">lowess=False</em>,&nbsp;<em class="sig-param">robust=False</em>,&nbsp;<em class="sig-param">logx=False</em>,&nbsp;<em class="sig-param">x_partial=None</em>,&nbsp;<em class="sig-param">y_partial=None</em>,&nbsp;<em class="sig-param">truncate=True</em>,&nbsp;<em class="sig-param">x_jitter=None</em>,&nbsp;<em class="sig-param">y_jitter=None</em>,&nbsp;<em class="sig-param">scatter_kws=None</em>,&nbsp;<em class="sig-param">line_kws=None</em>,&nbsp;<em class="sig-param">size=None</em><span class="sig-paren">)</span></span></p><p><span class="sig-paren"><span class="sig-paren">可以看出，参数是相当的多啊。</span></span></p><p><span class="sig-paren"><span class="sig-paren"><strong>x, y&nbsp;</strong><span class="classifier">strings, optional</span>:是data数据中，行的名字。</span></span></p><p><span class="sig-paren"><span class="sig-paren"><strong>data&nbsp;</strong><span class="classifier">DataFrame</span>：那就是你的数据了。</span></span></p><p><span class="sig-paren"><span class="sig-paren">我们用实例慢慢验证，<span style="font-size: 15px;">本次试用的数据集是Seaborn内置的tips小费数据集：</span></span></span></p><p><span class="sig-paren"><span class="sig-paren"><span style="font-size: 15px;">第一步，导入相应的包,并输出数据</span></span></span></p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> seaborn as snstips </span>= sns.load_dataset(<span style="color: #800000;">"</span><span style="color: #800000;">tips</span><span style="color: #800000;">"</span><span style="color: #000000;">)</span><span style="color: #0000ff;">print</span>(tips.head())</pre></div><p>输出结果：</p><div class="cnblogs_code"><pre><span style="color: #000000;">   total_bill   tip     sex smoker  day    time  size0       </span>16.99  1.01  Female     No  Sun  Dinner     21       10.34  1.66    Male     No  Sun  Dinner     32       21.01  3.50    Male     No  Sun  Dinner     33       23.68  3.31    Male     No  Sun  Dinner     24       24.59  3.61  Female     No  Sun  Dinner     4</pre></div><p><span class="sig-paren"><span class="sig-paren"><span style="font-size: 15px;">我们用一下lmplot，看看绘制出来的是什么样的图：</span></span></span></p><div class="cnblogs_code"><pre>df = sns.lmplot(x=<span style="color: #800000;">'</span><span style="color: #800000;">total_bill</span><span style="color: #800000;">'</span>,y=<span style="color: #800000;">'</span><span style="color: #800000;">tip</span><span style="color: #800000;">'</span>,data=tips)</pre></div><p>绘制结果：</p><p><img src="/2023/image/1218402-20200629111203975-165051449.png" alt="" loading="lazy" /></p><p>我们可以看到，lmplot对所选择的数据集做出了一条最佳的拟合直线。</p><p><strong>hue, col, row&nbsp;&nbsp;</strong><span class="classifier">strings：其实就是用于分类，我们可以看到，他把smoker所在列中，是否抽烟做了分类。</span></p><div class="cnblogs_code"><pre>df = sns.lmplot(x=<span style="color: #800000;">"</span><span style="color: #800000;">total_bill</span><span style="color: #800000;">"</span>, y=<span style="color: #800000;">"</span><span style="color: #800000;">tip</span><span style="color: #800000;">"</span>, hue=<span style="color: #800000;">"</span><span style="color: #800000;">smoker</span><span style="color: #800000;">"</span>, data=tips)</pre></div><p><img src="/2023/image/1218402-20200629111718935-412407513.png" alt="" loading="lazy" /></p><p><code><strong>order&nbsp;</strong><span class="classifier">int, optional</span>:</code>控制进行回归的幂次（一次以上即是多项式回归）</p><div class="cnblogs_code"><pre>df = sns.lmplot(x=<span style="color: #800000;">"</span><span style="color: #800000;">total_bill</span><span style="color: #800000;">"</span>, y=<span style="color: #800000;">"</span><span style="color: #800000;">tip</span><span style="color: #800000;">"</span>, hue=<span style="color: #800000;">"</span><span style="color: #800000;">smoker</span><span style="color: #800000;">"</span>, data=tips,order=3)</pre></div><p><img src="/2023/image/1218402-20200629112532359-1992033592.png" alt="" loading="lazy" /></p><p><code>col strings:</code>根据所指定属性在列上分类</p><p><code>row strings:</code>根据所指定属性在行上分类</p><div><div class="cnblogs_code"><pre>df = sns.lmplot(x=<span style="color: #800000;">"</span><span style="color: #800000;">total_bill</span><span style="color: #800000;">"</span>, y=<span style="color: #800000;">"</span><span style="color: #800000;">tip</span><span style="color: #800000;">"</span>,data=tips,col=<span style="color: #800000;">"</span><span style="color: #800000;">day</span><span style="color: #800000;">"</span>)</pre></div><p><img src="/2023/image/1218402-20200629113120548-619372313.png" alt="" loading="lazy" /></p><div class="cnblogs_code"><pre>df = sns.lmplot(x=<span style="color: #800000;">"</span><span style="color: #800000;">total_bill</span><span style="color: #800000;">"</span>, y=<span style="color: #800000;">"</span><span style="color: #800000;">tip</span><span style="color: #800000;">"</span>,data=tips,row=<span style="color: #800000;">"</span><span style="color: #800000;">sex</span><span style="color: #800000;">"</span>)</pre></div><p><img src="/2023/image/1218402-20200629113253456-612015125.png" alt="" loading="lazy" /></p><div class="cnblogs_code"><pre>df = sns.lmplot(x=<span style="color: #800000;">"</span><span style="color: #800000;">total_bill</span><span style="color: #800000;">"</span>, y=<span style="color: #800000;">"</span><span style="color: #800000;">tip</span><span style="color: #800000;">"</span>,data=tips,row=<span style="color: #800000;">"</span><span style="color: #800000;">sex</span><span style="color: #800000;">"</span>,col=<span style="color: #800000;">"</span><span style="color: #800000;">day</span><span style="color: #800000;">"</span>)</pre></div><p><img src="/2023/image/1218402-20200629113446228-771203202.png" alt="" loading="lazy" /></p><p>&nbsp;</p><p><strong>col_wrap&nbsp;</strong><span class="classifier">int, optional&nbsp;指定每行的列数，最多等于col参数所对应的不同类别的数量</span></p><div class="cnblogs_code"><pre>df = sns.lmplot(x=<span style="color: #800000;">"</span><span style="color: #800000;">total_bill</span><span style="color: #800000;">"</span>, y=<span style="color: #800000;">"</span><span style="color: #800000;">tip</span><span style="color: #800000;">"</span>,data=tips,col=<span style="color: #800000;">"</span><span style="color: #800000;">day</span><span style="color: #800000;">"</span>,col_wrap=3)</pre></div><p>&nbsp;</p><p><img src="/2023/image/1218402-20200629113908429-1618364906.png" alt="" loading="lazy" /></p><p>先暂时学习到这儿，之后慢慢补充。</p></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>回归图绘制</tag>
      
      <tag>Implot</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>PyTorch的Autograd</title>
    <link href="/2020/PyTorch%20%E7%9A%84%20Autograd/"/>
    <url>/2020/PyTorch%20%E7%9A%84%20Autograd/</url>
    
    <content type="html"><![CDATA[<p>看了一篇博客，感觉写的很棒：<a title="PyTorch 的 Autograd" href="https://blog.csdn.net/byron123456sfsfsfa/article/details/92210253" target="_blank">PyTorch 的 Autograd</a></p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Autograd</tag>
      
      <tag>pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torch.max()使用讲解</title>
    <link href="/2020/torch.max()%E4%BD%BF%E7%94%A8%E8%AE%B2%E8%A7%A3/"/>
    <url>/2020/torch.max()%E4%BD%BF%E7%94%A8%E8%AE%B2%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>output = torch.max(input, dim)</p><p>input输入的是一个tensor</p><p><code>dim</code>是max函数索引的维度<code>0/1</code>，<code>0</code>是每列的最大值，<code>1</code>是每行的最大值</p><p>实例：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as np</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> matplotlib.pyplot as plt<p>x </span>&#x3D; torch.randn(3,3<span style="color: #000000;">)<br></span><span style="color: #0000ff;">print</span><span style="color: #000000;">(x)<br>max_value,index </span>&#x3D; torch.max(x,dim&#x3D;1) <span style="color: #008000;">#</span><span style="color: #008000;">返回的是两个值，一个是每一行最大值的tensor组，另一个是最大值所在的位置</span><br><span style="color: #0000ff;">print</span><span style="color: #000000;">(max_value,index)<br>max_lie_value </span>&#x3D; torch.max(x,dim&#x3D;0)[0].numpy() <span style="color: #008000;">#</span><span style="color: #008000;">每一列最大值</span><br>max_hang_value &#x3D; torch.max(x,dim&#x3D;1)[0].numpy() <span style="color: #008000;">#</span><span style="color: #008000;">每一行最大值</span><br><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">max_lie_value:</span><span style="color: #800000;">‘</span>,max_lie_value,<span style="color: #800000;">‘</span><span style="color: #800000;">\nmax_hang_value</span><span style="color: #800000;">‘</span>,max_hang_value)</pre></p></div><p>输出：</p><div class="cnblogs_code"><pre>tensor([[ 1.0625, -0.7129,  0.0849<span style="color: #000000;">],        [ </span>0.9122, -0.5969,  1.2351<span style="color: #000000;">],        [</span>-0.2937,  0.0923, -0.4093<span style="color: #000000;">]])tensor([</span>1.0625, 1.2351, 0.0923]) tensor([0, 2, 1<span style="color: #000000;">])max_lie_value: [</span>1.0625167  0.09232075 1.2350996<span style="color: #000000;"> ] max_hang_value [</span>1.0625167  1.2350996  0.09232075]</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>torch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Pytorch常用的交叉熵损失函数CrossEntropyLoss()详解</title>
    <link href="/2020/Pytorch%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0CrossEntropyLoss()%E8%AF%A6%E8%A7%A3/"/>
    <url>/2020/Pytorch%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0CrossEntropyLoss()%E8%AF%A6%E8%A7%A3/</url>
    
    <content type="html"><![CDATA[<p>本篇借鉴了这篇文章，如果有兴趣，大家可以看看：<a href="https://blog.csdn.net/geter_CS/article/details/84857220">https://blog.csdn.net/geter_CS/article/details/84857220</a></p><p>1、<strong>交叉熵</strong>：交叉熵主要是用来判定实际的输出与期望的输出的接近程度</p><p>2、CrossEntropyLoss()损失函数结合了nn.LogSoftmax()和nn.NLLLoss()两个函数。它在做分类（具体几类）训练的时候是非常有用的。</p><p>3、<strong><a href="https://zh.m.wikipedia.org/zh-hans/Softmax%E5%87%BD%E6%95%B0" target="_blank">softmax</a>用于多分类过程中</strong>，它将多个神经元的输出，映射到（0,1）区间内，可以看成概率来理解，从而来进行多分类！</p><p>其公式如下：&nbsp;&nbsp;</p><p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;<img src="/2023/image/1218402-20220522104415895-177811607.png" alt="" /></p><p>numpy计算代码：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as npz </span>= np.array([1.0, 2.0, 3.0, 4.0, 1.0, 2.0, 3.0<span style="color: #000000;">])</span><span style="color: #0000ff;">print</span>(np.exp(z)/sum(np.exp(z)))</pre></div><p>&nbsp;4、<a href="https://zhuanlan.zhihu.com/p/159477597" target="_blank">LogSoftmax能够解决函数上溢和下溢的问题,加快运算速度,提高数据稳定性</a>。</p><p>其计算公式：</p><p><img src="/2023/image/1218402-20220522105409120-2030408559.png" alt="" /></p><p>M是max(x_i),这样可以解决上溢下溢的问题.(但这样输出概率和就不是1了)</p><p>代码：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torchx </span>= torch.Tensor([-4, 2, -3.2, 0, 7<span style="color: #000000;">])softmax </span>= torch.exp(x)/<span style="color: #000000;">torch.sum(torch.exp(x))</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">softmax\n</span><span style="color: #800000;">"</span><span style="color: #000000;">,softmax)</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">sum:</span><span style="color: #800000;">"</span><span style="color: #000000;">,torch.sum(softmax))LogSoftmax </span>=<span style="color: #000000;"> torch.log(softmax)</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">LogSoftmax\n</span><span style="color: #800000;">"</span><span style="color: #000000;">,LogSoftmax)</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">sum:</span><span style="color: #800000;">"</span>,torch.sum(LogSoftmax))</pre></div><p>结果：</p><p><img src="/2023/image/1218402-20220522105812481-1809087401.png" alt="" /></p><p>&nbsp;5、NllLoss:即负对数似然损失函数(Negtive Log Likehood)。</p><p>公式：</p><p><img src="/2023/image/1218402-20220522150756014-1249398109.png" alt="" /></p><p>&nbsp;</p><p>其中 y<sub>i&nbsp;</sub>是one_hot编码后的数据标签,NLLLoss()得到的结果即是&nbsp;y<sub>i&nbsp;</sub>与logsoftmax()激活后的结果相乘再求均值再取反。（实际在用封装好的函数时,传入的标签无需进行one_hot编码）</p><p>代码：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch.nn.functional as F</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch.nn as nnx </span>= torch.randn(5,5<span style="color: #000000;">)</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">x:\n</span><span style="color: #800000;">"</span><span style="color: #000000;">,x)target </span>= torch.tensor([0,2,3,1,4<span style="color: #000000;">])one_hot </span>=<span style="color: #000000;"> F.one_hot(target).float()</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">one_hot:\n</span><span style="color: #800000;">"</span><span style="color: #000000;">, one_hot)softmax </span>= torch.exp(x)/torch.sum(torch.exp(x), dim=1).reshape(-1,1<span style="color: #000000;">)</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">soft_max:\n</span><span style="color: #800000;">"</span><span style="color: #000000;">,softmax)LogSoftmax </span>=<span style="color: #000000;"> torch.log(softmax)nllloss </span>= -torch.sum(one_hot*LogSoftmax)/<span style="color: #000000;">target.shape[0]</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">nllLoss:</span><span style="color: #800000;">"</span><span style="color: #000000;">,nllloss)</span><span style="color: #008000;">#</span><span style="color: #008000;">利用torch.nn.funcation实现</span>logsoftmax = F.log_softmax(x, dim=1<span style="color: #000000;">)nllloss </span>=<span style="color: #000000;"> F.nll_loss(logsoftmax, target)</span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">"</span><span style="color: #800000;">torch_nllLoss:</span><span style="color: #800000;">"</span><span style="color: #000000;">,nllloss)<p></span><span style="color: #008000;">#</span><span style="color: #008000;">直接用torch.nn.CrossEntropyLoss验证</span><br>cross_entropy &#x3D;<span style="color: #000000;"> F.cross_entropy(x, target)<br></span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">“</span><span style="color: #800000;">cross_entropy:</span><span style="color: #800000;">“</span>,cross_entropy)</pre></p></div><p>结果：</p><p><img src="/2023/image/1218402-20220522112759275-1811304950.png" alt="" /></p><p>5、没有权重的损失函数的计算如下：</p><p>&nbsp; &nbsp; &nbsp;&nbsp;<img src="/2023/image/1218402-20200626133403330-906999435.png" alt="" loading="lazy" /></p><p>有权重的损失函数的计算如下：</p><p><img src="/2023/image/1218402-20200626133454364-1008730379.png" alt="" loading="lazy" /></p><h4>注意这里的标签值class，并不参与直接计算，而是作为一个索引,索引对象为实际类别</h4><p>6、交叉熵损失（CE）和负对数极大似然估计（NLL）的关系：交叉熵是定义在两个one-hot向量之间的，更具体地说是定义在两个概率向量之间nll是定义在一个模型上的，取决于模型本身可以取不同的形式。</p><p><a href="https://zh.m.wikipedia.org/zh-cn/%E4%BC%BC%E7%84%B6%E5%87%BD%E6%95%B0" target="_blank">似然函数：</a>都是指某种事件发生的可能性，但是在统计学中，&ldquo;似然性&rdquo;和&ldquo;概率&rdquo;（或然性）有明确的区分：概率，用于在已知一些参数的情况下，预测接下来在观测上所得到的结果；似然性，则是用于在已知某些观测所得到的结果时，对有关事物之性质的参数进行估值，也就是说已观察到某事件后，对相关参数进行猜测。</p><p><a href="https://zhuanlan.zhihu.com/p/159477597" target="_blank">下图出处：</a></p><p><img src="/2023/image/1218402-20220522145857413-1877940132.png" alt="" /></p><p>&nbsp;</p><p>举个栗子，我们一共有三种类别，批量大小为1（为了好计算），那么输入size为（1,3），具体值为torch.Tensor([[-0.7715, -0.6205,-0.2562]])。标签值为target = torch.tensor([0])，这里标签值为0，表示属于第0类。loss计算如下：</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> torch.nn as nn</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as npentroy </span>=<span style="color: #000000;"> nn.CrossEntropyLoss()input </span>= torch.Tensor([[-0.7715,-0.6205,-0.2562<span style="color: #000000;">]])target </span>=<span style="color: #000000;"> torch.tensor([0])output </span>=<span style="color: #000000;"> entroy(input,target)</span><span style="color: #0000ff;">print</span>(output) <span style="color: #008000;">#</span><span style="color: #008000;">采用CrossEntropyLoss计算的结果。</span>myselfout = -(input[:,0])+np.log(np.exp(input[:,0])+np.exp(input[:,1])+np.exp(input[:,2])) <span style="color: #008000;">#自己带公式</span><span style="color: #008000;">计算的结果</span><span style="color: #0000ff;">print</span><span style="color: #000000;">(myselfout)lsf </span>=<span style="color: #000000;"> nn.LogSoftmax()loss </span>=<span style="color: #000000;"> nn.NLLLoss()lsfout </span>=<span style="color: #000000;"> lsf(input)lsfnout </span>=<span style="color: #000000;"> loss(lsfout,target)</span><span style="color: #0000ff;">print</span>(lsfnout)</pre></div><p>结果:</p><div class="cnblogs_code"><pre>tensor(1.3447<span style="color: #000000;">)tensor([</span>1.3447<span style="color: #000000;">])tensor(</span>1.3447)</pre></div><p>&nbsp;</p><div id="translate-man-app" class="content-3WfBL_0" style="background-color: #ffffff; left: -1547px; top: 129px;"><div class="outputBox-qe9A4_0" data-v-2868eb04=""><div class="outputBox-3oESn_0" data-v-2868eb04=""><span class="outputBox-13Ovx_0" data-v-2868eb04="">softmax</span></div><div class="outputBox-1GLb__0" data-v-2868eb04=""><div class="icon-tprjJ_0 outputBox-onVZH_0" data-v-2868eb04=""><img src="chrome-extension://fapgabkkfcaejckbfmfcdgnfefbmlion/static/sound.svg" class="icon-tprjJ_0" /></div></div><div class="outputBox-2sJgr_0" data-v-2868eb04=""><div class="outputBox-GomOI_0" data-v-2868eb04=""><span class="outputBox-2liU7_0" data-v-2868eb04="">SoftMax</span></div></div><div class="outputBox-17RAm_0" style="display: none;" data-v-2868eb04="">&nbsp;</div></div></div>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>损失函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>torch.optim.SGD()各参数的解释</title>
    <link href="/2020/torch.optim.SGD()%E5%90%84%E5%8F%82%E6%95%B0%E7%9A%84%E8%A7%A3%E9%87%8A/"/>
    <url>/2020/torch.optim.SGD()%E5%90%84%E5%8F%82%E6%95%B0%E7%9A%84%E8%A7%A3%E9%87%8A/</url>
    
    <content type="html"><![CDATA[<div class="wy-grid-for-nav"><div class="wy-nav-content"><div class="rst-content"><div class="section"><h3>看<a title="pytoch中文文档" href="https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-optim/" target="_blank">pytorch中文文档</a>摘抄的笔记。</h3><h3>class torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)[source]</h3><p>实现随机梯度下降算法（momentum可选）。</p><p>Nesterov动量基于<a href="http://www.cs.toronto.edu/~hinton/absps/momentum.pdf">On the importance of initialization and momentum in deep learning</a>中的公式.</p><p><strong>参数：</strong></p><ul><li>params (iterable) &ndash; 待优化参数的iterable或者是定义了参数组的dict</li><li>lr (<code>float</code>) &ndash; 学习率</li><li>momentum (<code>float</code>, 可选) &ndash; 动量因子（默认：0）</li><li>weight_decay (<code>float</code>, 可选) &ndash; 权重衰减（L2惩罚）（默认：0）</li><li>dampening (<code>float</code>, 可选) &ndash; 动量的抑制因子（默认：0）</li><li>nesterov (<code>bool</code>, 可选) &ndash; 使用Nesterov动量（默认：False）</li></ul><p><strong>例子：</strong></p><pre><code class="python hljs"><span class="hljs-prompt">&gt;&gt;&gt; optimizer = torch.optim.SGD(model.parameters(), lr=<span class="hljs-number">0.1, momentum=<span class="hljs-number">0.9)<span class="hljs-prompt">&gt;&gt;&gt; optimizer.zero_grad()<span class="hljs-prompt">&gt;&gt;&gt; loss_fn(model(input), target).backward()<span class="hljs-prompt">&gt;&gt;&gt; optimizer.step()</span></span></span></span></span></span></code></pre><h4 id="note">&nbsp;</h4></div></div></div></div>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>torch</tag>
      
      <tag>随机梯度下降</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pytorch中y.data.norm()的含义</title>
    <link href="/2020/pytorch%E4%B8%ADy.data.norm()%E7%9A%84%E5%90%AB%E4%B9%89/"/>
    <url>/2020/pytorch%E4%B8%ADy.data.norm()%E7%9A%84%E5%90%AB%E4%B9%89/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> torchx </span>= torch.randn(3, requires_grad=<span style="color: #000000;">True)y </span>= x*2<span style="color: #0000ff;">print</span><span style="color: #000000;">(y.data.norm())</span><span style="color: #0000ff;">print</span>(torch.sqrt(torch.sum(torch.pow(y,2<span style="color: #000000;">))))  #其实就是对y张量L2范数，先对y中每一项取平方，之后累加，最后取根号i</span>=<span style="color: #000000;">0</span><span style="color: #0000ff;">while</span> y.data.norm()&lt;1000<span style="color: #000000;">:  y </span>= y*2<span style="color: #000000;">  i</span>+=1<span style="color: #0000ff;">print</span><span style="color: #000000;">(y)</span><span style="color: #0000ff;">print</span>(i)</pre></div><p>结果：</p><div class="cnblogs_code"><pre>tensor(3.7025<span style="color: #000000;">)tensor(</span>3.7025, grad_fn=&lt;SqrtBackward&gt;<span style="color: #000000;">)tensor([ </span>1066.4563, -1511.3652,  -414.6933], grad_fn=&lt;MulBackward0&gt;<span style="color: #000000;">)</span>9</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>torch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sklearn分类模块</title>
    <link href="/2020/sklearn%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9D%97/"/>
    <url>/2020/sklearn%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9D%97/</url>
    
    <content type="html"><![CDATA[<p>学习数据酷客做的笔记，懒得自己打字，就截屏记录一下，方便以后回顾。</p><p><img src="/2023/image/1218402-20200624192931513-1987678225.png" alt="" loading="lazy" /></p><p><img src="/2023/image/1218402-20200624193204001-444157779.png" alt="" loading="lazy" /></p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>sklearn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>分类问题的评价指标AUC</title>
    <link href="/2020/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87AUC/"/>
    <url>/2020/%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87AUC/</url>
    
    <content type="html"><![CDATA[<p><img src="/2023/image/1218402-20200624192305608-1265685000.png" alt="" loading="lazy" /></p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分类评价指标</tag>
      
      <tag>AUC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python处理nii文件</title>
    <link href="/2020/python%E5%A4%84%E7%90%86nii%E6%96%87%E4%BB%B6/"/>
    <url>/2020/python%E5%A4%84%E7%90%86nii%E6%96%87%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<p>第一步安装<span class="hljs-keyword">nibabel，可以使用命令：pip <span class="hljs-keyword">install nibabel</span></span></p><p><span class="hljs-keyword"><span class="hljs-keyword">之后：</span></span></p><div>from nibabel.viewers import OrthoSlicer3D as osd<br />import nibabel as nib</div><div>filename = 'image.nii'</div><div>img = nib.load(filename)</div><div>#输出文件信息<br />print(img)</div><div>w,h,q = img.dataobj.shape</div><div>#显示3D图像<br />osd(img.dataobj).show()</div><div>&nbsp;</div><div>结果：</div><div>&lt;class 'nibabel.nifti1.Nifti1Image'&gt;<br />data shape (512, 512, 333)<br />affine: <br />[[&nbsp; -0.82617199&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 204.01400757]<br />&nbsp;[&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -0.82617199&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 211.5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]<br />&nbsp;[&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.25&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -431.97399902]<br />&nbsp;[&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]]<br />metadata:<br />&lt;class 'nibabel.nifti1.Nifti1Header'&gt; object, endian='&lt;'<br />sizeof_hdr&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 348<br />data_type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : b''<br />db_name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : b''<br />extents&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0<br />session_error&nbsp;&nbsp; : 0<br />regular&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : b'r'<br />dim_info&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0<br />dim&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : [&nbsp; 3 512 512 333&nbsp;&nbsp; 1&nbsp;&nbsp; 1&nbsp;&nbsp; 1&nbsp;&nbsp; 1]<br />intent_p1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />intent_p2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />intent_p3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />intent_code&nbsp;&nbsp;&nbsp;&nbsp; : none<br />datatype&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : int32<br />bitpix&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 32<br />slice_start&nbsp;&nbsp;&nbsp;&nbsp; : 0<br />pixdim&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : [1.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.826172 0.826172 1.25&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ]<br />vox_offset&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />scl_slope&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : nan<br />scl_inter&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : nan<br />slice_end&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0<br />slice_code&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : unknown<br />xyzt_units&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 2<br />cal_max&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />cal_min&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />slice_duration&nbsp; : 0.0<br />toffset&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />glmax&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0<br />glmin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0<br />descrip&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : b''<br />aux_file&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : b''<br />qform_code&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : scanner<br />sform_code&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : unknown<br />quatern_b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />quatern_c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 0.0<br />quatern_d&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 1.0<br />qoffset_x&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 204.014<br />qoffset_y&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : 211.5<br />qoffset_z&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : -431.974<br />srow_x&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : [0. 0. 0. 0.]<br />srow_y&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : [0. 0. 0. 0.]<br />srow_z&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : [0. 0. 0. 0.]<br />intent_name&nbsp;&nbsp;&nbsp;&nbsp; : b''<br />magic&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; : b'n+1'</div><div>&nbsp;</div><div>各字段意义：</div><div><strong>sizeof_hdr：</strong>sizeof_hdr 是保存文件的头文件大小，如果是NIFTI-1或者ANALYZE格式的文件sizeof_hdr=348.</div><div>&nbsp;</div><div><strong>dim_info：</strong>dim_info字段存储着频率编码方向（1,2,3），相位编码方向（1,2,3）和采集期间层选择方向（1,2,3），对于径向采集来讲，频率编码和相位编码都设置为0。</div><div>&nbsp;</div><div><strong>dim：</strong>short dim[8]保存着前面提到的图像的维度信息。如果第0维不是（1-7）之间的数字，那么这个数据具有相反的字节顺序，所以应该进行字节交换（NIFTI标准没有提供字节顺序的字段，提倡使用dim[0]）。</div><div>&nbsp;</div><div><span style="font-size: 16px;"><strong>intent系列</strong>（<strong>影响到图像数据的读取和存储）</strong></span></div><div>&nbsp;</div><div><span style="font-size: 16px;"><strong>datatype和bitpix</strong></span></div><div>datatype中存储的是数据的类型，可接受类型如下：</div><div><img src="/2023/image/1218402-20200624090154956-2029262320.png" alt="" loading="lazy" /></div><div><img src="/2023/image/1218402-20200624090208479-1056753351.png" alt="" loading="lazy" /></div><div>而bitpix字段必须与datatype中的代码所对应的bit(s)/pix的大小相等。</div><div>&nbsp;</div><div><strong>slice切片信息</strong></div><div><div>包含字段：slice_start，slice_end, slice_code, slice_duration</div><div>slice_duration是存储功能磁共振成像采集的时间相关信息，需要与dim_info字段一起使用。</div><div>&nbsp;</div><div><strong>pixdim体素维度：</strong>每个体素维度信息都保存在pixdim[8]中，各自对应dim[8]，但pixdim[0]有特殊意义，其值只能是-1或1。前四个维度将在xyzt_units字段中指定。</div><div>&nbsp;</div><div><strong>vox_offset体素偏移量：</strong>vox_offset指 单个文件（.nii）图像数据的字节偏移量。</div><div>&nbsp;</div><div><strong>scl_slope和scl_inter数据缩放的斜率和截距</strong></div><div>存储在每个体素中的值可以线性缩放到不同的单位。字段float scl_slope和float scl_inter定义一个斜率和一个线性函数的截距。数据缩放功能允许存储在比数据类型所允许的范围更广的范围内。但是，可以在相同的数据类型中使用缩放。对于rgb数据的存储，两个缩放字段都应该被忽略。对于复杂类型，它应用于实部和虚部。</div><div>&nbsp;</div><div><strong>cal_max 和cal_min数据显示</strong></div></div><div>&nbsp;存储标量数据的文件，这两个字段用来图像打开时默认显示范围。体素值小于等于cal_min的像素显示为显示范围中的最小值（灰度范围内通常为黑），大于等于cal_max的值显示为显示范围中的最大值（通常为白色），注意：这里并不是真实改变数据大小，而是改变显示大小。</div><div>&nbsp;</div><div><div><strong>xyzt_units 度量单位</strong></div><div>在dim[1]和dim[4]中用到的空间和时间测量单元（对应各自的pixdim[1]和pixdim[4]），编码在xyzt_units字段中，1-3 bit用来存储空间维度，4-6 bit用来存储时间维度，6-7 bit没有使用。时间偏移量放在float toffset字段中，xyzt_units十进制编码如下：<img src="/2023/image/1218402-20200624092304621-1130984877.png" alt="" loading="lazy" /></div><div>&nbsp;</div><div><h3 id="char-descrip80-描述">descrip描述</h3><p>该字段char descrip[80]可以包含最多80个字符的文本。标准中没有指定这个字符串是否需要被空字符终止</p><p><strong>aux_file附加文件</strong></p><p>包含额外信息的补充文件可放在该字段中</p><p><strong>magic</strong></p><p>该字符串声明文件符合NIFTI标准。 <br />理想情况下，应该先检查该字段，如果字段中存储为&rdquo;ni1&rdquo;（或者是16进制的&lsquo;6E 69 31 00&rsquo;），那么是.hdr/.img文件对形式；如果是&rsquo;n+1&rsquo;（或&rsquo;6E 2B 31 00&rsquo;），那么就是单一的.nii文件；而如果缺少字符串，那么就按照ANALYZE格式处理。<strong><br /></strong></p><p>&nbsp;</p><p>&nbsp;</p><h3>&nbsp;</h3></div></div>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>nii</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LinearRegression线性回归</title>
    <link href="/2020/LinearRegression%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <url>/2020/LinearRegression%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<p>1、<span style="font-family: NSimsun; font-size: small;">LinearRegression</span>将方程分为两个部分存放，<code>coef_</code>存放回归系数，<code>intercept_</code>则存放截距，因此要查看方程，就是查看这两个变量的取值。</p><p>2、回归系数（regression coefficient）在<a href="https://baike.baidu.com/item/%E5%9B%9E%E5%BD%92%E6%96%B9%E7%A8%8B/11042494" target="_blank" data-lemmaid="11042494">回归方程</a>中表示<a href="https://baike.baidu.com/item/%E8%87%AA%E5%8F%98%E9%87%8F/6895256" target="_blank" data-lemmaid="6895256">自变量</a>x 对<a href="https://baike.baidu.com/item/%E5%9B%A0%E5%8F%98%E9%87%8F" target="_blank">因变量</a>y 影响大小的参数。回归系数越大表示x 对y 影响越大，正回归系数表示y 随x 增大而增大，负回归系数表示y 随x增大而减小。例如回归方程式Y=bX+a中，<a href="https://baike.baidu.com/item/%E6%96%9C%E7%8E%87/4914111" target="_blank" data-lemmaid="4914111">斜率</a>b称为回归系数，表示X每变动一单位，平均而言，Y将变动b单位。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>线性回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>安装seaborn</title>
    <link href="/2020/%E5%AE%89%E8%A3%85seaborn/"/>
    <url>/2020/%E5%AE%89%E8%A3%85seaborn/</url>
    
    <content type="html"><![CDATA[<p>第一步：安装scipy，因为seaborn依赖scipy，如何安装scipy我之前有说过，可以看我之前安装sklearn库的过程中有安装scipy的方法。</p><p>第二步：pip install seaborn</p><p>第三步：import seaborn</p><p>第四步：没有错误，那就安装成功</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>seaborn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>《大秦帝国</title>
    <link href="/2020/%E8%AF%BB%E3%80%8A%E5%A4%A7%E7%A7%A6%E5%B8%9D%E5%9B%BD%E3%80%8B%E5%90%8E%E6%84%9F/"/>
    <url>/2020/%E8%AF%BB%E3%80%8A%E5%A4%A7%E7%A7%A6%E5%B8%9D%E5%9B%BD%E3%80%8B%E5%90%8E%E6%84%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="读《大秦帝国》后感"><a href="#读《大秦帝国》后感" class="headerlink" title="读《大秦帝国》后感"></a><center>读《大秦帝国》后感</center></h1><p>读完大秦帝国，深深理解了杜牧在《阿房宫赋》中写道“灭六国者，六国也，非秦也。族秦者，秦也，非天下也”。也许是置于死地而后生，若没有当初秦国的弱小，宗族力量也是弱小无比，或许才会有商鞅变法的成功，而六国却因宗族力量太过庞大，变法始终未变彻底，才有了秦国的富强。当然若没有秦孝公替商鞅解决宗族内部问题，或许变法也不会那么轻松，随之，《商君书》也在一代代君臣维护下，使得秦国富庶百年。但是商鞅的结局却是那么悲惨，文中写道秦惠王借世族与六国之口车裂商鞅，才会有借口铲除世族复辟势力，使封地制在秦国彻底结束，完成了秦国真正的法治转化。正如韩非在《孤愤》中写道“变法志士必为牺牲”。当然若没有一代代强君与强臣，何谈秦国一统华夏，每当一次次读到秦国危亡之际，“赳赳老秦，共赴国难”就会萦绕在耳边。读到秦昭襄王这个时期，知道白起长平之战坑杀四十万赵军，被后世称为杀神，或许读完历史，你才会明白那个时期，当时在战国，白起若接受四十万赵军投降，该如何处理降军，想要全部羁押回到秦国，谈何容易，秦军也是因地势围困赵军，哪有兵力羁押，万一羁押途中生变谁负责任。何况四十万生口粮也是问题，当时秦国国仓也不富裕，肯定不能押回秦国。若是释放赵军，难保不会放虎归山，何况当时赵国是与秦国国力相当的强国，肯定不能释放降兵，虽然白起上书秦昭襄王，但是秦昭襄王却将这个事丢给白起，让白起处理，最终白起因坑杀四十万降军而被后世诟病，真是为白起鸣不平。最后也因为拒绝秦王再去攻打赵国，因为白起深知灭赵国时机已过，最后被秦王一气之下赐死。一代强君秦昭襄王之后，虽然有几年弱君执政，但是寿命都不长久且都维护秦法，秦孝文王与秦庄襄王一个做了一年秦王，一个做了三年秦王，若是多做几年，估计也就没嬴政一统华夏之说了或者大秦帝国之说。当然这也使秦国不至于像山东六国一弱再弱，当然，还好有吕不韦存在，处理国事，才不会酿成因两王先后离世而造成的秦国动荡。由于吕不韦深刻洞察到秦法的严苛，不容德政，不利于民意，所以提出宽政缓刑。使我想起吕不韦的一段争辩：“法不容德，法之过也。德不兼法，德之失也。德法并举，宽政缓刑，是为治国至道也。”这不就是当下中国德与法的关系吗？从这本书中使我重新认识了秦始皇嬴政，那个因为韩国派遣郑国修渠疲秦，而一时气愤发布逐客令，之后却果断勇于承认错误，并将这件事归为国耻，写入史记，供后人阅读，当时嬴政也在二十来岁而已。处置母亲赵姬一系列荒唐事件，以及吕不韦死后所造成的后果，依法而行，井井有条，使秦国不至于动乱，可以想到秦法当时在国民心中已经根深蒂固，不然任何一件放到山东六国，都可能造成大祸。那个可以亲自上阵，与秦国百万人民一起开凿郑国渠，可以一路奔跑四百余里，追赶水头，只为保证河渠是否质量过关，能使开渠能真正造福于民，强秦国。当读到这儿，我认为嬴政是一个明君，而不是历史上的暴君。有此明君，再与当时六国君主相比，大秦为何能不一统华夏，正如尉缭所说，“天下将一，轴心安在？华夏轴心，非秦莫属”。当然读到韩非之死，文中写到秦王因韩非存韩之心不改，而又担心韩非这种大才回韩，因为秦王已经拜读了韩非的《韩非子》，所以将其下狱，李斯上书劝谏得不到回答，最终李斯因他人提醒，这可能是秦王要他处死韩非，使得李斯只能这么做，最后证明秦王的确是这种想法，这使我又不得不想起秦昭襄王对白起坑杀四十万降军的做法是多么相似，所以后世流传李斯妒忌韩非之才，才使其下狱并杀害他，当然历史又有谁说的清，后世只能根据合理的推理还原历史而已。正如燕国有九代历史无从考证，因为没有相关史书记载，只能靠后世推测。读到王翦和蒙武逝世那一章节，这两位大将军都是驻守岭南而去世，为使岭南彻底融入华夏做出了不可磨灭的功勋，始皇心知中原复辟势力波涛汹涌，所以给赵佗下令，中原但有不测，不得是南海军队北上，不能使中原战乱波及南海，因为始皇心中有整个华夏，他说道老秦人为华夏留住了广袤的西北，也要为华夏留住广袤的南海，因为当时老秦人在中原人口不足三成，而为了岭南，老秦人移民十万余人，只为使岭南融入华夏。如果没有始皇当初的决断，真的很难想想今日南海还是否是南海。再说到焚书坑儒事件，如果没有一批儒家博士在朝堂大言取消已经实行八年的郡县制而去实行诸侯制，因为当时六国复辟势力蠢蠢欲动，此行为不正满足了六国复辟吗？且秦始皇为了彰显帝国对儒家的厚待，将在战国备受冷落的儒家学派推上了学派领袖位置，更是赐予高官，但是却没有得到儒家投桃报李，却处处想着恢复旧制，获罪之后更是一味报仇，以至于千秋万代对秦政鞭尸叱骂，毫无一丝中庸之心，而焚书坑儒就是帝国对六国复辟势力做出的反击，是新文明彻底摆脱旧时代而付出的必然代价。况且当时的焚书法令有很大的弹性，按之后许多名士文中写道，焚书并没有后世儒家所传的那么恐怖及严苛，只是为了震慑儒家之言，震慑复辟势力，或许我们都是受到后世儒家的渲染与夸张，有时候我们真的好好读一读历史，才能更好地了解历史，不能尽信一家之言。当然全文都充斥着对儒家学派的蔑视与不屑，可能作者也带着一丝蔑视儒家的心，从张仪大骂孟子那一段，看着着实精彩，也说出了儒家学派的作风，让我读起来，都替儒家脸红。当然始皇和秦国也因为这件事被钉在了历史耻辱柱上。感觉嬴政最大的败笔就是执政一生，没有在在世之时就确立扶苏为太子，而当时扶苏的品性与才具已经得到天下公认，这才会使得赵高李斯有可乘之机，篡改始皇遗诏，立最不成器胡亥为二世皇帝。使得帝国败亡如此之快。可惜李斯前半生巨大功绩和杰出才具，读完全文，感觉若没有李斯的协助，始皇想一统华夏也难。当然战国真的是人才济济的时代，是一个敢争的时代，凡有血气，皆有争心，不尚空谈，求真务实，国有昏君暴政，则人才立即出走，人民立即反抗，或纷纷逃亡他国，诸子百家各展身手，哪一国获得人才，哪一国就会兴盛，哪一国抛弃人才，哪一国就会亡国，正如文中“天意如何，失才便要亡国”。魏国灭亡大多数原因就是失才，正如文中所说：“大争之世，何物最为宝贵？人才。风华魏国，何种资源最丰厚？人才。魏国政风，最不在乎的是什么？人才”，战国人才十之七八都是出自魏国，而魏国却因失才而灭亡。也是战国变法的时代，当然变法最成功的就是商鞅变法，被称之为法圣，在那个时代能举国一法，法无外刑，即使是卿相大夫忠诚孝子犯法，也是和民众一体对待，依法论罪，绝不开赦。再想到儒家一说，“刑不上大夫，礼不下庶人”，真是荒唐。怪不得无法在战国立足，无法在秦国立足，还一直想着恢复诸侯制，真是为一己之私欲，不顾天下百姓。其次秦国以及秦帝国时代，是中国历史上唯一一个自觉的法治时代，如果秦国之后能一直延续这种法治，今日之中国，将会强大到何种地步，而曾经的大英帝国也才只是在1688年以后进入法治时代，成就了后来的全球帝国。最后借作者一句：“秦帝国的根本伟大之处，不在于统一了国家，而在于统一了文明。惟其统一的中国文明，我们民族虽历经劫难，但生命永恒”。当我读完这部巨著，真的想将项羽这等屠夫暴打一顿，为一己之愤慨，而将关于秦国及秦帝国的传记全部随着咸阳宫殿烧毁，使得后世关于秦国史记多半都是听信儒家言论与记载，而秦帝国却只能无声辩驳。而项羽呢，明明是一个连屠六城的屠夫，使得中原人口大幅度减少，却只是霸王自刎乌江这段历史被人广为流之，他屠之人比白起多多少倍，应该叫屠夫自刎乌江。但也要感谢作者孙皓晖耗时16年才完成这部巨著，给我们还原这段弥足珍贵的历史，使我们能够大幅度了解那个时代。</p>]]></content>
    
    
    <categories>
      
      <category>读一本好书</category>
      
    </categories>
    
    
    <tags>
      
      <tag>大秦帝国</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>内联函数规则</title>
    <link href="/2020/%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0%E8%A7%84%E5%88%99/"/>
    <url>/2020/%E5%86%85%E8%81%94%E5%87%BD%E6%95%B0%E8%A7%84%E5%88%99/</url>
    
    <content type="html"><![CDATA[<p>1、内联函数的声明必须在调用之前。</p><div class="cnblogs_Highlighter"><pre class="brush:cpp;gutter:true;">#include&lt;iostream&gt;inline bool ischar(char); //内联声明int main(){    char c;    if(ischar(c)){....}}bool ischar(char ch){....}</pre></div><p>如果是下面这种情况，那么在程序编译的过程中，并不认为那是内联函数，会将他当做普通函数对待。</p><div class="cnblogs_Highlighter"><pre class="brush:cpp;gutter:true;">#include&lt;iostream&gt;bool ischar(char); //此处无inlineint main(){    char c;    if(ischar(c)){....}}inline bool ischar(char ch){....} //此处为inline</pre></div><p>所以在编译时，在调用之前看到内联声明就十分必要了。</p><p>2、内联函数应该尽可能的小，并且要结构简单，这样嵌入代码时才不会影响调用函数的主体结构。因此，内联函数不能出现switch、while等语句，如果出现这些语句，那么编译时将会无视这个内联函数，将它作为普通函数对待。</p><p>3、递归函数也不能作为内联函数</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>内联函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python安装sklearn</title>
    <link href="/2020/python%E5%AE%89%E8%A3%85sklearn/"/>
    <url>/2020/python%E5%AE%89%E8%A3%85sklearn/</url>
    
    <content type="html"><![CDATA[<p>安装sklearn这个包，首先要安装三个依赖包，如图划红线的部分。</p><p><img src="/2023/image/1218402-20200308224626491-369985655.png" alt="" /></p><p>要找这三个包，我们都可以登录：<a href="https://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy" target="_blank">https://www.lfd.uci.edu/~gohlke/pythonlibs/#scipy&nbsp;</a> 这个网址，去下载你需要的包。</p><p>当然在下载这几个包时，会非常的慢，建议用谷歌下载时，保存下载路径，然后用迅雷下载，相比会快很多。</p><p>之后呢，就一个一个安装。</p><p><strong>pip install ***.whl</strong></p><p>之所以要一个个安装，是因为如果直接pip install sklearn 很容易出错。反正我是被搞害怕了，就把他要依赖的包，自己下载下来去安装。</p><p>最后呢，打开idle。输入<strong>import sklearn</strong></p><p>如果没报错，那就安装成功了。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>sklearn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python安装pandas+pytz</title>
    <link href="/2020/python%E5%AE%89%E8%A3%85pandas+pytz/"/>
    <url>/2020/python%E5%AE%89%E8%A3%85pandas+pytz/</url>
    
    <content type="html"><![CDATA[<p>如下图所示，在安装pandas的过程中，发现他还要安装pytz这个包。我不想等他自己下载，因为很容易出错，所以我就先下载了pytz这个包，然后安装完毕，再去安装pandas这个包。</p><p><img src="/2023/image/1218402-20200308215013249-516181254.png" alt="" /></p><p>首先呢先登录这个网址：https://pypi.org/project/pytz/#files</p><p><img src="/2023/image/1218402-20200308215242885-1745667828.png" alt="" /></p><p>&nbsp;</p><p>然后下载划红线的那个whl文件，可能会非常慢。（反正我等了老久）</p><p>之后就开始安装：pip --default-time=100 install pytz-2019.3-py2.py3-none-any.whl</p><p>其中-default-time=100 这个是防止报等待时间过长而出现的错误。</p><p>然后呢，再登录这个网址：https://pypi.org/project/pandas/#files</p><p><img src="/2023/image/1218402-20200308215533917-943169149.png" alt="" /></p><p>&nbsp;</p><p>选择你需要的whl文件下载。因为我的python版本是3.7的，所以就下载了红线这个版本。</p><p>当然我的下载的whl文件都放在：D:\python\Scripts这个目录下了。</p><p>&nbsp;</p><p>之后就在安装pandas，第一张图有代码。</p><p>所有过程都完毕后，你运行idle，输入：import pandas</p><p>如果没有错误，那就恭喜你，安装成功。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>pandas</tag>
      
      <tag>pytz</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>西瓜书第十四章概率图模型学习笔记</title>
    <link href="/2020/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E5%8D%81%E5%9B%9B%E7%AB%A0%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>1、<strong>机器学习最重要的任务</strong>就是根据已有的一系列证据（例如训练样本）来对未知变量（例如类别标记）进行估计和推测。<br />2、概率图分为两类：<br />&nbsp;　　1）、使用<strong>有向无环图</strong>表示变量间的<strong>依赖关系</strong>，称为有向图模型或贝叶斯网（Bayesian network）。<br />&nbsp;　　2）、使用<strong>无向图</strong>表示变量间的<strong>相互关系</strong>，称为无向图模型或马尔可夫网（Markov network）。<br />3、<span style="color: #ff0000;">隐马尔可夫模型（Hiddden Markov Model，简称HMM）</span>是结构最简单的动态贝叶斯网（dynamic Bayesian network），这是一种著名的<span style="color: #3366ff;">生成式有向图模型</span>，主要用于时序数据建模，在语音识别、自然语言处理等领域有广泛应用。<br />4、<span style="color: #ff0000;">马尔可夫链（Markov chain</span>）:系统下一时刻的状态仅由当前状态决定，不依赖与以往的任何状态。<br />5、确定一个<span style="color: #993366;">隐马尔可夫模型需要三个参数</span>：<span style="color: #3366ff;">状态转移概率、输出转移概率、初始状态概率</span>。<br />6、<span style="color: #ff0000;">马尔可夫随机场（Markov Random Field，简称MRF）是典型的马尔可夫网</span>，是一种著名的<span style="color: #3366ff;">生成式无向图模型</span>。图中每个结点表示一个或一组变量，结点之间的边表示两个变量之间的依赖关系。<br />&nbsp;　　1）、全局马尔科夫性：给定两个变量子集的分离集，则这两个变量子集条件独立。<br />7、由全局马尔可夫性可得到两个推论：<br />&nbsp;　　1）、<span style="color: #ff0000;">局部马尔可夫性（local Markov property）</span>:给定某个变量的邻接变量，则该变量条件独立于其他变量。<br />&nbsp;　　2）、<span style="color: #ff0000;">成对马尔可夫性（pairwise Markov property）</span>:给定所有其他变量，两个非邻接变量条件独立。<br />8、<span style="color: #ff0000;">条件随机场（Conditional Random Field，简称CRF</span>）是一种<span style="color: #3366ff;">判别式无向图模型</span>。<br />&nbsp;　　1）、条件随机场试图对多个变量在给定观测值后的条件概率进行建模。<br />&nbsp;　　2）、条件随机场和马尔可夫随机场均使用团上的势函数定义概率，两者在形式上没有显著区别；</p><p>　　　　　但条件随机场处理的是条件概率，而马尔可夫随机场处理的是联合概率。<br />9、<span style="color: #99cc00;">概率图模型推断方法</span>大致分为两类：<br />&nbsp;　　1）、<span style="color: #800080;">精确推断法</span>，希望能计算出目标变量的边际分布或条件分布的精确值。其缺点就是，这类算法的计算复杂度随着极大规模的增长呈指数增长，适用范围有限。<br />　　&nbsp;2）、<span style="color: #800080;">近似推断法</span>，希望在较低的时间复杂度下获得原问题的近似解。这类方法在现实中常用。<br />10、精确推断算法是一类动态规划算法，他利用图模型所描述的条件独立性来削减计算目标概率值所需的计算量。变量消去法是最直观的精确推断算法，也是其他精确推断算法的基础。<br />&nbsp;　　1）、变量消去的缺点：若需计算多个边际分布，重复使用变量消去法将会造成大量的冗余计算。<br />&nbsp;　　2）、<span style="color: #ff0000;">信念传播（Belief Propagation）</span>算法将变量消去法中的求和操作看做一个消息传递过程，较好地解决了求解多个边际分布时的重复计算问题。<br />11、近似推断方法大致分为两类：<br />&nbsp;　　1）、采样（sampling）,使用随机化方法完成近似。<br />&nbsp;　　2）、使用确定性近似完成近似推断，典型代表为<span style="color: #ff0000;">变分推断（variational inference）</span>.<br />12、概率图模型中最常用的<span style="color: #800080;">采样技术</span>是<span style="color: #ff0000;">马尔可夫链蒙特卡洛（Markov Chain Monte Carlo，简称MCMC）</span>方法。<br />&nbsp;　　1）、MCMC方法的关键就在于通过构造&ldquo;平稳分布为p的马尔科夫链&rdquo;来产生样本。<br />&nbsp;　　2）、MCMC方法先设法构造一条马尔可夫链，使其收敛至平稳分布恰为待估计参数的后验分布，然后通过这条马尔可夫链来产生符合后验分布的样本，并基于这些样本来进行估计。<br />&nbsp;　　3）、<span style="color: #ff0000;">Metropolis-Hasting（简称MH）</span>算法是MCMC的重要代表，它基于&ldquo;拒绝采样&rdquo;（reject sampling）来逼近平稳分布p。<br />&nbsp;　　4）、<span style="color: #ff0000;">吉布斯采样（Gibbs sampling）</span>被视作MH算法的特例，它也是使用马尔可夫链来获取样本，而该马尔可夫链的平稳分布也是采样的目标分布。<br />13、<span style="text-decoration: underline;">变分推断通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近似分布的类型，从而得到一种局部最优解、但具有确定解的近似后验分布。</span><br />14、<span style="color: #ff0000;">话题模型（topic model）</span>是一族生成式有向图模型，主要用于处理离散型的数据，在信息检索、自然语言处理等领域有广泛应用。<br />&nbsp;　　1）、<span style="color: #ff0000;">狄利克雷分配模型（Latent Dirichlet Allocation，简称LDA）</span>是话题模型的典型代表。</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>西瓜书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习西瓜书第七章贝叶斯分类器笔记</title>
    <link href="/2020/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%B8%83%E7%AB%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%AC%94%E8%AE%B0%20/"/>
    <url>/2020/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%B8%83%E7%AB%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8%E7%AC%94%E8%AE%B0%20/</url>
    
    <content type="html"><![CDATA[<div>1、<span style="color: #ff0000;">贝叶斯决策理论（Bayesian decision theory）</span>是概率框架下实施决策的基本方法。<br />2、欲使用贝叶斯判定准则来最小化决策风险，首先要获得后验概率P。<br />3、<span style="color: #ff0000;">极大似然估计（Maximum Likelihood Estimation，简称MLE）</span>是根据数据采样来估计概率分布参数的经典算法。</div><div>&nbsp;　　1）、估计类条件概率的一种常用策略是先假定其具有某种确定的概率分布形式，再基于训练样本对概率分布的参数进行估计。<br />4、基于贝叶斯公式来估计后验概率的主要困难在于：类条件概率是所有属性上的联合概率，难以从有限的训练样本直接估计而得。为了避开这个障碍，<span style="color: #ff0000;">朴素贝叶斯分类器（naive Bayes classifier）</span>采用&ldquo;属性条件独立性假设&rdquo;（attribute conditional independence assumption）:对已知类别，假设所有属性相对独立。<br />5、朴素贝叶斯分类器的训练过程就是基于训练集D来估计类先验概率，并为每个属性估计条件概率。<br />6、为了避免其他属性携带的信息被训练集中未出现的属性值&ldquo;抹去&rdquo;，在估计概率值时通常要进行&ldquo;平滑&rdquo;（smoothing），常用&ldquo;<span style="color: #ff0000;">拉普拉斯修正&rdquo;（Laplacian correction）</span>，从而避免了因训练集样本不充分而导致概率估值为零的问题。<br />7、拉普拉斯修正实质上假设了属性值与类别均匀分布。<br />8、因为属性条件独立性假设在现实任务中难以假设成立，所以引入了&ldquo;<span style="color: #ff0000;">半朴素贝叶斯分类器&rdquo;（semi-navie Bayes classifiers）</span>的学习方法。<br />9、半朴素贝叶斯分类器思想：适当考虑一部分属性间的相互依赖信息，从而既不需要进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。所以<span style="color: #ff0000;">&ldquo;独依赖估计&rdquo;（One-Dependent Estimator，简称ODE）</span>是半朴素贝叶斯分类器最常用的一种策略。<br />10、<span style="color: #ff0000;">贝叶斯网（Bayesian network）亦称&ldquo;信念网&rdquo;（belief network）</span>，它借助<span style="color: #ff0000;">有向无环图（Directed Acyclic Graph，简称DAG</span>）来刻画属性之间的依赖关系，并使用<span style="color: #ff0000;">条件概率表（Conditional Probability Table，简称CPT）</span>来描述属性的联合概率分布。<br />11、贝叶斯网的学习过程：首先就是根据数据集来找出结构最&ldquo;恰当&rdquo;的贝叶斯网，由此引入&ldquo;评分搜索&rdquo;解决这一问题。我们需要先定义一个<span style="color: #ff0000;">评分函数（score function）</span>以此来评估贝叶斯网与训练数据的契合程度，然后基于这个评分函数拉寻找结构最优的贝叶斯网。<br />12、常用的评分函数通常基于<span style="color: #ff0000;">信息论准则</span>，此类准则将学习问题看做一个数据压缩任务，学习的目标是找到一个能以最短编码长度描述训练数据的模型。对贝叶斯学习而言，模型就是一个贝叶斯网。<br />13、直接根据贝叶斯网定义的联合概率分布来求精确计算后验概率，这样的&ldquo;精确推断&rdquo;已被证明是NP难的，此时，需要借助&ldquo;近似推断&rdquo;，通过降低精度要求，在有限的时间内求得近似解。在现实应用中，贝叶斯网的近似推断常使用<span style="color: #ff0000;">吉布斯采样（Gibbs sampling）</span>来完成，这是一种随机采样方法。<br />14、<span style="color: #ff0000;">EM（Expectation-Maximization）</span>算法是常用的估计参数隐变量的利器，它是一种迭代式方法，其基本思想是：若参数O已知，则可根据训练数据推断出最优隐常量Z的值（E步）；反之，若Z的值已知，则可方便地对参数O做极大似然估计（M步）。<br />15、贝叶斯分类器（Bayes Classifier）是通过最大后验概率进行单点估计。<br />&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 贝叶斯学习（Bayesian Learning）是进行分布估计。<br />16、贝叶斯网为不确定学习和推断提供了基本框架，因其强大的表示能力、良好的可解释性而广受关注。贝叶斯网学习分为结构学习和参数学习两部分。参数学习较为简单，而结构学习被证是NP难问题。</div>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>西瓜书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习西瓜书第六章支持向量机笔记</title>
    <link href="/2020/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E5%85%AD%E7%AB%A0%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AC%94%E8%AE%B0%20%20/"/>
    <url>/2020/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E5%85%AD%E7%AB%A0%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%AC%94%E8%AE%B0%20%20/</url>
    
    <content type="html"><![CDATA[<p>1、<span style="color: #ff0000;">支持向量（support vector</span>）:就是距离超平面最近的几个训练样本点使得满足某方程式的成立。个人理解就是超平面一侧的点（距离最近）与超平面另外一侧的点（距离最近）其绝对值是相等的。而这个方程式有两个关键量：<span style="text-decoration: underline;">w=（w1,w2..）法向量、b位移项。</span><br />2、<span style="color: #ff0000;">二次规划（Quadratic Programming，简称QP）</span>是一类典型的优化问题，包括凸二次优化和非凸二次优化。在此类问题中，目标函数是变量的二次函数，而约束条件是变量的线性不等式。<br />&nbsp;　　1）、<span style="color: #00ff00;">常用二次规划解法有：</span>椭圆法（ellipsoid method）、内点法（interior point）、增广拉格朗日法（augmented Lagrangian）、梯度投影法（gradient projection）等。<br />3、<span style="color: #ff0000;">SMO（Sequential Minimal Optimization）</span>:就是为了解决对偶问题（dual problem）在实际任务中会造成很大开销而引入的。<br />4、如果原始空间是有限维，即属性数有限，那么一定存在一个高维特征空间使样本可分。<br />5、<span style="color: #ff0000;">核函数（kernel function）</span><br />&nbsp;　　1）、只要一个对称函数所对应的核矩阵半正定，他就能作为核函数使用。<br />&nbsp;　　2）、任何一个核函数都隐式地定义了一个称为&ldquo;<span style="color: #ff0000;">再生核希尔伯特空间&rdquo;（Reproducing Kernel Hilbert Space，简称RKHS）</span>的特征空间。<br />&nbsp;　　3）、因为我们希望样本在特征空间内线性可分，因此特征空间的好坏对支持向量机的性能至关重要。<br />&nbsp;　　4）、因为核函数隐式地定义特征空间，所以&ldquo;核函数选择&rdquo;是支持向量机的最大变数。<br />6、<span style="color: #ff0000;">软间隔（soft margin）</span>：在现实实际问题中，很难找到合适的核函数使得训练样本在特征空间中线性可分，或者说，即使找到合适的核函数使得训练集在特征空间中线性可分，也很难断定这个貌似线性可分的结果不是由于过拟合所造成的，缓解该问题的一个办法就是允许支持向量机在一些样本上出错，所以引入软间隔。<br />7、支持向量机的求解通常是借助于凸优化技术。</p><p>8、支持向量机：</p><p>　　1）、优点：泛化错误率低，计算开销不大，结果易解释。</p><p>　　2）、缺点：对参数调节和核函数的选择敏感，原始分类器不加修改仅适用于处理二类问题</p><p>　　3）、适用数据类型：数值型和标准型数据</p><p>9、支持向量机是一种分类器。因为它可以产生一个二值决策结果，所以称为&ldquo;机&ldquo;，即它是一种决策&ldquo;机&rdquo;。</p><p>10、支持向量机是一种监督学习算法。</p><p>11、SVM是针对二分类问题的学习方法</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>西瓜书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>matplotlib安装</title>
    <link href="/2020/matplotlib%E5%AE%89%E8%A3%85/"/>
    <url>/2020/matplotlib%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<p>第一步：登录：https://pypi.org/project/matplotlib/#files</p><p>第二步：选择你需要的版本下载的版本</p><p><img src="/2023/image/1218402-20200223222020897-1935553533.png" alt="" /></p><p>&nbsp;</p><p>第三步：保存在&nbsp; D:\python\Scripts&nbsp; 下，本目录下打开cmd</p><p>第四步：pip install ***.whl</p><p>第五步：打开python的IDLE。输入：import matplotlib，若没报错，则说明安装成功。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>matplotlib</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>numpy安装</title>
    <link href="/2020/numpy%E5%AE%89%E8%A3%85/"/>
    <url>/2020/numpy%E5%AE%89%E8%A3%85/</url>
    
    <content type="html"><![CDATA[<p>第一步登录网址：https://www.lfd.uci.edu/~gohlke/pythonlibs/ &nbsp; &nbsp; 下载你需要的版本；</p><p><img src="/2023/image/1218402-20200223220026521-1806862205.png" alt="" /></p><p>第二步：保存到D:\python\Scripts下</p><p>第三步：本目录下打开cmd</p><p>第四步：pip install ***.whl</p><p>第五步：打开python的IDEL输入：import numpy。如果没出现错误，则安装成功。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>numpy</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2020MICS一些会议笔记</title>
    <link href="/2018/2020MICS%E4%B8%80%E4%BA%9B%E4%BC%9A%E8%AE%AE%E7%AC%94%E8%AE%B0/"/>
    <url>/2018/2020MICS%E4%B8%80%E4%BA%9B%E4%BC%9A%E8%AE%AE%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>目录</p><p>一、张惠茅（AI在放射科）... 1</p><p>二、练春锋... 2</p><p>三、徐军（计算病理及其数字化切片组织形态学定量分析）... 2</p><p>四、徐佳园... 2</p><p>五、张康（人工智能助力CT影像对新冠肺炎进行精准诊断）... 2</p><p>六、程炜（脑影像大数据及其在精神疾病中的应用）... 3</p><p>七、李阳（多模态自适应脑网络方法及应用）... 4</p><p>八、宋彬... 6</p><p>九、周涛（多模态学习）... 6</p><p>十、于杰（人工智能在肝占位超声诊断中的研究）... 6</p><p>十一、闫平昆（Multi-X Medical Image Segmentation）... 6</p><p>十二、马建华（低剂量医学CT成像技术）... 7</p><p>十三、赵一天... 8</p><p>十四、圆桌会议... 8</p><p>十五、结束... 9</p><p>&nbsp;</p><h2>一、张惠茅（AI在放射科）</h2><p>1、发展现状：</p><p>&nbsp;&nbsp;&nbsp; （1）88%的医学影像AI在肺结节</p><p>&nbsp;&nbsp;&nbsp; （2）超过30%的研究所不能获得医院的数据</p><p>2、应用方向</p><p>&nbsp;&nbsp;&nbsp; （1）鼻咽癌靶区勾画和分割</p><p>&nbsp;&nbsp;&nbsp; （2）全栈AI（上海联影）</p><p>&nbsp;&nbsp;&nbsp; （3）质量控制</p><p>&nbsp;&nbsp;&nbsp; （4）胸片分诊</p><p>&nbsp;&nbsp;&nbsp; （5）肺结节筛查和评估系统</p><p>&nbsp;&nbsp;&nbsp; （6）儿童骨龄评价系统</p><p>3、AI合作之路（医理工合作）</p><p>&nbsp;&nbsp;&nbsp; （1）落地产品很少</p><p>&nbsp;&nbsp;&nbsp; （2）如何获得一个好的算法帮助医生进行标注</p><p>&nbsp;&nbsp;&nbsp; （3）新冠肺炎AI挑战--&mdash;标注的困境</p><p>4、结语</p><p>&nbsp;&nbsp;&nbsp; （1）界定相对独立实用的医学场景</p><p>&nbsp;</p><h2>二、练春锋</h2><p>1、（H-FCN）hierarchical fully convolution network:在阿尔兹海默症中应用</p><p>2、H-FCN改进Attention-guided Hybrid Network</p><p>3、MWAN</p><p>4、PVS</p><p>&nbsp;&nbsp;&nbsp; （1）multi-channel Multi-scale FCN(M<sup>2</sup>FCN)</p><p>&nbsp;</p><h2>三、徐军（计算病理及其数字化切片组织形态学定量分析）</h2><p>1、分割实用unet网络</p><p>2、利用混淆矩阵评估模型</p><h2>四、徐佳园</h2><p>1、通过遥感卫星观察地区变化对人脑发展的影响</p><h2>五、张康（人工智能助力CT影像对新冠肺炎进行精准诊断）</h2><p>1、key points：精准病灶分割与诊断</p><p>&nbsp;</p><h2>六、程炜（脑影像大数据及其在精神疾病中的应用）</h2><p>1、脑影像数据库</p><p>&nbsp;</p><p>2、绘图：matlib</p><p>&nbsp;</p><p>&nbsp;</p><p>3、association analysis</p><p>&nbsp;</p><p>&nbsp;</p><h2>七、李阳（多模态自适应脑网络方法及应用）</h2><p>1、创新一：有向脑连接网络及弹性多层感知机</p><p>&nbsp;</p><p>2、创新二：多模态脑网络</p><p>&nbsp;</p><p>&nbsp;</p><p>3、创新三：多模态自适应网络与时空特征深度融合</p><p>&nbsp;&nbsp;&nbsp; （1）使用了SVM分类器</p><h2>八、宋彬</h2><p>1、pyRadiomics是提取影像学特征</p><h2>九、周涛（多模态学习）</h2><p>1、Latent representation learning for AD diagnosis</p><p>2、Hi-Net for Multi-modal MR Image Synthesis</p><h2>十、于杰（人工智能在肝占位超声诊断中的研究）</h2><p>1、使用超声图片，利用人工智能对图像进行分析，进而提升超声对疾病的判断，使得超声不仅仅只是用于疾病筛查，真正用于疾病的诊断。使得超声能够和CT匹配，达到诊断医生的水平。</p><p>2、输入的是静态图像</p><p>&nbsp;</p><p>&nbsp;</p><h2>十一、闫平昆（Multi-X Medical Image Segmentation）</h2><p>1、</p><p>&nbsp;</p><h2>十二、马建华（低剂量医学CT成像技术）</h2><p>1、</p><p>&nbsp;</p><p>&nbsp;</p><h2>十三、赵一天</h2><p>1、OCT-A眼底图片当前研究的很少，所以很有发展前景</p><p>2、研究的OCT-A是自己建立的数据库（全球唯一）</p><p>3、成果</p><p>&nbsp;</p><h2>十四、圆桌会议</h2><p>1、医学AI技术如何落地？</p><p>答：（1）深度学习和机器学习的医学人工智能的落地成本降低，突破了课商业投资的阈值。肺结节、骨折、乳腺、脑出血易于落地。</p><p>（2）落地阻力：技术不够，监管不够，产品价值不明晰</p><p>2、医学AI科研如何选题？项目申请有何经验？</p><p>答：（1）来源于临床，高于临床，服务于临床。</p><p>3、医学到底需要那一方面数学基础？</p><p>答：（1）最优化，现在的深度学习就是一个最优化问题。</p><p>（2）偏分法</p><p>（3）微积分和线性代数</p><p>（4）level set一种曲线拟合的方法，相比较深度学习可解释性强。比较小众。</p><p>（5）计算机视觉的基础要好，沉下心，别太着急发paper</p><p>4、青年学者应该在小领域还是大领域开始？</p><p>答：打基础，在一个具体领域先混好，先满足自己生存，之后再在大领域发展。争取将自己发展为T型人才，在某一方面扎下根，广泛涉猎各个领域。</p><h2>十五、结束</h2><p>1、每期会议链接。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>2020MICS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>DBSCAN基于密度的聚类算法</title>
    <link href="/2018/DBSCAN%E5%9F%BA%E4%BA%8E%E5%AF%86%E5%BA%A6%E7%9A%84%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    <url>/2018/DBSCAN%E5%9F%BA%E4%BA%8E%E5%AF%86%E5%BA%A6%E7%9A%84%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><span style="font-family: 仿宋;">DBSCAN(Density-Based Spatial Clustering of Applications with Noise)是一个比较有代表性的基于密度的<a href="https://baike.baidu.com/item/%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95" target="_blank">聚类算法</a>。与划分和层次聚类方法不同，它将簇定义为密度相连的点的最大集合，能够把具有足够高密度的区域划分为簇，并可在噪声的<a href="https://baike.baidu.com/item/%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E5%BA%93" target="_blank">空间数据库</a>中发现任意形状的聚类。</span></p><p><span style="font-weight: bold; font-family: 仿宋;">关键概念<br />1.与基于距离的聚类算法不同的是，基于距离的聚类算法的聚类结果是球状的簇，而基于密度的聚类算法可以发现任意形状的聚类，这对于带有噪音点的数据起着重要的作用。<br />2.所有的数据被分为三类点：<br />核心点。在半径eps内含有超过min_samples数目的点。<br />边界点。在半径eps内点的数量小于min_samples，但是落在核心点的邻域内，也就是说该点不是核心点，但是与其他核心点的距离小于eps。<br />噪音点。既不是核心点也不是边界点的点，该类点的周围数据点非常少。</span></p><p><span style="font-family: 仿宋;">步骤：</span></p><div class="para"><span style="font-family: 仿宋;">DBScan需要二个参数： 扫描半径 (eps)和最小包含点数(minPts)。 任选一个未被访问(unvisited)的点开始，找出与其距离在eps之内(包括eps)的所有附近点。</span></div><div class="para"><span style="font-family: 仿宋;">如果 附近点的数量 &ge; minPts，则当前点与其附近点形成一个簇，并且出发点被标记为已访问(visited)。 然后递归，以相同的方法处理该簇内所有未被标记为已访问(visited)的点，从而对簇进行扩展。</span></div><div class="para"><span style="font-family: 仿宋;">如果 附近点的数量 &lt; minPts，则该点暂时被标记作为噪声点。</span></div><div class="para"><span style="font-family: 仿宋;">如果簇充分地被扩展，即簇内的所有点被标记为已访问，然后用同样的算法去处理未被访问的点。</span></div><div class="para"><span style="font-family: 仿宋;">&nbsp;</span></div><div class="para"><span style="font-family: 仿宋;">好处：</span></div><div class="para"><div class="para"><span style="font-family: 仿宋;">1. 与K-means方法相比，DBSCAN不需要事先知道要形成的簇类的数量。</span></div><div class="para"><span style="font-family: 仿宋;">2. 与K-means方法相比，DBSCAN可以发现任意形状的簇类。</span></div><div class="para"><span style="font-family: 仿宋;">3. 同时，DBSCAN能够识别出噪声点。</span></div><div class="para"><span style="font-family: 仿宋;">4.DBSCAN对于数据库中样本的顺序不敏感，即Pattern的输入顺序对结果的影响不大。但是，对于处于簇类之间边界样本，可能会根据哪个簇类优先被探测到而其归属有所摆动。</span></div><div class="para"><span style="font-family: 仿宋;">&nbsp;</span></div><div class="para"><span style="font-weight: bold; font-family: 仿宋;">应用场景和限制：<br />是非监督的聚类算法。<br />对噪声点的容忍性非常好；而去簇的形状随意，不受线性方程的限制。</span></div><div class="para">&nbsp;</div><div class="para"><span style="font-family: 仿宋;">缺点：</span></div><div class="para"><div class="para"><span style="font-family: 仿宋;">1. DBScan不能很好反映高维数据。</span></div><p><span style="font-family: 仿宋;">2. DBScan不能很好反映数据集以变化的密度</span></div></p><div class="para"><span style="font-family: 仿宋;">&nbsp;</span></div><div class="para"><span style="font-family: 仿宋;">参数：</span></div><div class="para"><span style="font-family: 仿宋;">class sklearn.cluster.DBSCAN(eps=0.5, min_samples=5, metric='euclidean', algorithm='auto', leaf_size=30, p=None, random_state=None)</span></div><div class="para"><span style="font-family: 仿宋;">eps：点之间的间距，大于这个间距的就不算一个簇了。</span><br /><span style="font-family: 仿宋;">min_samples：可以算作核心点的高密度区域的最少点个数。</span><br /><span style="font-family: 仿宋;">metric：距离公式，可以用默认的欧式距离，还可以自己定义距离函数。</span><br /><span style="font-family: 仿宋;">algorithm：发现近邻的方法，是暴力brute，二维空间的距离树kd_tree还是球状树形结构ball_tree。这个参数主要是为了降低计算复杂度的，可以从O(N^2)降到O(n*log(n))。换句话说，无论哪种算法都会达到最后的结果，影响的只是性能。</span><br /><span style="font-family: 仿宋;">leaf_size：配合两种_tree算法的。</span><br /><span style="font-family: 仿宋;">random_state：不用。</span></div><div class="para"><p><span style="font-family: 宋体;">结果展开说：</span></p><span style="font-family: 仿宋;">labels_：所有点的分类结果。无论核心点还是边界点，只要是同一个簇的都被赋予同样的label，噪声点为-1.<br />core_sample_indices_：核心点的索引，因为labels_不能区分核心点还是边界点，所以需要用这个索引确定核心点。</span></div><div class="para"><span style="font-family: 仿宋;"># 不是很懂，做个笔记，日后用到详细添加内容</span></div></div>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>DBSCAN</tag>
      
      <tag>密度聚类算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>HierarchicalClustering分层集群</title>
    <link href="/2018/Hierarchical%20Clustering%E5%88%86%E5%B1%82%E9%9B%86%E7%BE%A4/"/>
    <url>/2018/Hierarchical%20Clustering%E5%88%86%E5%B1%82%E9%9B%86%E7%BE%A4/</url>
    
    <content type="html"><![CDATA[<p>主要分为两大类：agglomerative（自底向上）和 divisive（自顶向下）。首先说前者，自底向上，一开始，每个数据点各自为一个类别，然后每一次迭代选取距离最近的两个类别，把他们合并，直到最后只剩下一个类别为止，至此一棵树构造完成。</p><p>　　有两个问题：</p><ol><li>如何计算两个点的距离？这个通常是 problem dependent 的，一般情况下可以直接用一些比较通用的距离就可以了，比如欧氏距离等。</li><li value="2">如何计算两个类别之间的距离？一开始所有的类别都是一个点，计算距离只是计算两个点之间的距离，但是经过后续合并之后，一个类别里就不止一个点了，那距离又要怎样算呢？到这里又有三个变种：<ul><li>Single Linkage：又叫做 nearest-neighbor ，就是取两个集合中距离最近的两个点的距离作为这两个集合的距离，容易造成一种叫做 Chaining 的效果，两个 cluster 明明从&ldquo;大局&rdquo;上离得比较远，但是由于其中个别的点距离比较近就被合并了，并且这样合并之后 Chaining 效应会进一步扩大，最后会得到比较松散的 cluster 。</li><li>Complete Linkage：这个则完全是 Single Linkage 的反面极端，取两个集合中距离最远的两个点的距离作为两个集合的距离。其效果也是刚好相反的，限制非常大，两个 cluster 即使已经很接近了，但是只要有不配合的点存在，就顽固到底，老死不相合并，也是不太好的办法。</li><li>Group Average：这种方法看起来相对有道理一些，也就是把两个集合中的点两两的距离全部放在一起求一个平均值，相对也能得到合适一点的结果。</li></ul></li></ol><p>总的来说，一般都不太用 Single Linkage 或者 Complete Linkage 这两种过于极端的方法。整个 agglomerative hierarchical clustering 的算法就是这个样子，描述起来还是相当简单的，不过计算起来复杂度还是比较高的，要找出距离最近的两个点，需要一个双重循环，而且 Group Average 计算距离的时候也是一个双重循环。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分层集群</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>K近邻算法（KNN）</title>
    <link href="/2018/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%EF%BC%88KNN%EF%BC%89/"/>
    <url>/2018/K-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%EF%BC%88KNN%EF%BC%89/</url>
    
    <content type="html"><![CDATA[<p><span style="color: #000000;">本文来自阅读机器学习实战过程中做的笔记，可能有点多，因为写的太好了，没忍住就记录下来，方便以后电子复习。</span></p><p>1、概念：k-近邻算法采用测量不同特征值之间的距离方法进行分类。</p><p>2、原理：存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所分类的对应关系。输入没有标签的新数据后，将新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k0近邻算法中k的由来。</p><p>3、优点：精度高、对异常值不敏感、无数据输入假定。</p><p>　&nbsp; 缺点：计算复杂度高、空间复杂度高。</p><p>&nbsp; &nbsp; &nbsp; 适用范围：数值型和标称型。</p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>KNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Logistic回归</title>
    <link href="/2018/Logistic%E5%9B%9E%E5%BD%92/"/>
    <url>/2018/Logistic%E5%9B%9E%E5%BD%92/</url>
    
    <content type="html"><![CDATA[<p>1、假设现在有一些数据点，我们用一条直线对这些点进行拟合（该线称为最佳拟合直线），这个拟合过程就称作回归。</p><p>2、思想：根据现有的数据对分类边界线建立回归公式，以此进行分类。</p><p>3、优点：计算代价不高，易于理解和实现。</p><p>　　缺点：容易欠拟合，分类精度可能不高。</p><p>　　使用数据类型：数值型和标准型数据。</p><p>4、Sigmoid函数：是一种阶跃函数（step function）。在数学中，如果实数域上的某个函数可以用半开区间上的指示函数的有限次线性组合来表示，那么这个函数就是阶跃函数。数学中的指示函数（indicator function）是定义在某集合X上的函数，表示其中有哪些元素属于某一子集A。</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Logistic回归</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python的set</title>
    <link href="/2018/python%E7%9A%84set/"/>
    <url>/2018/python%E7%9A%84set/</url>
    
    <content type="html"><![CDATA[<p>python的set和其他语言类似,&nbsp;是一个无序不重复元素集,&nbsp;基本功能包括关系测试和消除重复元素.&nbsp;集合对象还支持union(联合),&nbsp;intersection(交),&nbsp;difference(差)和sysmmetric&nbsp;difference(对称差集)等数学运算.&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>set操作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sklearn.datasets.make_moons半月形数据生成</title>
    <link href="/2018/sklearn.datasets.make_moons%E5%8D%8A%E6%9C%88%E5%BD%A2%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/"/>
    <url>/2018/sklearn.datasets.make_moons%E5%8D%8A%E6%9C%88%E5%BD%A2%E6%95%B0%E6%8D%AE%E7%94%9F%E6%88%90/</url>
    
    <content type="html"><![CDATA[<p>学习了一个很有趣的数据生成，给大家分享一下</p><div class="cnblogs_code"><pre></pre><pre><span style="color: #cc7832;">from sklearn.datasets <span style="color: #cc7832;">import make_moons<br /><span style="color: #cc7832;">import matplotlib.pyplot <span style="color: #cc7832;">as plt<br /><br /><span style="color: #cc7832;">if __name__ == <span style="color: #6a8759;">'__main__':<br />    N = <span style="color: #6897bb;">400<br /><span style="color: #6897bb;">    centers = <span style="color: #6897bb;">4<br /><span style="color: #6897bb;"><br /><span style="color: #6897bb;">    noise = (<span style="color: #6897bb;">0.5<span style="color: #cc7832;">, <span style="color: #6897bb;">0.05)<br />    plt.figure(<span style="color: #aa4926;">figsize=(<span style="color: #6897bb;">12<span style="color: #cc7832;">, <span style="color: #6897bb;">14)<span style="color: #cc7832;">, <span style="color: #aa4926;">facecolor=<span style="color: #6a8759;">'w')<br />    <span style="color: #cc7832;">for i<span style="color: #cc7832;">, n <span style="color: #cc7832;">in <span style="color: #8888c6;">enumerate(noise):<br />        plt.subplot(<span style="color: #6897bb;">1<span style="color: #cc7832;">, <span style="color: #6897bb;">2<span style="color: #cc7832;">, i+<span style="color: #6897bb;">1)<br />        plt.title(n<span style="color: #cc7832;">, <span style="color: #aa4926;">fontsize=<span style="color: #6897bb;">16)<br />        data<span style="color: #cc7832;">, y = make_moons(<span style="color: #aa4926;">n_samples=N<span style="color: #cc7832;">, <span style="color: #aa4926;">noise=n)<br />        plt.scatter(data[:<span style="color: #cc7832;">, <span style="color: #6897bb;">0]<span style="color: #cc7832;">, data[:<span style="color: #cc7832;">, <span style="color: #6897bb;">1]<span style="color: #cc7832;">, <span style="color: #aa4926;">c=y<span style="color: #cc7832;">,)<br />    plt.savefig(<span style="color: #6a8759;">'one.png')<br />    plt.show()</span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></pre><pre><span style="color: #000000;">&nbsp;</span></pre></div><p><img src="/2023/image/1218402-20171209155813417-90414577.png" alt="" /></p><p>当noise的值不同时，产生的数据随之也不一样，noise个人认为就是添加的噪声。当noise越小时，产生的数据越精确。越大就反正了。希望大家多多点评</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>sklearn</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>window使用VNC远程ubuntu16.04</title>
    <link href="/2018/window%E4%BD%BF%E7%94%A8VNC%E8%BF%9C%E7%A8%8Bubuntu16.04/"/>
    <url>/2018/window%E4%BD%BF%E7%94%A8VNC%E8%BF%9C%E7%A8%8Bubuntu16.04/</url>
    
    <content type="html"><![CDATA[<p>首先保证在同一局域网下</p><h1>一、设置Ubuntu 16.04 允许进行远程控制</h1><p>首先在ubuntu下找到下图图标</p><p><img src="/2023/image/1218402-20200926212633155-563108075.png" alt="" loading="lazy" /></p><p>将【允许其他人查看您的桌面】这一项勾上，然后在安全那项，勾选【要求远程用户输入此密码】，并设置远程密码。并且我们取消勾选【必须为对本机器的每次访问进行确定】（这样做，是为了被远程的时候不需要再确认，否则每次远程都要人为确认才能被远程，会很繁琐）如图所示</p><p><img src="/2023/image/1218402-20200926212653629-587026793.png" alt="" loading="lazy" /></p><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h1>二、安装vncserver</h1><p>&nbsp;</p><p>打开终端，我们需要安装vncserver的基础服务，输入以下命令：</p><pre>sudo apt-get install xrdp vnc4server xbase-clients</pre><h1>三、安装dconf-editor(取消权限限制)</h1><p>&nbsp;　　再次，我们需要取消掉请求加密的功能，否则缺少这一步是无法远程上的，这个时候我们需要安装dconf-editor工具进行配置，输入以下命令：</p><pre>sudo apt-get install dconf-editor<br />之后输入sudo dconf-editor 打开如下图标，不要在桌面搜索打开dconf-editor，因为可能出现无法编辑的问题（本人就遇到过）<br />依次操作：打开之后，依次展开org-&gt;gnome-&gt;desktop-&gt;remote-access，然后取消 &ldquo;requlre-encryption&rdquo;和"prompr-enabled"的勾选即可。如图所示</pre><p><img src="/2023/image/1218402-20200926213104308-1158459718.png" alt="" loading="lazy" /></p><p>&nbsp;</p><p>至此，前期准备工作已经完成，后面直接通过VNC工具或者Windows自带的mstsc(远程桌面控制)进行访问就行。</p><p>之后在终端输入：vncserver</p><p>因为接下来这个文件可能一开始不会有。</p><p><strong>如果还是遇到问题，那就需要换 vncserver端口，具体操作如下：</strong></p><p>修改vnc配置文件：</p><p>输入gedit ~/.vnc/xstartup(不用管报错)</p><p>&nbsp;</p><p><img src="/2023/image/1218402-20200926213415720-1962351903.png" alt="" loading="lazy" /></p><p>&nbsp;</p><p>&nbsp;上图最后未注释几行可能不清楚，在下面文字显现：</p><p>export XKL_XMODMAP_DISABLE=1&nbsp;</p><p>unset SESSION_MANAGER&nbsp;</p><p>unset DBUS_SESSION_BUS_ADDRESS&nbsp;</p><p>&nbsp;</p><p>gnome-panel &amp;</p><p>gnome-settings-daemon &amp;</p><p>metacity &amp;</p><p>nautilus &amp;</p><p>gnome-terminal &amp;</p><p>&nbsp;</p><p>将其中内容仅保留第一行，其余替换为配置文档中的内容：</p><p>点击该文件的save按钮，关闭即可。</p><p>之后再次输入vncserver，获取新的端口号：</p><p>&nbsp;<img src="/2023/image/1218402-20200926213505453-191211156.png" alt="" loading="lazy" /></p><p>&nbsp;</p><p>&nbsp;</p><p>可以看到新端口号为5.</p><p>进入vnc在顶部输入栏输入：10.8.26.140:5</p><p>就可以远程上你想要远程的服务器了。</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>ubuntu</tag>
      
      <tag>Windows</tag>
      
      <tag>VNC</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>排序算法基础知识</title>
    <link href="/2018/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"/>
    <url>/2018/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    
    <content type="html"><![CDATA[<p>各种排序算法时间复杂度和空间复杂度</p><p><img src="/2023/image/1218402-20220923164443781-270345838.png" alt="" /></p><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>排序算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习西瓜书第二章笔记</title>
    <link href="/2018/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%BA%8C%E7%AB%A0%E7%AC%94%E8%AE%B0/"/>
    <url>/2018/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%BA%8C%E7%AB%A0%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<div><span style="font-family: 宋体; font-size: 18px;"><strong>第二节；模型评估与选择</strong></span><br /><span style="font-family: 宋体;">1、过拟合（过配）：当学习器把训练样本学得&ldquo;<span style="color: #ff0000;">太好</span>&rdquo;了的时候，很可能已经把训练样本自身的一些特点当做了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。</span><br /><span style="font-family: 宋体;">&nbsp;　　*过拟合最常见导致原因：学习能力过于强大</span><br /><span style="font-family: 宋体;">&nbsp;　　*过拟合是<span style="color: #ff0000;">无法彻底避免</span>的，我们所能做的只是&rdquo;缓解&rdquo;，或者说减小其风险</span><br /><span style="font-family: 宋体;">2、欠拟合（欠配）：是指对训练样本的一般性质尚未学好</span><br /><span style="font-family: 宋体;">3、学习能力是否&ldquo;过于强大&ldquo;，是由学习算法和数据内涵共同决定</span><br /><span style="font-family: 宋体;">4、产生训练集S和测试集T的方法</span><br /><span style="font-family: 宋体;">&nbsp;　　1）、<span style="color: #ff0000;">留出法</span>：直接将数据集D划分为两个互斥的集合。即一个作为训练集S，一个作为测试集T。</span><br /><span style="font-family: 宋体;">&nbsp;　　*难点在于如何划分两个集合，训练集S过大会导致评估结果不够稳定准确，T过大会导致降低评估结果的保真性（fidelity）。</span><br /><span style="font-family: 宋体;">&nbsp;　　2）、<span style="color: #ff0000;">交叉验证法</span>：先将数据集D划分为k个大小相似的互斥子集，每个子集都尽可能保持数据分布的一致性，然后每次用k-1个子集的并集作　　　　为训练集，余下的那一个子集作为测试集；这样就可以获得k组训练/测试集，从而可以进行k次训练和测试，最终返回的是这k个测试集结果的均值。</span><br /><span style="font-family: 宋体;">&nbsp;　　3）、<span style="color: #ff0000;">自助法</span>：以自助采样法（<span style="color: #ff9900;">bootstrap sampling</span>）为基础。在给定包含m个样本的数据集D，我们对它进行采样产生数据集D`，每次随机从D中挑选一个样本，将其拷贝放入到D`,然后再将该样本放回D中，使得该样本在下次随机取样中依旧可能被采集到，将这个过程重复m次后，我们就得到了包含m个样本的数据集D`，这就是自助采样的结果。</span><br /><span style="font-family: 宋体;">5、模型的&ldquo;好坏&rdquo;是相对的，模型的好坏不仅取决于算法和数据，还取决于任务需求。</span><br /><span style="font-family: 宋体;">&nbsp;　　<span style="color: #00ff00;">*回归任务最常用的性能度量是：均方误差</span></span><br /><span style="font-family: 宋体;">6、查准率（准确率）和查全率（召回率）是一对矛盾的度量。一般时候查准率越高（低），查全率往往越低（高）。</span><br /><span style="font-family: 宋体;">&nbsp;　　*查准率:P=TP/(TP+FP)</span><br /><span style="font-family: 宋体;">&nbsp;　　*查全率:R=TP/(TP+FN)</span><br /><span style="font-family: 宋体;">&nbsp;　　1）、若一个学习器的P-R曲线被另一个学习器的曲线完全&ldquo;包住&rdquo;，则可断言后者的性能优于前者。</span><br /><span style="font-family: 宋体;">&nbsp;　　2）、<span style="color: #ff0000;">平衡点</span>（<span style="color: #3366ff;">Break-Even Point 简称：BEP</span>）：它是&ldquo;查准率=查全率&rdquo;时的取值。</span><br /><span style="font-family: 宋体;">&nbsp;&nbsp;　　*通常不使用BEP，因为太过简化，一般使用F1度量，F1是基于查准率与查全率的<span style="color: #ff0000;">调和平均</span>（<span style="color: #3366ff;">harmonic mean</span>）定义的。</span><br /><span style="font-family: 宋体;">7、ROC与AUC</span><br /><span style="font-family: 宋体;">&nbsp;　　1）、<span style="color: #ff0000;">截断点</span>（<span style="color: #3366ff;">cut point</span>）：将样本分为两个部分，前一部分判作正例，后一部分则判作反例。</span><br /><span style="font-family: 宋体;">&nbsp;　　2）、我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以他们为横，纵坐标作图，就得到<span style="color: #ff0000;">ROC曲线</span>。</span><br /><span style="font-family: 宋体;">&nbsp;　　3）、<span style="color: #ff0000;">ROC</span>全称是&ldquo;<span style="color: #ff0000;">受试者工作特征</span>&rdquo;（<span style="color: #3366ff;">Receiver Operating Characteristic</span>），其纵轴是<span style="color: #ff0000;">&ldquo;真正例率</span>&rdquo;（<span style="color: #3366ff;">True Positive Rate</span>，简称：<span style="color: #3366ff;">TPR</span>），横轴是&ldquo;<span style="color: #ff0000;">假正例率</span>&rdquo;（<span style="color: #3366ff;">False Positive Rate，简称：FPR</span>）</span><br /><span style="font-family: 宋体;">&nbsp;　　4）、与P-R图相似，若一个学习器的ROC曲线被另一个学习器的曲线完全"包住"，则可以断言后者的性能优于前者。若两个学习器曲线发生交叉，则一般难以进行判定谁优谁劣，此时若要进行比较，则比较合理的方法就是比较<span data-mce-="">ROC曲线下的面积，即<span data-mce-="">AUC（<span data-mce-="">Area Under ROC Curve）。</span></span></span></span><br /><span style="font-family: 宋体;">8、代价敏感错误率与代价曲线</span><br /><span style="font-family: 宋体;">&nbsp;　　1）、为权衡不同类型错误所造成的不同损失，可为错误赋予&ldquo;<span style="color: #ff0000;">非均等代价</span>&rdquo;（<span style="color: #3366ff;">unequal cost</span>）</span><br /><span style="font-family: 宋体;">&nbsp;　　2）、在非均等代价下，ROC曲线不能直接反映出学习器的期望总体代价，而&ldquo;<span style="color: #ff0000;">代价曲线</span>&rdquo;（<span style="color: #3366ff;">cost curve</span>）则可以达到该目的。</span><br /><span style="font-family: 宋体;">9、<span style="color: #ff00ff;">机器学习性能比较的几个重要因素</span>：</span><br /><span style="font-family: 宋体;">&nbsp;　　1）、我们希望比较的是泛化性能，然而通过实验评估方法我们获得的是测试集上的性能，两者的对比结果可能未必相同。</span><br /><span style="font-family: 宋体;">&nbsp;　　2）、测试集上的性能与测试集本身的选择有很大关系，且不论使用不同大小的测试集会得到不同的结果，即便用相同大小的测试集，所包含测试样例不同，测试结果也会有不同。</span><br /><span style="font-family: 宋体;">&nbsp;　　3）、很多机器学习算法本身有一定的随机性，即便用相同的参数设置在同一个测试集上多次运行，其结果也会有不同。</span><br /><span style="font-family: 宋体;">10、<span style="color: #ff0000;">统计假设检验</span>（<span style="color: #3366ff;">hypothesis test</span>）为我们进行学习器性能比较提供了重要依据</span><br /><span style="font-family: 宋体;">&nbsp;　　1）<span style="color: #ff0000;">&ldquo;<strong>二项检验&ldquo;和&ldquo;t检验（t-test</strong>）&rdquo;</span><span style="text-decoration: underline;">是对于单个学习器泛化性能的假设进行检验</span>。</span></div><div><span style="font-family: 宋体;">　　　　<span style="color: #ff0000;">&ldquo;</span><span style="color: #ff0000;"><strong>交叉验证t检验&rdquo;和&ldquo;McNemar检验&rdquo;</strong></span><span style="text-decoration: underline;">是对不同学习器的性能进行比较</span>。</span><br /><span style="font-family: 宋体;">&nbsp;　　2）<span style="color: #ff0000;">交叉验证t检验</span>：其思想就是若两个学习器的性能相同，则他们使用相同的训练/测试集得到的测试错误率应相同。具体来说，就是对<span style="color: #ff0000;">k折交叉验证</span>产生的k对测试错误率，先对每队结果求差，若两个学习器性能相同，则差值理应为零，因此可以根据这些差值，计算出差值的均值和方差。</span><br /><span style="font-family: 宋体;">&nbsp;　　3）、<strong><span style="color: #ff0000;">&ldquo;交叉验证t检验&rdquo;和&ldquo;McNemar检验&rdquo;</span></strong>都是在一个数据集上比较两个算法的性能。而我们在<span style="color: #000000;">一个数据集上进行多个算法比较</span>，<span style="color: #00ff00;">则采用基于算法排序的<span style="color: #ff0000;">Friedman检验</span></span><span style="color: #ff0000;">，</span>使用Friedman检验来判断这些算法是否性能都相同，若相同，则它们的平均序值应当相同，若&ldquo;所有算法的性能相同&rdquo;这个假设被拒绝，则说明算法的性能显著不同，这是就需要进行&ldquo;<span data-mce-=""><span style="color: #ff0000;">后续检验</span>&rdquo;（<span data-mce-="">post-hoc test）来进一步区分各算法，常用的有<span data-mce-=""><span style="color: #ff0000;">Nemenyi后续检验</span>。</span></span></span></span><br /><span style="font-family: 宋体;">11、<span style="color: #ff0000;">偏差-方差分解</span>（<span style="color: #3366ff;">bias-variance decomposition</span>）是解释学习算法泛化性能的一种重要工具。</span><br /><span style="font-family: 宋体;">&nbsp;　　1）、偏差与方差分解说明，泛化性能是由学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的。</span></div><div><span style="font-family: 宋体;">&nbsp;</span></div><div><span style="font-family: 宋体;">&nbsp;</span></div>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>西瓜书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机器学习西瓜书第五章神经网络笔记</title>
    <link href="/2018/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%BA%94%E7%AB%A0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%20/"/>
    <url>/2018/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%A5%BF%E7%93%9C%E4%B9%A6%E7%AC%AC%E4%BA%94%E7%AB%A0%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AC%94%E8%AE%B0%20/</url>
    
    <content type="html"><![CDATA[<p><span style="font-size: 18px;"><strong>第五章：神经网络</strong></span></p><p>1、<span style="color: #ff0000;">神经网络（neural networks</span>）：神经网络是由具有适应性的简单单元组成的广泛并进行互连的网络，它的组织能够模拟生物神经系统对真实世界物体所做出的交互反应。<br />2、<span style="color: #ff0000;">感知机（Perceptron</span>）由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层是M-P神经元，也称为&ldquo;<span style="color: #ff0000;">阈值逻辑单元&rdquo;（threshold logic unit）</span>。<br />&nbsp;　　1）、感知机只有输出层神经元进行<span style="color: #00ff00;">激活函数处理</span>，即只拥有一层<span style="color: #ff0000;">功能神经元（functional neuron</span>），其学习能力非常有限。<br />&nbsp;　　2）、输入层与输出层之间的层神经元，被称为隐层或<span style="color: #ff0000;">隐含层（hidden layer）</span>。<br />3、<span style="color: #ff0000;">多层前馈神经网络（multi-layer feedforward neural networks）</span>:每层神经元与下一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接。<br />&nbsp;　　1）、前馈并不意味着网络中的信号不能向后传递，而是指网络拓扑结构上不存在环或者回路。<br />&nbsp;　　2）、神经网络的学习过程，就是根据训练数据来调整神经元之间的&ldquo;<span style="color: #ff0000;">连接权&rdquo;（connection weight</span>）以及每个功能神经元的阈值，换言之，神经网络&ldquo;学&rdquo;到的东西，蕴含在在连接权和阈值中。<br />4、<span style="color: #ff0000;">误差逆传播（error BackPropagation，简称：BP）算法</span>：是最成功的的神经网络学习算法，可用于多层前馈神经网络和其他类型的神经网络。<br />&nbsp;　　1）、BP是一个迭代学习算法，在迭代的每一轮中采用广义感知机学习规则对参数进行更新估计。<br />　　&nbsp;2）、BP算法是基于<span style="color: #ff0000;">梯度下降（gradient descent</span>）策略，以目标的负梯度方向对参数进行调整。<br />&nbsp;　　3）、BP操作过程：先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出层的结果；然后计算输出层的误差，再将误差逆向传播至隐层神经元，最后根据隐层神经元的误差来对连接权和阈值进行调整。该迭代过程循环进行，直到达到某些停止条件为止。<br />&nbsp;　　4）、BP算法由于其强大的表示能力，所以经常遭遇过拟合，其训练误差持续降低，但测试误差却可能上升。有两种策略缓解BP过拟合问题：<br />&nbsp;　　　　（1）、<span style="color: #ff0000;">早停（early stopping）</span>：将数据分为训练集和验证集，训练集用来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值。<br />&nbsp;&nbsp;　　　&nbsp; （2）、<span style="color: #ff0000;">正则化（regularization）</span>：在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接权和阈值的平方和。<br /><span style="color: #3366ff;"><strong>注</strong>：<strong>BP算法实质是LMS（Least Mean Square）算法的推广</strong></span>。<br />5、全局最小和局部极小<br />&nbsp;　　1）、用E表示神经网络在训练集上的误差，显然，它是关于连接权和阈值的函数。此时，神经网络训练过程可以看做是一个参数寻优过程，我们需要寻找一组最优参数使得E最小。<br />&nbsp;　　2）、两种最优：<span style="color: #ff0000;">全局最小（global minimum）</span>和<span style="color: #ff0000;">局部极小（local minimum）</span>，全局最小一定是局部极小，反之不成立。我们在寻优的过程就是希望找到全局最小。<br />&nbsp;　　3）、由于负梯度方向是函数值下降最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解。<br />　　&nbsp;4）、&ldquo;跳出&rdquo;局部极小，寻找全局最小的策略：<br />&nbsp;&nbsp;　　　　（1）、以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差最小的解作为最终参数。<br />&nbsp;&nbsp;　　　　（2）、<span style="color: #ff0000;">&ldquo;模拟退火&rdquo;（simulated annealing）技术</span>：模拟退火在每一步都以一定的概率接受比当前解更差的结果，在每步迭代过程中，接受&ldquo;次优解&rdquo;的概率要随着时间的推移而逐渐降低，从而保证算法稳定。<span style="color: #3366ff;"><strong>注</strong>：<strong>但是也可能会造成&ldquo;跳出&rdquo;全局最小。</strong></span><br />&nbsp;&nbsp;　　　　（3）、使用随机梯度下降。<br />&nbsp;&nbsp;　　　　（4）、<span style="color: #ff0000;">遗传算法（genetic algorithms）</span>。<br />6、常见的神经网络<br />&nbsp;　　1）、<span style="color: #ff0000;">RBF（Radial Basis Function，径向基函数）网络</span>：是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函数，而输出层则是对隐层神经元输出的线性组合。<br />&nbsp;　　2）、<span style="color: #ff0000;">ART（Adaptive Resonance Theory，自适应谐振理论）网络</span>：是<span style="color: #00ff00;">竞争型学习</span>（competitive learning）【<strong><span style="color: #3366ff;">注：无监督学习策略</span></strong>】的代表。<br />&nbsp;　　3）、<span style="color: #ff0000;">SOM（Self-Organizing Map，自组织映射）网络</span>：是一种竞争学习型的<span style="color: #00ff00;">无监督神经网络</span>，它能将高维输入数据映射到低维空间，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点映射到网络输出层中的邻近神经元。<br />&nbsp;　　4）、<span style="color: #ff0000;">级联相关（Cascade-Correlation）网络</span>:是结构自适应网络的重要代表。<br />&nbsp;　　5）、<span style="color: #ff0000;">Elman网络</span>：是最常用的递归神经网络之一。<br />7、<span style="color: #ff0000;"><strong>Boltzmann机（玻尔兹曼机）</strong></span>：<br />&nbsp;　　1）、一种基于<span style="color: #ff0000;">能量的模型（energy-based model</span>），其神经元分为两层：显层与隐层。显层用于表示数据的输入与输出，隐层则被理解为数据的内在表达。<br />&nbsp;　　2）、Boltzmann机中的神经元都是布尔型。<br />&nbsp;　　3）、它的训练过程就是将每个训练样本视为一个状态向量，使其出现的概率尽可能大。<br />&nbsp;　　4）、标准Boltzmann机是一个全连接图，训练网络复杂度很高，这使其难以用于解决现实任务。所以现实中一般采用<span style="color: #ff0000;">受限Boltzmann机（Restricted Boltzmann Machine，简称：RBM）</span>。<br />8、受限Boltzmann机常用&ldquo;<span style="color: #ff0000;">对比散度&rdquo;（Contrastive Divergence，简称CD）算法</span>来进行训练。</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>西瓜书</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习之蒙特卡洛算法</title>
    <link href="/2018/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E7%AE%97%E6%B3%95/"/>
    <url>/2018/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p>蒙特卡洛算法称之为统计模拟方法，是一种以概率论统计理论为指导的一类非常重要的数值计算方法。是通过使用随机数来解决很多计算问题的方法。</p><p>基本思想：是某种随机事件出现的概率，或者是某个随机变量的期望值时，通过某种&ldquo;实验&rdquo;的方法，以这种事件出现的频率估计这一随机事件的概率，或者得到这个随机变量的某些数字特征，并将其作为问题的解。</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>蒙特卡洛算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>生成式模型和判别式模型</title>
    <link href="/2018/%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8B/"/>
    <url>/2018/%E7%94%9F%E6%88%90%E5%BC%8F%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%88%A4%E5%88%AB%E5%BC%8F%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<img src="/2023/image/1218402-20221016173550035-626104642.png" alt="" /><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>充电学习</category>
      
    </categories>
    
    
    <tags>
      
      <tag>生成式模型</tag>
      
      <tag>判别式模型</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pycharm连接数据库</title>
    <link href="/2017/pycharm%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    <url>/2017/pycharm%E8%BF%9E%E6%8E%A5%E6%95%B0%E6%8D%AE%E5%BA%93/</url>
    
    <content type="html"><![CDATA[<p>今天说说如何使用pycharm连接oracle数据库</p><p>1、首先你需要安装oracle数据库</p><p>2、在pycharm中安装cx_Oracle。在file-&gt;settings-&gt;Project-&gt;project interpreter。中选择你的python版本，然后直接点击右上方+按钮，搜索cx_Oracle，进行安装。具体看图</p><p><img src="/2023/image/1218402-20171219151252725-1626917096.png" alt="" /></p><p>3、之后就是使用如下代码进行连接</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span> cx_Oracle <span style="color: #008000;">#</span><span style="color: #008000;"> 这个就是为了连接oracle导入的库，个人认为应该就是一个驱动吧！</span><span style="color: #800000;">'''</span><span style="color: #800000;">    第一个：参数是你的的登录oracle时的用户名    第二个：参数就是登录密码    第三个：127.0.0.1:1521就是oracle的ip地址加端口    第四个：是你的监听服务器的名称，你可以去oracle下的Net Configuration Assistance这儿去修改，有一个地址讲的特别详细            最后我会贴地址。                                               </span><span style="color: #800000;">'''</span><span style="color: #000000;">conn </span>= cx_Oracle.connect(<span style="color: #800000;">'</span><span style="color: #800000;">scott</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">123</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">127.0.0.1:1521/orcl</span><span style="color: #800000;">'</span>)  <span style="color: #008000;">#</span><span style="color: #008000;"> 第一个参数是你的的登录oracle时的用户名</span>cursor =<span style="color: #000000;"> conn.cursor()cursor.execute(</span><span style="color: #800000;">'</span><span style="color: #800000;">select * from AQI_DATA</span><span style="color: #800000;">'</span><span style="color: #000000;">)result </span>=<span style="color: #000000;"> cursor.fetchall()</span><span style="color: #0000ff;">print</span><span style="color: #000000;"> (cursor.rowcount)</span><span style="color: #0000ff;">for</span> row <span style="color: #0000ff;">in</span><span style="color: #000000;"> result:    </span><span style="color: #0000ff;">print</span>(row)</pre></div><p>修改TNS地址，也就是监听：https://jingyan.baidu.com/article/03b2f78c7a0ab75ea237ae33.html</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>连接数据库</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python之csv操作</title>
    <link href="/2017/python%E4%B9%8Bcsv%E6%93%8D%E4%BD%9C/"/>
    <url>/2017/python%E4%B9%8Bcsv%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<p>在使用python爬虫时或者其他情况，都会用到csv存储与读取的相关操作，我们在这里就浅谈一下：</p><p>CSV（Comma-Separated Values）逗号分隔符，也就是每条记录中的值与值之间是用分号分隔的。</p><p>一、读文件</p><p>方法一:只是使用csv这个库</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span> csv <span style="color: #008000;">#</span><span style="color: #008000;"> 导入csv这个库</span><span style="color: #0000ff;">from</span> itertools <span style="color: #0000ff;">import</span> islice  <span style="color: #008000;">#</span><span style="color: #008000;"> 当不读取csv文件第一行时，导入这个包有很棒的效果</span><span style="color: #008000;">#</span><span style="color: #008000;"> 读取china_city_aqi.csv文件，以r方式进行读取，编码是utf-8</span>with open(<span style="color: #800000;">"</span><span style="color: #800000;">china_city_aqi.csv</span><span style="color: #800000;">"</span>, <span style="color: #800000;">"</span><span style="color: #800000;">r</span><span style="color: #800000;">"</span>, encoding = <span style="color: #800000;">"</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">"</span><span style="color: #000000;">) as f:    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 将csv读取的文件放入reader中</span>    reader =<span style="color: #000000;"> csv.reader(f)    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 之后进行遍历，islice(reader, 1, None) 中表示读取reader文件中的第一行至最后一行，当然你可以修改到第几行结束</span>    <span style="color: #0000ff;">for</span> line <span style="color: #0000ff;">in</span> islice(reader, 1<span style="color: #000000;">, None):        </span><span style="color: #008000;">#</span><span style="color: #008000;"> 读取名称</span>        name = line[:1<span style="color: #000000;">]        </span><span style="color: #008000;">#</span><span style="color: #008000;"> 读取名称之后的数据</span>        value = line[1<span style="color: #000000;">:]        </span><span style="color: #0000ff;">print</span>(name, <span style="color: #800000;">'</span> <span style="color: #800000;">'</span>, value)<br /><br /></pre></div><p>方法二：使用pandas这个库（非常方便了）</p><pre>top_city.to_csv('top_city.csv', index=False, encoding='utf-8')<br />1、top_city:就是你要保存呢的数据，我的是列表保存<br />2、index：不想在文件中出现索引的话，那就设置为False,默认是True</pre><p>二、写文件</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> csvheaders </span>= [<span style="color: #800000;">'</span><span style="color: #800000;">苹果</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">香蕉</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">apple</span><span style="color: #800000;">'</span><span style="color: #000000;">]</span><span style="color: #008000;">#</span><span style="color: #008000;"> newline:表示换行，默认情况下都是'\n'</span>file = open(<span style="color: #800000;">'</span><span style="color: #800000;">writer.csv</span><span style="color: #800000;">'</span>, <span style="color: #800000;">'</span><span style="color: #800000;">w</span><span style="color: #800000;">'</span>, encoding=<span style="color: #800000;">'</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">'</span>, newline=<span style="color: #800000;">''</span><span style="color: #000000;">)writer </span>=<span style="color: #000000;"> csv.writer(file)writer.writerow(headers)</span></pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>csv操作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python网络爬虫之爬取图片</title>
    <link href="/2017/python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B9%8B%E7%88%AC%E5%8F%96%E5%9B%BE%E7%89%87/"/>
    <url>/2017/python%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB%E4%B9%8B%E7%88%AC%E5%8F%96%E5%9B%BE%E7%89%87/</url>
    
    <content type="html"><![CDATA[<p>今天使用requests和BeautifulSoup爬取了一些图片，还是很有成就感的，注释可能有误，希望大家多提意见：</p><p>方法一：requests</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">import</span><span style="color: #000000;"> requests</span><span style="color: #0000ff;">from</span> bs4 <span style="color: #0000ff;">import</span><span style="color: #000000;"> BeautifulSoupcircle </span>= requests.get(<span style="color: #800000;">'</span><span style="color: #800000;">http://travel.quanjing.com/tag/12975/%E9%A9%AC%E5%B0%94%E4%BB%A3%E5%A4%AB</span><span style="color: #800000;">'</span><span style="color: #000000;">)<p></span><span style="color: #008000;">#</span><span style="color: #008000;"> 将获取的图片地址依次放入count中</span><br>count &#x3D;<span style="color: #000000;"> []<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 将获取的网页内容放入BeautifulSoup</span><br>soup &#x3D; BeautifulSoup(circle.text, <span style="color: #800000;">‘</span><span style="color: #800000;">lxml</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 根据谷歌SelectGadGet这个插件，获取html标签，比如获取：#gallery-list</span><br><span style="color: #0000ff;">for</span> item <span style="color: #0000ff;">in</span> soup.select(<span style="color: #800000;">‘</span><span style="color: #800000;">#gallery-list</span><span style="color: #800000;">‘</span><span style="color: #000000;">):<br>    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 用bs4中的find_all获取 #gallery-list 中是否存在 img这个标签</span><br>    <span style="color: #0000ff;">for</span> img <span style="color: #0000ff;">in</span> item.find_all(<span style="color: #800000;">‘</span><span style="color: #800000;">img</span><span style="color: #800000;">‘</span><span style="color: #000000;">):<br>        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">img</span><span style="color: #800000;">‘</span><span style="color: #000000;">, img)<br>        </span><span style="color: #008000;">#</span><span style="color: #008000;"> m 是 img标签中存在的属性</span><br>        img_path &#x3D; img.get(<span style="color: #800000;">‘</span><span style="color: #800000;">m</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>        count.append(img_path)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 用enumerate依次取出count中的图片地址 放入v中</span><br><span style="color: #0000ff;">for</span> i,v <span style="color: #0000ff;">in</span><span style="color: #000000;"> enumerate(count):<br>    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 将获取的v值再次放入request中进行与网站相应</span><br>    image &#x3D;<span style="color: #000000;"> requests.get(v)<br>    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 存取图片过程中，出现不能存储 int 类型，故而，我们对他进行类型转换 str()。w:读写方式打开，b：二进制进行读写。图片一般用到的都是二进制。</span><br>    with open(<span style="color: #800000;">‘</span><span style="color: #800000;">D:\img</span><span style="color: #800000;">‘</span>+str(i)+<span style="color: #800000;">‘</span><span style="color: #800000;">.jpg</span><span style="color: #800000;">‘</span>, <span style="color: #800000;">‘</span><span style="color: #800000;">wb</span><span style="color: #800000;">‘</span><span style="color: #000000;">) as file:<br>        </span><span style="color: #008000;">#</span><span style="color: #008000;"> content：图片转换成二进制，进行保存。</span><br><span style="color: #000000;">        file.write(image.content)<br>    </span><span style="color: #0000ff;">print</span>(i)</pre></p></div><p>&nbsp;方法二：urllib.request</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">from</span> bs4 <span style="color: #0000ff;">import</span><span style="color: #000000;"> BeautifulSoup</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> urllib.request as ure</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> osurl </span>= <span style="color: #800000;">'</span><span style="color: #800000;">http://travel.quanjing.com/tag/12975/%E9%A9%AC%E5%B0%94%E4%BB%A3%E5%A4%AB</span><span style="color: #800000;">'</span><span style="color: #000000;">response </span>= ure.urlopen(url, timeout=30<span style="color: #000000;">)circle </span>= response.read().decode(<span style="color: #800000;">'</span><span style="color: #800000;">utf-8</span><span style="color: #800000;">'</span><span style="color: #000000;">)<p></span><span style="color: #008000;">#</span><span style="color: #008000;"> 将获取的图片地址依次放入count中</span><br>count &#x3D;<span style="color: #000000;"> []<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 将获取的网页内容放入BeautifulSoup</span><br>soup &#x3D; BeautifulSoup(circle, <span style="color: #800000;">‘</span><span style="color: #800000;">lxml</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 根据谷歌SelectGadGet这个插件，获取html标签，比如获取：#gallery-list</span><br><span style="color: #0000ff;">for</span> item <span style="color: #0000ff;">in</span> soup.select(<span style="color: #800000;">‘</span><span style="color: #800000;">#gallery-list</span><span style="color: #800000;">‘</span><span style="color: #000000;">):<br>    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 用bs4中的find_all获取 #gallery-list 中是否存在 img这个标签,limit:限制爬取的数量。</span><br>    <span style="color: #0000ff;">for</span> img <span style="color: #0000ff;">in</span> item.find_all(<span style="color: #800000;">‘</span><span style="color: #800000;">img</span><span style="color: #800000;">‘</span>, limit&#x3D;5<span style="color: #000000;">):<br>        </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">img</span><span style="color: #800000;">‘</span><span style="color: #000000;">, img)<br>        </span><span style="color: #008000;">#</span><span style="color: #008000;"> m 是 img标签中存在的属性</span><br>        img_path &#x3D; img.get(<span style="color: #800000;">‘</span><span style="color: #800000;">m</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>        count.append(img_path)<br></span><span style="color: #0000ff;">if</span> <span style="color: #0000ff;">not</span> os.path.exists(<span style="color: #800000;">‘</span><span style="color: #800000;">photo</span><span style="color: #800000;">‘</span><span style="color: #000000;">):<br>    os.makedirs(</span><span style="color: #800000;">‘</span><span style="color: #800000;">photo</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br></span><span style="color: #008000;">#</span><span style="color: #008000;"> 用enumerate依次取出count中的图片地址 放入v中</span><br><span style="color: #0000ff;">for</span> i,v <span style="color: #0000ff;">in</span><span style="color: #000000;"> enumerate(count):<br>    </span><span style="color: #008000;">#</span><span style="color: #008000;"> 存取图片过程中，出现不能存储 int 类型，故而，我们对他进行类型转换 str()。w:读写方式打开，b：二进制进行读写。图片一般用到的都是二进制。</span><br>    path &#x3D; <span style="color: #800000;">‘</span><span style="color: #800000;">photo\img</span><span style="color: #800000;">‘</span>+str(i)+<span style="color: #800000;">‘</span><span style="color: #800000;">.jpg</span><span style="color: #800000;">‘</span><span style="color: #000000;"><br>    with open(path, </span><span style="color: #800000;">‘</span><span style="color: #800000;">w</span><span style="color: #800000;">‘</span><span style="color: #000000;">) as file:<br>        ure.urlretrieve(v, path)<br>    </span><span style="color: #0000ff;">print</span>(i)</pre></p></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>爬虫</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>pyhton中map和reduce</title>
    <link href="/2017/pyhton%E4%B8%ADmap%E5%92%8Creduce/"/>
    <url>/2017/pyhton%E4%B8%ADmap%E5%92%8Creduce/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre><span style="color: #0000ff;">from</span> functools <span style="color: #0000ff;">import</span><span style="color: #000000;"> reduce</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> numpy as np</span><span style="color: #800000;">'''</span><span style="color: #800000;">reduce[function, sequence[, initial]]使用1、function:是一个有两个参数的函数，reduce依次从sequence中取一个元素，和上一次调用function的结果做参数再次调用function2、如果设置initial参数，会以sequence中的第一个元素和initial作为参数调用function。</span><span style="color: #800000;">'''</span><span style="color: #008000;">#</span><span style="color: #008000;"> 不设置initial</span><span style="color: #0000ff;">def</span><span style="color: #000000;"> reduce1():    result </span>= reduce(<span style="color: #0000ff;">lambda</span> x, y: x+y, [1, 3, 5, 7, 9<span style="color: #000000;">])    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">'</span><span style="color: #800000;">无initial：</span><span style="color: #800000;">'</span><span style="color: #000000;">, result)</span><span style="color: #0000ff;">def</span><span style="color: #000000;"> reduce2():    result </span>= reduce(<span style="color: #0000ff;">lambda</span> x, y: x + y, [1, 3, 5, 7, 9],100<span style="color: #000000;">)    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">'</span><span style="color: #800000;">有initial：</span><span style="color: #800000;">'</span><span style="color: #000000;">, result)<p></span><span style="color: #800000;">‘’’</span><span style="color: #800000;"><br>    map(function, sequence[, sequence, …]) -&gt; list<br>    第一个参数是函数，剩下是一个或多个序列，返回一个集合<br>    1、存在多个序列，会依次以每个序列中相同位置的元素做参数调用function函数<br></span><span style="color: #800000;">‘’’</span><br><span style="color: #0000ff;">def</span><span style="color: #000000;"> map1():<br>    array </span>&#x3D; np.arange(1,4<span style="color: #000000;">)<br>    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">array:</span><span style="color: #800000;">‘</span><span style="color: #000000;">, array)<br>    result </span>&#x3D; map(<span style="color: #0000ff;">lambda</span>  x: x**2<span style="color: #000000;">, array)<br>    </span><span style="color: #0000ff;">for</span> index,value <span style="color: #0000ff;">in</span><span style="color: #000000;"> enumerate(result):<br>        </span><span style="color: #0000ff;">print</span><span style="color: #000000;">( value)<br></span><span style="color: #0000ff;">def</span><span style="color: #000000;"> map2():<br>    array1 </span>&#x3D; np.arange(1,5<span style="color: #000000;">)<br>    array2 </span>&#x3D; np.arange(5,10<span style="color: #000000;">)<br>    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">array1:</span><span style="color: #800000;">‘</span><span style="color: #000000;">, array1)<br>    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">array2:</span><span style="color: #800000;">‘</span><span style="color: #000000;">, array2)<br>    result </span>&#x3D; map(<span style="color: #0000ff;">lambda</span> x, y: x +<span style="color: #000000;"> y, array1, array2)<br>    </span><span style="color: #0000ff;">for</span> index, value <span style="color: #0000ff;">in</span><span style="color: #000000;"> enumerate(result):<br>        </span><span style="color: #0000ff;">print</span><span style="color: #000000;">(value)<br></span><span style="color: #0000ff;">if</span> <span style="color: #800080;"><strong>name</strong></span> &#x3D;&#x3D; <span style="color: #800000;">‘</span><span style="color: #800000;"><strong>main</strong></span><span style="color: #800000;">‘</span><span style="color: #000000;">:<br>    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">—————–reduce———–</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>    reduce1()<br>    reduce2()<br>    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">—————map—————–</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>    map1()<br>    </span><span style="color: #0000ff;">print</span>(<span style="color: #800000;">‘</span><span style="color: #800000;">多个序列</span><span style="color: #800000;">‘</span><span style="color: #000000;">)<br>    map2()</span></pre></p></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>map操作</tag>
      
      <tag>reduce操作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sklearn中make_blobs模块使用</title>
    <link href="/2017/sklearn%20%E4%B8%AD%20make_blobs%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8/"/>
    <url>/2017/sklearn%20%E4%B8%AD%20make_blobs%E6%A8%A1%E5%9D%97%E4%BD%BF%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<p>sklearn.datasets.make_blobs(n_samples=100, n_features=2, centers=3, cluster_std=1.0, center_box=(-10.0, 10.0), shuffle=True, random_state=None)</p><p>属性含义：</p><p><strong>n_samples</strong>: int, optional (default=100) <br />The total number of points equally divided among clusters. <br />待生成的样本的总数。 <br /><strong>n_features</strong>: int, optional (default=2) <br />The number of features for each sample. <br />每个样本的特征数。 <br /><strong>centers</strong>: int or array of shape [n_centers, n_features], optional (default=3)  <br />The number of centers to generate, or the fixed center locations. <br />要生成的样本中心（类别）数，或者是确定的中心点。 <br /><strong>cluster_std</strong>: float or sequence of floats, optional (default=1.0) <br />The standard deviation of the clusters. <br />每个类别的方差，例如我们希望生成2类数据，其中一类比另一类具有更大的方差，可以将cluster_std设置为[1.0,3.0]。 <br /><strong>center_box</strong>: pair of floats (min, max), optional (default=(-10.0, 10.0)) <br />The bounding box for each cluster center when centers are generated at random. <br /><strong>shuffle</strong>: boolean, optional (default=True) <br />Shuffle the samples. <br /><strong>random_state</strong>: int, RandomState instance or None, optional (default=None) <br />If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by np.random.</p><h1 id="returns"><span style="font-size: 14px;">返回值</span></h1><p>X : array of shape [n_samples, n_features] <br />The generated samples. <br />生成的样本数据集。 <br />y : array of shape [n_samples] <br />The integer labels for cluster membership of each sample. <br />样本数据集的标签。</p><div class="cnblogs_code"><pre><span style="color: #0000ff;">from</span> sklearn.datasets <span style="color: #0000ff;">import</span><span style="color: #000000;"> make_blobs</span><span style="color: #0000ff;">import</span><span style="color: #000000;"> matplotlib.pyplot as plt<p></span><span style="color: #0000ff;">if</span> <span style="color: #800080;"><strong>name</strong></span> &#x3D;&#x3D; <span style="color: #800000;">‘</span><span style="color: #800000;"><strong>main</strong></span><span style="color: #800000;">‘</span><span style="color: #000000;">:<br>    N </span>&#x3D; 400<span style="color: #000000;"><br>    centers </span>&#x3D; 4<span style="color: #000000;"><br>    data, y </span>&#x3D; make_blobs(n_samples&#x3D;N, n_features&#x3D;2, centers&#x3D;<span style="color: #000000;">centers)</p><pre><code class="hljs">plt.scatter(data[:, 0], data[:, &lt;/span&gt;1], c=&lt;span style=&quot;color: #000000;&quot;&gt;y)plt.show()&lt;/span&gt;&lt;/pre&gt;</code></pre></div><p><img src="/2023/image/1218402-20171209153912339-2013239830.png" alt="" /></p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>make_blobs模块</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>python中的“.T”操作</title>
    <link href="/2017/python%E4%B8%AD%E7%9A%84%E2%80%9C.T%E2%80%9D%E6%93%8D%E4%BD%9C/"/>
    <url>/2017/python%E4%B8%AD%E7%9A%84%E2%80%9C.T%E2%80%9D%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<p>其实就是对一个矩阵的转置</p><p>看代码：</p><div class="cnblogs_code"><pre><span style="color: #000000;">aarray([[</span>1, 2, 3<span style="color: #000000;">],       [</span>4, 5, 6<span style="color: #000000;">],       [</span>7, 8, 9<span style="color: #000000;">]])a.Tarray([[</span>1, 4, 7<span style="color: #000000;">],       [</span>2, 5, 8<span style="color: #000000;">],       [</span>3, 6, 9]])</pre></div><p>&nbsp;</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>.T操作</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sklearn.neighbors.kneighbors_graph的简单属性介绍</title>
    <link href="/2017/sklearn.neighbors.kneighbors_graph%E7%9A%84%E7%AE%80%E5%8D%95%E5%B1%9E%E6%80%A7%E4%BB%8B%E7%BB%8D/"/>
    <url>/2017/sklearn.neighbors.kneighbors_graph%E7%9A%84%E7%AE%80%E5%8D%95%E5%B1%9E%E6%80%A7%E4%BB%8B%E7%BB%8D/</url>
    
    <content type="html"><![CDATA[<div class="cnblogs_code"><pre>connectivity = kneighbors_graph(data, n_neighbors=7, mode=<span style="color: #800000;">'</span><span style="color: #800000;">distance</span><span style="color: #800000;">'</span>, metric=<span style="color: #800000;">'</span><span style="color: #800000;">minkowski</span><span style="color: #800000;">'</span>, p=2, include_self=<span style="color: #000000;">True)<br />　　　 　<span style="color: #808080;"># kneighbors_graph([X,n_neighbors,mode]) 计算X中k个临近点（列表）对应的权重。</span>        </span><span style="color: #008000;">#</span><span style="color: #008000;"> metric：字符或者调用，默认值为&lsquo;minkowski&rsquo;</span>        <span style="color: #008000;">#</span><span style="color: #008000;"> n_neighbors：整数，可选（默认值为5）,用kneighbors_graph查找的近邻数。</span>        <span style="color: #008000;">#</span><span style="color: #008000;"> p：整数，可选（默认值为2）。是sklearn.metrics.pairwise.pairwise_distance里的闵可夫斯基度量参数，当 p=1时，</span>        <span style="color: #008000;">#</span><span style="color: #008000;"> 使用曼哈顿距离。当p=2时，使用的是欧氏距离。对于任意的p，使用闵可夫斯基距离。</span></pre></div><p>1、n_neighbors：整数，可选（默认值为5）,用k_neighbors查找的近邻数。 <br />2、radius：浮点数，可选（默认值为1.0） <br />3、algorithm：{&lsquo;auto&rsquo;,&rsquo;ball_tree&rsquo;,&rsquo;kd_tree&rsquo;,&rsquo;brute&rsquo;},可选 算法用来计算临近的值，&lsquo;ball_tree&rsquo;会用BallTree,&rsquo;kd_tree&rsquo;会用KDtree,&rsquo;brute&rsquo;会用burte-force来搜寻。 <br />                                                      &lsquo;auto&rsquo;会基于fit方法来决定大部分相似情况下合适的算法。 <br />                 4、NoTe:如果fit用在稀疏（矩阵）的输入上，那么将会覆盖参数的设置，而使用brute force. <br />5、leaf_size：整数，可选（默认值为30） <br />                 6、Leaf size是针对BallTree 和 KDTree的。 它将会影响构建模型和搜寻的速度，以及存储的树的内存。可选值将决定该问题的类型。 <br />7、p：整数，可选（默认值为2）。是sklearn.metrics.pairwise.pairwise_distance里的闵可夫斯基度量参数，当 p=1时，使用曼哈顿距离。当p=2时，使用的是欧氏距离。对于任意的p，使用闵可夫斯基距离。 <br />8、metric：字符或者调用，默认值为&lsquo;minkowski&rsquo; <br />              9、metric用来计算距离。scikit-learn或者scipy.spatial.distance中的任何距离都可以被使用。 <br />              如果距离是可选函数，每一对实例都会返回相应的记录值。（无法计算矩阵间的距离。） <br />10、metric_params：字典，可选（默认值为1） <br />                           关于距离公式中其他的关键值讨论。 <br />11、n_jobs：int，可选（默认值为1） <br />             表示搜寻近邻值时并行作业的数量    。如果为-1，那么并行数量则会被设定为CPU的内核数。 <br />             （只针对k_neighbors 和kneighbors_graph方法）</p>]]></content>
    
    
    <categories>
      
      <category>技术</category>
      
    </categories>
    
    
    <tags>
      
      <tag>KNN</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
